{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import lightgbm as lgb\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, matthews_corrcoef, precision_score, recall_score, make_scorer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation + Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42 \n",
    "LABEL_COLS = [\"CPPG.STATUS_SPS\", \"CPPG.STATUS_U0\", \"CPPG.STATUS_HEIGHT\", \"CPPG.STATUS_IMPEDANCE\", \"CPPG.STATUS_FORMATION\", \"CPPG.STATUS_MODUL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Data/TMTSA_Daten.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all Columns with only 1 value (no information gain for the algorithm) --> Removing 24 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_without_information_gain = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if len(df[column].value_counts()) == 1:\n",
    "        columns_without_information_gain.append(column)\n",
    "\n",
    "df_only_information_gain = df.drop(columns_without_information_gain, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPW.Werk',\n",
       " 'CPW.CATHODE_FZLENGTH_LOWER',\n",
       " 'CPM.Werk',\n",
       " 'CPX.Werk',\n",
       " 'CPFORM.SenderName',\n",
       " 'CPFORM.PROCESSDESCRIPTION',\n",
       " 'CPFORM.Werk',\n",
       " 'CPPG.Werk',\n",
       " 'CPPG.STATUS_MODUL',\n",
       " 'CPX.Werk_1',\n",
       " 'CPX.Werk_2',\n",
       " 'CPW.QUALITY_INSPECTION',\n",
       " 'CPX.CONV_Result001_1',\n",
       " 'CPM.RejectScan',\n",
       " 'CPM.RejectScan1',\n",
       " 'CPX.CONV_Result001_2',\n",
       " 'CPX.CONV_ACOHs047_2',\n",
       " 'CPX.CONV_ACOHs048_2',\n",
       " 'CPM.RejectWelding',\n",
       " 'CPPG.REJECTED',\n",
       " 'CPW.Soll_DMC',\n",
       " 'CPX.CONV_ACOHs049',\n",
       " 'CPX.CONV_ACOHs050',\n",
       " 'CPM.WeldLogfile_Nr']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_without_information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>CPW.Name</th>\n",
       "      <th>CPW.Linie</th>\n",
       "      <th>CPW.Timestamp</th>\n",
       "      <th>CPW.ANODE_FZLENGTH</th>\n",
       "      <th>CPW.ANODE_LENGTH</th>\n",
       "      <th>CPW.CATHODE_FZLENGTH_UPPER</th>\n",
       "      <th>CPW.CATHODE_LENGTH</th>\n",
       "      <th>CPW.DIAMTER_MAX</th>\n",
       "      <th>...</th>\n",
       "      <th>CPX.CONV_ACOHs043_2</th>\n",
       "      <th>CPX.CONV_ACOHs044_2</th>\n",
       "      <th>CPX.CONV_ACOHs045_2</th>\n",
       "      <th>CPX.CONV_ACOHs046_2</th>\n",
       "      <th>CPX.AI_ACOHs055</th>\n",
       "      <th>CPX.AI_ACOHs056</th>\n",
       "      <th>CPX.CONV_ACOHs045_1</th>\n",
       "      <th>CPX.CONV_ACOHs046_1</th>\n",
       "      <th>CPX.CONV_ACOHs047_1</th>\n",
       "      <th>CPX.CONV_ACOHs048_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CPMW26</td>\n",
       "      <td>710.0</td>\n",
       "      <td>2022-08-29 02:00:32</td>\n",
       "      <td>61.268271</td>\n",
       "      <td>350.282969</td>\n",
       "      <td>9.179729</td>\n",
       "      <td>302.502813</td>\n",
       "      <td>12.28662</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CPMW23</td>\n",
       "      <td>707.0</td>\n",
       "      <td>2022-08-20 12:42:20</td>\n",
       "      <td>57.259561</td>\n",
       "      <td>348.452969</td>\n",
       "      <td>10.880899</td>\n",
       "      <td>301.902344</td>\n",
       "      <td>12.26344</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>CPMW53</td>\n",
       "      <td>725.0</td>\n",
       "      <td>2022-08-31 16:23:37</td>\n",
       "      <td>58.295284</td>\n",
       "      <td>351.588750</td>\n",
       "      <td>10.690954</td>\n",
       "      <td>302.626719</td>\n",
       "      <td>12.29760</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>CPMW27</td>\n",
       "      <td>711.0</td>\n",
       "      <td>2022-10-11 17:54:46</td>\n",
       "      <td>62.750492</td>\n",
       "      <td>351.843710</td>\n",
       "      <td>10.240900</td>\n",
       "      <td>303.179531</td>\n",
       "      <td>12.22806</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>CPMW23</td>\n",
       "      <td>707.0</td>\n",
       "      <td>2022-08-24 22:20:35</td>\n",
       "      <td>57.823748</td>\n",
       "      <td>350.698770</td>\n",
       "      <td>10.889323</td>\n",
       "      <td>310.547188</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 457 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID CPW.Name  CPW.Linie       CPW.Timestamp  CPW.ANODE_FZLENGTH  \\\n",
       "0           0   1   CPMW26      710.0 2022-08-29 02:00:32           61.268271   \n",
       "1           1   2   CPMW23      707.0 2022-08-20 12:42:20           57.259561   \n",
       "2           2   3   CPMW53      725.0 2022-08-31 16:23:37           58.295284   \n",
       "3           3   4   CPMW27      711.0 2022-10-11 17:54:46           62.750492   \n",
       "4           4   5   CPMW23      707.0 2022-08-24 22:20:35           57.823748   \n",
       "\n",
       "   CPW.ANODE_LENGTH  CPW.CATHODE_FZLENGTH_UPPER  CPW.CATHODE_LENGTH  \\\n",
       "0        350.282969                    9.179729          302.502813   \n",
       "1        348.452969                   10.880899          301.902344   \n",
       "2        351.588750                   10.690954          302.626719   \n",
       "3        351.843710                   10.240900          303.179531   \n",
       "4        350.698770                   10.889323          310.547188   \n",
       "\n",
       "   CPW.DIAMTER_MAX  ...  CPX.CONV_ACOHs043_2  CPX.CONV_ACOHs044_2  \\\n",
       "0         12.28662  ...                  NaN                  NaN   \n",
       "1         12.26344  ...                  NaN                  NaN   \n",
       "2         12.29760  ...                  NaN                  NaN   \n",
       "3         12.22806  ...                  NaN                  NaN   \n",
       "4          0.00000  ...                  NaN                  NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs045_2  CPX.CONV_ACOHs046_2  CPX.AI_ACOHs055  CPX.AI_ACOHs056  \\\n",
       "0                  NaN                  NaN              NaN              NaN   \n",
       "1                  NaN                  NaN              NaN              NaN   \n",
       "2                  NaN                  NaN              NaN              NaN   \n",
       "3                  NaN                  NaN              NaN              NaN   \n",
       "4                  NaN                  NaN              NaN              NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs045_1  CPX.CONV_ACOHs046_1  CPX.CONV_ACOHs047_1  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs048_1  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "\n",
       "[5 rows x 457 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_only_information_gain.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually removing unnecessary and forbidden columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_columns = [\n",
    "        \"Unnamed: 0\", \n",
    "        \"ID\", \n",
    "        \"CPW.Linie\", \n",
    "        \"CPM.Linie\", \n",
    "        \"CPM.CellcodeGrade\", \n",
    "        \"CPM.Weld_Logfile_Nr\", \n",
    "        \"CPX.Linie\", \n",
    "        \"CPFORM.Filename\", \n",
    "        \"CPFORM.TestNumber\", \n",
    "        \"CPFORM.Reasoncode\", \n",
    "        \"CPFORM.Reasoncodename\", \n",
    "        \"CPX.TrayResult\"\n",
    "    ]\n",
    "\n",
    "not_allowed_columns = [\n",
    "        \"CPPG.SenderName\", \n",
    "        \"CPPG.SenderTimestamp\", \n",
    "        \"CPPG.Impedance_mOhm\", \n",
    "        \"CPPG.Height_mm\", \n",
    "        \"CPPG.U0_mV\", \n",
    "        \"CPPG.Cell Status\",\n",
    "        \"CPPG.STATUS_SPS\",\n",
    "        \"CPPG.STATUS_U0\",\n",
    "        \"CPPG.STATUS_HEIGHT\",\n",
    "        \"CPPG.STATUS_IMPEDANCE\",\n",
    "        \"CPPG.STATUS_FORMATION\"\n",
    "    ]\n",
    "\n",
    "df_removed_cols = df_only_information_gain.drop(unnecessary_columns + not_allowed_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPW.Name</th>\n",
       "      <th>CPW.Timestamp</th>\n",
       "      <th>CPW.ANODE_FZLENGTH</th>\n",
       "      <th>CPW.ANODE_LENGTH</th>\n",
       "      <th>CPW.CATHODE_FZLENGTH_UPPER</th>\n",
       "      <th>CPW.CATHODE_LENGTH</th>\n",
       "      <th>CPW.DIAMTER_MAX</th>\n",
       "      <th>CPW.DIAMTER_MIN</th>\n",
       "      <th>CPW.DIAMTER_AVERAGE</th>\n",
       "      <th>CPW.ANODETABPOSITION</th>\n",
       "      <th>...</th>\n",
       "      <th>CPX.CONV_ACOHs043_2</th>\n",
       "      <th>CPX.CONV_ACOHs044_2</th>\n",
       "      <th>CPX.CONV_ACOHs045_2</th>\n",
       "      <th>CPX.CONV_ACOHs046_2</th>\n",
       "      <th>CPX.AI_ACOHs055</th>\n",
       "      <th>CPX.AI_ACOHs056</th>\n",
       "      <th>CPX.CONV_ACOHs045_1</th>\n",
       "      <th>CPX.CONV_ACOHs046_1</th>\n",
       "      <th>CPX.CONV_ACOHs047_1</th>\n",
       "      <th>CPX.CONV_ACOHs048_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPMW26</td>\n",
       "      <td>2022-08-29 02:00:32</td>\n",
       "      <td>61.268271</td>\n",
       "      <td>350.282969</td>\n",
       "      <td>9.179729</td>\n",
       "      <td>302.502813</td>\n",
       "      <td>12.28662</td>\n",
       "      <td>12.03286</td>\n",
       "      <td>12.12436</td>\n",
       "      <td>91.861033</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPMW23</td>\n",
       "      <td>2022-08-20 12:42:20</td>\n",
       "      <td>57.259561</td>\n",
       "      <td>348.452969</td>\n",
       "      <td>10.880899</td>\n",
       "      <td>301.902344</td>\n",
       "      <td>12.26344</td>\n",
       "      <td>12.13656</td>\n",
       "      <td>12.20000</td>\n",
       "      <td>49.241435</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPMW53</td>\n",
       "      <td>2022-08-31 16:23:37</td>\n",
       "      <td>58.295284</td>\n",
       "      <td>351.588750</td>\n",
       "      <td>10.690954</td>\n",
       "      <td>302.626719</td>\n",
       "      <td>12.29760</td>\n",
       "      <td>12.04140</td>\n",
       "      <td>12.14632</td>\n",
       "      <td>120.583939</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPMW27</td>\n",
       "      <td>2022-10-11 17:54:46</td>\n",
       "      <td>62.750492</td>\n",
       "      <td>351.843710</td>\n",
       "      <td>10.240900</td>\n",
       "      <td>303.179531</td>\n",
       "      <td>12.22806</td>\n",
       "      <td>12.04628</td>\n",
       "      <td>12.11948</td>\n",
       "      <td>368.920286</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPMW23</td>\n",
       "      <td>2022-08-24 22:20:35</td>\n",
       "      <td>57.823748</td>\n",
       "      <td>350.698770</td>\n",
       "      <td>10.889323</td>\n",
       "      <td>310.547188</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>196.501964</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CPW.Name       CPW.Timestamp  CPW.ANODE_FZLENGTH  CPW.ANODE_LENGTH  \\\n",
       "0   CPMW26 2022-08-29 02:00:32           61.268271        350.282969   \n",
       "1   CPMW23 2022-08-20 12:42:20           57.259561        348.452969   \n",
       "2   CPMW53 2022-08-31 16:23:37           58.295284        351.588750   \n",
       "3   CPMW27 2022-10-11 17:54:46           62.750492        351.843710   \n",
       "4   CPMW23 2022-08-24 22:20:35           57.823748        350.698770   \n",
       "\n",
       "   CPW.CATHODE_FZLENGTH_UPPER  CPW.CATHODE_LENGTH  CPW.DIAMTER_MAX  \\\n",
       "0                    9.179729          302.502813         12.28662   \n",
       "1                   10.880899          301.902344         12.26344   \n",
       "2                   10.690954          302.626719         12.29760   \n",
       "3                   10.240900          303.179531         12.22806   \n",
       "4                   10.889323          310.547188          0.00000   \n",
       "\n",
       "   CPW.DIAMTER_MIN  CPW.DIAMTER_AVERAGE  CPW.ANODETABPOSITION  ...  \\\n",
       "0         12.03286             12.12436             91.861033  ...   \n",
       "1         12.13656             12.20000             49.241435  ...   \n",
       "2         12.04140             12.14632            120.583939  ...   \n",
       "3         12.04628             12.11948            368.920286  ...   \n",
       "4          0.00000              0.00000            196.501964  ...   \n",
       "\n",
       "   CPX.CONV_ACOHs043_2  CPX.CONV_ACOHs044_2  CPX.CONV_ACOHs045_2  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs046_2  CPX.AI_ACOHs055  CPX.AI_ACOHs056  CPX.CONV_ACOHs045_1  \\\n",
       "0                  NaN              NaN              NaN                  NaN   \n",
       "1                  NaN              NaN              NaN                  NaN   \n",
       "2                  NaN              NaN              NaN                  NaN   \n",
       "3                  NaN              NaN              NaN                  NaN   \n",
       "4                  NaN              NaN              NaN                  NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs046_1  CPX.CONV_ACOHs047_1  CPX.CONV_ACOHs048_1  \n",
       "0                  NaN                  NaN                  NaN  \n",
       "1                  NaN                  NaN                  NaN  \n",
       "2                  NaN                  NaN                  NaN  \n",
       "3                  NaN                  NaN                  NaN  \n",
       "4                  NaN                  NaN                  NaN  \n",
       "\n",
       "[5 rows x 434 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_removed_cols.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster the retests and save the information as bool/num variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ray_0_cols = [f\"CPX.AI_ACOHs00{i}\" if i < 10 else f\"CPX.AI_ACOHs0{i}\" for i in range(1, 53)] + [\n",
    "    \"CPX.AI_Result001\", \n",
    "    \"CPX.Tab_Overhang001\", \n",
    "    \"CPX.DIFF_Y1001\", \n",
    "    \"CPX.DIFF_Y2001\",\n",
    "    \"CPX.Failure_Code001\",\n",
    "    \"CPX.Name\",\n",
    "    \"CPX.Xray_Timestamp\",\n",
    "    \"CPX.Result\"\n",
    "]\n",
    "\n",
    "x_ray_1_cols = [f\"CPX.AI_ACOHs00{i}_1\" if i < 10 else f\"CPX.AI_ACOHs0{i}_1\" for i in range(1, 53)] + [\n",
    "    \"CPX.AI_Result001_1\", \n",
    "    \"CPX.Tab_Overhang001_1\", \n",
    "    \"CPX.DIFF_Y1001_1\", \n",
    "    \"CPX.DIFF_Y2001_1\",\n",
    "    \"CPX.Failure_Code001_1\",\n",
    "    \"CPX.Name_1\",\n",
    "    \"CPX.Xray_Timestamp_1\",\n",
    "    \"CPX.Result_1\"\n",
    "]\n",
    "\n",
    "x_ray_2_cols = [f\"CPX.AI_ACOHs00{i}_2\" if i < 10 else f\"CPX.AI_ACOHs0{i}_2\" for i in range(1, 53)] + [\n",
    "    \"CPX.AI_Result001_2\", \n",
    "    \"CPX.Tab_Overhang001_2\", \n",
    "    \"CPX.DIFF_Y1001_2\", \n",
    "    \"CPX.DIFF_Y2001_2\",\n",
    "    \"CPX.Failure_Code001_2\",\n",
    "    \"CPX.Name_2\",\n",
    "    \"CPX.Xray_Timestamp_2\",\n",
    "    \"CPX.Result_2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_ray_cluster = df_removed_cols.copy()\n",
    "retest_bool = []\n",
    "retest_num = []\n",
    "\n",
    "for index, row in df_removed_cols.iterrows():\n",
    "    for position, column in enumerate(x_ray_0_cols):\n",
    "        boolean = None\n",
    "        number = None\n",
    "        if not pd.isna(row[x_ray_2_cols[position]]):\n",
    "            df_x_ray_cluster.loc[index, column] = row[x_ray_2_cols[position]]  \n",
    "            boolean = True\n",
    "            number = 2\n",
    "        elif not pd.isna(row[x_ray_1_cols[position]]):\n",
    "            df_x_ray_cluster.loc[index, column] = row[x_ray_1_cols[position]]\n",
    "            boolean = True\n",
    "            number = 1\n",
    "        else:\n",
    "            boolean = False\n",
    "            number = 0\n",
    "    retest_bool.append(boolean)\n",
    "    retest_num.append(number)\n",
    "\n",
    "df_x_ray_cluster[\"CPX.Retest_Bool\"] = retest_bool\n",
    "df_x_ray_cluster[\"CPX.Retest_Num\"] = retest_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 120 columns (still some x ray cols included which will be removed based on feature importance)\n",
    "df_x_ray_cleaned = df_x_ray_cluster.drop(x_ray_1_cols + x_ray_2_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPX.Retest_Num\n",
       "0    981788\n",
       "1     18099\n",
       "2       113\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_ray_cleaned[\"CPX.Retest_Num\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPW.Name</th>\n",
       "      <th>CPW.Timestamp</th>\n",
       "      <th>CPW.ANODE_FZLENGTH</th>\n",
       "      <th>CPW.ANODE_LENGTH</th>\n",
       "      <th>CPW.CATHODE_FZLENGTH_UPPER</th>\n",
       "      <th>CPW.CATHODE_LENGTH</th>\n",
       "      <th>CPW.DIAMTER_MAX</th>\n",
       "      <th>CPW.DIAMTER_MIN</th>\n",
       "      <th>CPW.DIAMTER_AVERAGE</th>\n",
       "      <th>CPW.ANODETABPOSITION</th>\n",
       "      <th>...</th>\n",
       "      <th>CPX.CONV_ACOHs045_2</th>\n",
       "      <th>CPX.CONV_ACOHs046_2</th>\n",
       "      <th>CPX.AI_ACOHs055</th>\n",
       "      <th>CPX.AI_ACOHs056</th>\n",
       "      <th>CPX.CONV_ACOHs045_1</th>\n",
       "      <th>CPX.CONV_ACOHs046_1</th>\n",
       "      <th>CPX.CONV_ACOHs047_1</th>\n",
       "      <th>CPX.CONV_ACOHs048_1</th>\n",
       "      <th>CPX.Retest_Bool</th>\n",
       "      <th>CPX.Retest_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPMW26</td>\n",
       "      <td>2022-08-29 02:00:32</td>\n",
       "      <td>61.268271</td>\n",
       "      <td>350.282969</td>\n",
       "      <td>9.179729</td>\n",
       "      <td>302.502813</td>\n",
       "      <td>12.28662</td>\n",
       "      <td>12.03286</td>\n",
       "      <td>12.12436</td>\n",
       "      <td>91.861033</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPMW23</td>\n",
       "      <td>2022-08-20 12:42:20</td>\n",
       "      <td>57.259561</td>\n",
       "      <td>348.452969</td>\n",
       "      <td>10.880899</td>\n",
       "      <td>301.902344</td>\n",
       "      <td>12.26344</td>\n",
       "      <td>12.13656</td>\n",
       "      <td>12.20000</td>\n",
       "      <td>49.241435</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPMW53</td>\n",
       "      <td>2022-08-31 16:23:37</td>\n",
       "      <td>58.295284</td>\n",
       "      <td>351.588750</td>\n",
       "      <td>10.690954</td>\n",
       "      <td>302.626719</td>\n",
       "      <td>12.29760</td>\n",
       "      <td>12.04140</td>\n",
       "      <td>12.14632</td>\n",
       "      <td>120.583939</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPMW27</td>\n",
       "      <td>2022-10-11 17:54:46</td>\n",
       "      <td>62.750492</td>\n",
       "      <td>351.843710</td>\n",
       "      <td>10.240900</td>\n",
       "      <td>303.179531</td>\n",
       "      <td>12.22806</td>\n",
       "      <td>12.04628</td>\n",
       "      <td>12.11948</td>\n",
       "      <td>368.920286</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPMW23</td>\n",
       "      <td>2022-08-24 22:20:35</td>\n",
       "      <td>57.823748</td>\n",
       "      <td>350.698770</td>\n",
       "      <td>10.889323</td>\n",
       "      <td>310.547188</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>196.501964</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CPW.Name       CPW.Timestamp  CPW.ANODE_FZLENGTH  CPW.ANODE_LENGTH  \\\n",
       "0   CPMW26 2022-08-29 02:00:32           61.268271        350.282969   \n",
       "1   CPMW23 2022-08-20 12:42:20           57.259561        348.452969   \n",
       "2   CPMW53 2022-08-31 16:23:37           58.295284        351.588750   \n",
       "3   CPMW27 2022-10-11 17:54:46           62.750492        351.843710   \n",
       "4   CPMW23 2022-08-24 22:20:35           57.823748        350.698770   \n",
       "\n",
       "   CPW.CATHODE_FZLENGTH_UPPER  CPW.CATHODE_LENGTH  CPW.DIAMTER_MAX  \\\n",
       "0                    9.179729          302.502813         12.28662   \n",
       "1                   10.880899          301.902344         12.26344   \n",
       "2                   10.690954          302.626719         12.29760   \n",
       "3                   10.240900          303.179531         12.22806   \n",
       "4                   10.889323          310.547188          0.00000   \n",
       "\n",
       "   CPW.DIAMTER_MIN  CPW.DIAMTER_AVERAGE  CPW.ANODETABPOSITION  ...  \\\n",
       "0         12.03286             12.12436             91.861033  ...   \n",
       "1         12.13656             12.20000             49.241435  ...   \n",
       "2         12.04140             12.14632            120.583939  ...   \n",
       "3         12.04628             12.11948            368.920286  ...   \n",
       "4          0.00000              0.00000            196.501964  ...   \n",
       "\n",
       "   CPX.CONV_ACOHs045_2  CPX.CONV_ACOHs046_2  CPX.AI_ACOHs055  CPX.AI_ACOHs056  \\\n",
       "0                  NaN                  NaN              NaN              NaN   \n",
       "1                  NaN                  NaN              NaN              NaN   \n",
       "2                  NaN                  NaN              NaN              NaN   \n",
       "3                  NaN                  NaN              NaN              NaN   \n",
       "4                  NaN                  NaN              NaN              NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs045_1  CPX.CONV_ACOHs046_1  CPX.CONV_ACOHs047_1  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs048_1  CPX.Retest_Bool  CPX.Retest_Num  \n",
       "0                  NaN            False               0  \n",
       "1                  NaN            False               0  \n",
       "2                  NaN            False               0  \n",
       "3                  NaN            False               0  \n",
       "4                  NaN            False               0  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_ray_cleaned.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration aus Timestamps berechnen und originale Timestamps entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_x_ray_cluster[\"CPW.Duration\"] = \n",
    "cpw_duration = df_x_ray_cleaned[\"CPM.Timestamp\"]-df_x_ray_cleaned[\"CPW.Timestamp\"]\n",
    "cpw_duration = cpw_duration.dt.total_seconds()\n",
    "\n",
    "cpm_duration = df_x_ray_cleaned[\"CPX.Xray_Timestamp\"]-df_x_ray_cleaned[\"CPM.Timestamp\"]\n",
    "cpm_duration = cpm_duration.dt.total_seconds()\n",
    "\n",
    "df_x_ray_cleaned[\"CPW.Duration\"] = cpw_duration\n",
    "df_x_ray_cleaned[\"CPM.Duration\"] = cpm_duration\n",
    "\n",
    "df_prepared = df_x_ray_cleaned.drop([\"CPW.Timestamp\", \"CPM.Timestamp\", \"CPX.Xray_Timestamp\"], axis=1) # Remove unnecessary timestamps (other timestamps will be removed later as CPForm data will be removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPW.Name</th>\n",
       "      <th>CPW.ANODE_FZLENGTH</th>\n",
       "      <th>CPW.ANODE_LENGTH</th>\n",
       "      <th>CPW.CATHODE_FZLENGTH_UPPER</th>\n",
       "      <th>CPW.CATHODE_LENGTH</th>\n",
       "      <th>CPW.DIAMTER_MAX</th>\n",
       "      <th>CPW.DIAMTER_MIN</th>\n",
       "      <th>CPW.DIAMTER_AVERAGE</th>\n",
       "      <th>CPW.ANODETABPOSITION</th>\n",
       "      <th>CPW.CATHODETABPOSITION</th>\n",
       "      <th>...</th>\n",
       "      <th>CPX.AI_ACOHs055</th>\n",
       "      <th>CPX.AI_ACOHs056</th>\n",
       "      <th>CPX.CONV_ACOHs045_1</th>\n",
       "      <th>CPX.CONV_ACOHs046_1</th>\n",
       "      <th>CPX.CONV_ACOHs047_1</th>\n",
       "      <th>CPX.CONV_ACOHs048_1</th>\n",
       "      <th>CPX.Retest_Bool</th>\n",
       "      <th>CPX.Retest_Num</th>\n",
       "      <th>CPW.Duration</th>\n",
       "      <th>CPM.Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPMW26</td>\n",
       "      <td>61.268271</td>\n",
       "      <td>350.282969</td>\n",
       "      <td>9.179729</td>\n",
       "      <td>302.502813</td>\n",
       "      <td>12.28662</td>\n",
       "      <td>12.03286</td>\n",
       "      <td>12.12436</td>\n",
       "      <td>91.861033</td>\n",
       "      <td>1.173663</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>395044.0</td>\n",
       "      <td>33503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPMW23</td>\n",
       "      <td>57.259561</td>\n",
       "      <td>348.452969</td>\n",
       "      <td>10.880899</td>\n",
       "      <td>301.902344</td>\n",
       "      <td>12.26344</td>\n",
       "      <td>12.13656</td>\n",
       "      <td>12.20000</td>\n",
       "      <td>49.241435</td>\n",
       "      <td>402.458856</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>734387.0</td>\n",
       "      <td>2131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPMW53</td>\n",
       "      <td>58.295284</td>\n",
       "      <td>351.588750</td>\n",
       "      <td>10.690954</td>\n",
       "      <td>302.626719</td>\n",
       "      <td>12.29760</td>\n",
       "      <td>12.04140</td>\n",
       "      <td>12.14632</td>\n",
       "      <td>120.583939</td>\n",
       "      <td>53.235782</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>335387.0</td>\n",
       "      <td>19343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPMW27</td>\n",
       "      <td>62.750492</td>\n",
       "      <td>351.843710</td>\n",
       "      <td>10.240900</td>\n",
       "      <td>303.179531</td>\n",
       "      <td>12.22806</td>\n",
       "      <td>12.04628</td>\n",
       "      <td>12.11948</td>\n",
       "      <td>368.920286</td>\n",
       "      <td>268.658312</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>126924.0</td>\n",
       "      <td>32637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPMW23</td>\n",
       "      <td>57.823748</td>\n",
       "      <td>350.698770</td>\n",
       "      <td>10.889323</td>\n",
       "      <td>310.547188</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>196.501964</td>\n",
       "      <td>106.837010</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>476852.0</td>\n",
       "      <td>32222.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CPW.Name  CPW.ANODE_FZLENGTH  CPW.ANODE_LENGTH  CPW.CATHODE_FZLENGTH_UPPER  \\\n",
       "0   CPMW26           61.268271        350.282969                    9.179729   \n",
       "1   CPMW23           57.259561        348.452969                   10.880899   \n",
       "2   CPMW53           58.295284        351.588750                   10.690954   \n",
       "3   CPMW27           62.750492        351.843710                   10.240900   \n",
       "4   CPMW23           57.823748        350.698770                   10.889323   \n",
       "\n",
       "   CPW.CATHODE_LENGTH  CPW.DIAMTER_MAX  CPW.DIAMTER_MIN  CPW.DIAMTER_AVERAGE  \\\n",
       "0          302.502813         12.28662         12.03286             12.12436   \n",
       "1          301.902344         12.26344         12.13656             12.20000   \n",
       "2          302.626719         12.29760         12.04140             12.14632   \n",
       "3          303.179531         12.22806         12.04628             12.11948   \n",
       "4          310.547188          0.00000          0.00000              0.00000   \n",
       "\n",
       "   CPW.ANODETABPOSITION  CPW.CATHODETABPOSITION  ...  CPX.AI_ACOHs055  \\\n",
       "0             91.861033                1.173663  ...              NaN   \n",
       "1             49.241435              402.458856  ...              NaN   \n",
       "2            120.583939               53.235782  ...              NaN   \n",
       "3            368.920286              268.658312  ...              NaN   \n",
       "4            196.501964              106.837010  ...              NaN   \n",
       "\n",
       "   CPX.AI_ACOHs056  CPX.CONV_ACOHs045_1  CPX.CONV_ACOHs046_1  \\\n",
       "0              NaN                  NaN                  NaN   \n",
       "1              NaN                  NaN                  NaN   \n",
       "2              NaN                  NaN                  NaN   \n",
       "3              NaN                  NaN                  NaN   \n",
       "4              NaN                  NaN                  NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs047_1  CPX.CONV_ACOHs048_1  CPX.Retest_Bool  CPX.Retest_Num  \\\n",
       "0                  NaN                  NaN            False               0   \n",
       "1                  NaN                  NaN            False               0   \n",
       "2                  NaN                  NaN            False               0   \n",
       "3                  NaN                  NaN            False               0   \n",
       "4                  NaN                  NaN            False               0   \n",
       "\n",
       "   CPW.Duration  CPM.Duration  \n",
       "0      395044.0       33503.0  \n",
       "1      734387.0        2131.0  \n",
       "2      335387.0       19343.0  \n",
       "3      126924.0       32637.0  \n",
       "4      476852.0       32222.0  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepared.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the cp_form step values (12 Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_form_features = [\"CPFORM.SenderTimestamp\", \"CPFORM.StartTime\", \"CPFORM.Duration_s\", \"CPFORM.TrayXID\", \"CPFORM.TrayPosition\", \"CPFORM.QualityStatus\", \"CPFORM.Grade\", \"CPFORM.ChgCap_mAh_Cycle0/0\", \"CPFORM.DsgCap_mAh_Cycle0/0\", \"CPFORM.OCV1_mV\", \"CPFORM.OCV1_Timestamp\", \"CPFORM.Rack\"]\n",
    "\n",
    "df_no_cp_form = df_prepared.drop(cp_form_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPW.Name</th>\n",
       "      <th>CPW.ANODE_FZLENGTH</th>\n",
       "      <th>CPW.ANODE_LENGTH</th>\n",
       "      <th>CPW.CATHODE_FZLENGTH_UPPER</th>\n",
       "      <th>CPW.CATHODE_LENGTH</th>\n",
       "      <th>CPW.DIAMTER_MAX</th>\n",
       "      <th>CPW.DIAMTER_MIN</th>\n",
       "      <th>CPW.DIAMTER_AVERAGE</th>\n",
       "      <th>CPW.ANODETABPOSITION</th>\n",
       "      <th>CPW.CATHODETABPOSITION</th>\n",
       "      <th>...</th>\n",
       "      <th>CPX.AI_ACOHs055</th>\n",
       "      <th>CPX.AI_ACOHs056</th>\n",
       "      <th>CPX.CONV_ACOHs045_1</th>\n",
       "      <th>CPX.CONV_ACOHs046_1</th>\n",
       "      <th>CPX.CONV_ACOHs047_1</th>\n",
       "      <th>CPX.CONV_ACOHs048_1</th>\n",
       "      <th>CPX.Retest_Bool</th>\n",
       "      <th>CPX.Retest_Num</th>\n",
       "      <th>CPW.Duration</th>\n",
       "      <th>CPM.Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPMW26</td>\n",
       "      <td>61.268271</td>\n",
       "      <td>350.282969</td>\n",
       "      <td>9.179729</td>\n",
       "      <td>302.502813</td>\n",
       "      <td>12.28662</td>\n",
       "      <td>12.03286</td>\n",
       "      <td>12.12436</td>\n",
       "      <td>91.861033</td>\n",
       "      <td>1.173663</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>395044.0</td>\n",
       "      <td>33503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPMW23</td>\n",
       "      <td>57.259561</td>\n",
       "      <td>348.452969</td>\n",
       "      <td>10.880899</td>\n",
       "      <td>301.902344</td>\n",
       "      <td>12.26344</td>\n",
       "      <td>12.13656</td>\n",
       "      <td>12.20000</td>\n",
       "      <td>49.241435</td>\n",
       "      <td>402.458856</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>734387.0</td>\n",
       "      <td>2131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPMW53</td>\n",
       "      <td>58.295284</td>\n",
       "      <td>351.588750</td>\n",
       "      <td>10.690954</td>\n",
       "      <td>302.626719</td>\n",
       "      <td>12.29760</td>\n",
       "      <td>12.04140</td>\n",
       "      <td>12.14632</td>\n",
       "      <td>120.583939</td>\n",
       "      <td>53.235782</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>335387.0</td>\n",
       "      <td>19343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPMW27</td>\n",
       "      <td>62.750492</td>\n",
       "      <td>351.843710</td>\n",
       "      <td>10.240900</td>\n",
       "      <td>303.179531</td>\n",
       "      <td>12.22806</td>\n",
       "      <td>12.04628</td>\n",
       "      <td>12.11948</td>\n",
       "      <td>368.920286</td>\n",
       "      <td>268.658312</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>126924.0</td>\n",
       "      <td>32637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPMW23</td>\n",
       "      <td>57.823748</td>\n",
       "      <td>350.698770</td>\n",
       "      <td>10.889323</td>\n",
       "      <td>310.547188</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>196.501964</td>\n",
       "      <td>106.837010</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>476852.0</td>\n",
       "      <td>32222.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CPW.Name  CPW.ANODE_FZLENGTH  CPW.ANODE_LENGTH  CPW.CATHODE_FZLENGTH_UPPER  \\\n",
       "0   CPMW26           61.268271        350.282969                    9.179729   \n",
       "1   CPMW23           57.259561        348.452969                   10.880899   \n",
       "2   CPMW53           58.295284        351.588750                   10.690954   \n",
       "3   CPMW27           62.750492        351.843710                   10.240900   \n",
       "4   CPMW23           57.823748        350.698770                   10.889323   \n",
       "\n",
       "   CPW.CATHODE_LENGTH  CPW.DIAMTER_MAX  CPW.DIAMTER_MIN  CPW.DIAMTER_AVERAGE  \\\n",
       "0          302.502813         12.28662         12.03286             12.12436   \n",
       "1          301.902344         12.26344         12.13656             12.20000   \n",
       "2          302.626719         12.29760         12.04140             12.14632   \n",
       "3          303.179531         12.22806         12.04628             12.11948   \n",
       "4          310.547188          0.00000          0.00000              0.00000   \n",
       "\n",
       "   CPW.ANODETABPOSITION  CPW.CATHODETABPOSITION  ...  CPX.AI_ACOHs055  \\\n",
       "0             91.861033                1.173663  ...              NaN   \n",
       "1             49.241435              402.458856  ...              NaN   \n",
       "2            120.583939               53.235782  ...              NaN   \n",
       "3            368.920286              268.658312  ...              NaN   \n",
       "4            196.501964              106.837010  ...              NaN   \n",
       "\n",
       "   CPX.AI_ACOHs056  CPX.CONV_ACOHs045_1  CPX.CONV_ACOHs046_1  \\\n",
       "0              NaN                  NaN                  NaN   \n",
       "1              NaN                  NaN                  NaN   \n",
       "2              NaN                  NaN                  NaN   \n",
       "3              NaN                  NaN                  NaN   \n",
       "4              NaN                  NaN                  NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs047_1  CPX.CONV_ACOHs048_1  CPX.Retest_Bool  CPX.Retest_Num  \\\n",
       "0                  NaN                  NaN            False               0   \n",
       "1                  NaN                  NaN            False               0   \n",
       "2                  NaN                  NaN            False               0   \n",
       "3                  NaN                  NaN            False               0   \n",
       "4                  NaN                  NaN            False               0   \n",
       "\n",
       "   CPW.Duration  CPM.Duration  \n",
       "0      395044.0       33503.0  \n",
       "1      734387.0        2131.0  \n",
       "2      335387.0       19343.0  \n",
       "3      126924.0       32637.0  \n",
       "4      476852.0       32222.0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_cp_form.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the min an max value for each column, which includes error values\n",
    "# The idea is that each error value will be 0 after replacement + normalization so the \"error\" needs to be replaced \n",
    "# --> so this value will be replaced with the min value of the column - d * range of the column\n",
    "\n",
    "replacement_dict = {}\n",
    "\n",
    "for i in range(1, 49):\n",
    "    for j in range(3):\n",
    "        col_name = None\n",
    "        if (i == 47 or i == 48) and j == 2:\n",
    "            continue\n",
    "        if i < 10:\n",
    "            if j == 0:\n",
    "                col_name = f\"CPX.CONV_ACOHs00{i}\"\n",
    "            else:\n",
    "                col_name = f\"CPX.CONV_ACOHs00{i}_{j}\"\n",
    "        else:\n",
    "            if j == 0:\n",
    "                col_name = f\"CPX.CONV_ACOHs0{i}\"\n",
    "            else:\n",
    "                col_name = f\"CPX.CONV_ACOHs0{i}_{j}\"\n",
    "        column = df_no_cp_form[col_name]\n",
    "        column_no_error = column[~column.isin([\"error\"])].mean()\n",
    "        column = column.replace(\"error\", column_no_error.mean())\n",
    "        replacement_dict[col_name] = [column.min(), column.max()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually encode columns with mixed datatypes (f.e. floating values in object column --> no label encoding in raw form possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replaced = df_no_cp_form.copy()\n",
    "d = 0.1\n",
    "\n",
    "for i in range(1, 49):\n",
    "    for j in range(3):\n",
    "        col_name = None\n",
    "        if (i == 47 or i == 48) and j == 2:\n",
    "            continue\n",
    "        if i < 10:\n",
    "            if j == 0:\n",
    "                col_name = f\"CPX.CONV_ACOHs00{i}\"\n",
    "            else:\n",
    "                col_name = f\"CPX.CONV_ACOHs00{i}_{j}\"\n",
    "        else:\n",
    "            if j == 0:\n",
    "                col_name = f\"CPX.CONV_ACOHs0{i}\"\n",
    "            else:\n",
    "                col_name = f\"CPX.CONV_ACOHs0{i}_{j}\"\n",
    "        max_val = replacement_dict[col_name][1]\n",
    "        min_val = replacement_dict[col_name][0]\n",
    "        replacement_value = min_val - d * (max_val - min_val)\n",
    "        df_replaced[col_name] = df_no_cp_form[col_name].replace(\"error\", replacement_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode remaining values to categorical --> save classes in dict for possible decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPW.Name\n",
      "CPM.MaxTimeWT\n",
      "CPM.Name\n",
      "CPX.AI_Result001\n",
      "CPX.Name\n",
      "CPX.Result\n",
      "CPX.Linie_1\n",
      "CPX.TrayResult_1\n",
      "CPX.CONV_Result001\n",
      "CPX.Linie_2\n",
      "CPX.TrayResult_2\n"
     ]
    }
   ],
   "source": [
    "df_encoded = df_replaced.copy()\n",
    "encoding_dict = {}\n",
    "\n",
    "for index, val in enumerate(df_replaced.dtypes):\n",
    "    if val == \"object\" or val == \"datetime64[ns]\":\n",
    "        col_name = df_replaced.columns[index]\n",
    "        print(col_name)\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col_name] = le.fit_transform(df_replaced[col_name])\n",
    "        encoding_dict[col_name] = le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPW.Name</th>\n",
       "      <th>CPW.ANODE_FZLENGTH</th>\n",
       "      <th>CPW.ANODE_LENGTH</th>\n",
       "      <th>CPW.CATHODE_FZLENGTH_UPPER</th>\n",
       "      <th>CPW.CATHODE_LENGTH</th>\n",
       "      <th>CPW.DIAMTER_MAX</th>\n",
       "      <th>CPW.DIAMTER_MIN</th>\n",
       "      <th>CPW.DIAMTER_AVERAGE</th>\n",
       "      <th>CPW.ANODETABPOSITION</th>\n",
       "      <th>CPW.CATHODETABPOSITION</th>\n",
       "      <th>...</th>\n",
       "      <th>CPX.AI_ACOHs055</th>\n",
       "      <th>CPX.AI_ACOHs056</th>\n",
       "      <th>CPX.CONV_ACOHs045_1</th>\n",
       "      <th>CPX.CONV_ACOHs046_1</th>\n",
       "      <th>CPX.CONV_ACOHs047_1</th>\n",
       "      <th>CPX.CONV_ACOHs048_1</th>\n",
       "      <th>CPX.Retest_Bool</th>\n",
       "      <th>CPX.Retest_Num</th>\n",
       "      <th>CPW.Duration</th>\n",
       "      <th>CPM.Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>61.268271</td>\n",
       "      <td>350.282969</td>\n",
       "      <td>9.179729</td>\n",
       "      <td>302.502813</td>\n",
       "      <td>12.28662</td>\n",
       "      <td>12.03286</td>\n",
       "      <td>12.12436</td>\n",
       "      <td>91.861033</td>\n",
       "      <td>1.173663</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>395044.0</td>\n",
       "      <td>33503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>57.259561</td>\n",
       "      <td>348.452969</td>\n",
       "      <td>10.880899</td>\n",
       "      <td>301.902344</td>\n",
       "      <td>12.26344</td>\n",
       "      <td>12.13656</td>\n",
       "      <td>12.20000</td>\n",
       "      <td>49.241435</td>\n",
       "      <td>402.458856</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>734387.0</td>\n",
       "      <td>2131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>58.295284</td>\n",
       "      <td>351.588750</td>\n",
       "      <td>10.690954</td>\n",
       "      <td>302.626719</td>\n",
       "      <td>12.29760</td>\n",
       "      <td>12.04140</td>\n",
       "      <td>12.14632</td>\n",
       "      <td>120.583939</td>\n",
       "      <td>53.235782</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>335387.0</td>\n",
       "      <td>19343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>62.750492</td>\n",
       "      <td>351.843710</td>\n",
       "      <td>10.240900</td>\n",
       "      <td>303.179531</td>\n",
       "      <td>12.22806</td>\n",
       "      <td>12.04628</td>\n",
       "      <td>12.11948</td>\n",
       "      <td>368.920286</td>\n",
       "      <td>268.658312</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>126924.0</td>\n",
       "      <td>32637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>57.823748</td>\n",
       "      <td>350.698770</td>\n",
       "      <td>10.889323</td>\n",
       "      <td>310.547188</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>196.501964</td>\n",
       "      <td>106.837010</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>476852.0</td>\n",
       "      <td>32222.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CPW.Name  CPW.ANODE_FZLENGTH  CPW.ANODE_LENGTH  CPW.CATHODE_FZLENGTH_UPPER  \\\n",
       "0         5           61.268271        350.282969                    9.179729   \n",
       "1         2           57.259561        348.452969                   10.880899   \n",
       "2        16           58.295284        351.588750                   10.690954   \n",
       "3         6           62.750492        351.843710                   10.240900   \n",
       "4         2           57.823748        350.698770                   10.889323   \n",
       "\n",
       "   CPW.CATHODE_LENGTH  CPW.DIAMTER_MAX  CPW.DIAMTER_MIN  CPW.DIAMTER_AVERAGE  \\\n",
       "0          302.502813         12.28662         12.03286             12.12436   \n",
       "1          301.902344         12.26344         12.13656             12.20000   \n",
       "2          302.626719         12.29760         12.04140             12.14632   \n",
       "3          303.179531         12.22806         12.04628             12.11948   \n",
       "4          310.547188          0.00000          0.00000              0.00000   \n",
       "\n",
       "   CPW.ANODETABPOSITION  CPW.CATHODETABPOSITION  ...  CPX.AI_ACOHs055  \\\n",
       "0             91.861033                1.173663  ...              NaN   \n",
       "1             49.241435              402.458856  ...              NaN   \n",
       "2            120.583939               53.235782  ...              NaN   \n",
       "3            368.920286              268.658312  ...              NaN   \n",
       "4            196.501964              106.837010  ...              NaN   \n",
       "\n",
       "   CPX.AI_ACOHs056  CPX.CONV_ACOHs045_1  CPX.CONV_ACOHs046_1  \\\n",
       "0              NaN                  NaN                  NaN   \n",
       "1              NaN                  NaN                  NaN   \n",
       "2              NaN                  NaN                  NaN   \n",
       "3              NaN                  NaN                  NaN   \n",
       "4              NaN                  NaN                  NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs047_1  CPX.CONV_ACOHs048_1  CPX.Retest_Bool  CPX.Retest_Num  \\\n",
       "0                  NaN                  NaN            False               0   \n",
       "1                  NaN                  NaN            False               0   \n",
       "2                  NaN                  NaN            False               0   \n",
       "3                  NaN                  NaN            False               0   \n",
       "4                  NaN                  NaN            False               0   \n",
       "\n",
       "   CPW.Duration  CPM.Duration  \n",
       "0      395044.0       33503.0  \n",
       "1      734387.0        2131.0  \n",
       "2      335387.0       19343.0  \n",
       "3      126924.0       32637.0  \n",
       "4      476852.0       32222.0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min Max Normalization for each column --> save min and max value for each column befor normalization for possible decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_dict = {}\n",
    "\n",
    "for index, name in enumerate(df_encoded.columns):\n",
    "    normalization_dict[name] = [df_encoded[name].min(), df_encoded[name].max()]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = df_encoded.apply(lambda column: pd.Series(scaler.fit_transform(column.values.reshape(-1, 1)).flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPW.Name</th>\n",
       "      <th>CPW.ANODE_FZLENGTH</th>\n",
       "      <th>CPW.ANODE_LENGTH</th>\n",
       "      <th>CPW.CATHODE_FZLENGTH_UPPER</th>\n",
       "      <th>CPW.CATHODE_LENGTH</th>\n",
       "      <th>CPW.DIAMTER_MAX</th>\n",
       "      <th>CPW.DIAMTER_MIN</th>\n",
       "      <th>CPW.DIAMTER_AVERAGE</th>\n",
       "      <th>CPW.ANODETABPOSITION</th>\n",
       "      <th>CPW.CATHODETABPOSITION</th>\n",
       "      <th>...</th>\n",
       "      <th>CPX.AI_ACOHs055</th>\n",
       "      <th>CPX.AI_ACOHs056</th>\n",
       "      <th>CPX.CONV_ACOHs045_1</th>\n",
       "      <th>CPX.CONV_ACOHs046_1</th>\n",
       "      <th>CPX.CONV_ACOHs047_1</th>\n",
       "      <th>CPX.CONV_ACOHs048_1</th>\n",
       "      <th>CPX.Retest_Bool</th>\n",
       "      <th>CPX.Retest_Num</th>\n",
       "      <th>CPW.Duration</th>\n",
       "      <th>CPM.Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.301151</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.686540</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>0.977767</td>\n",
       "      <td>0.981295</td>\n",
       "      <td>0.984448</td>\n",
       "      <td>0.209158</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118489</td>\n",
       "      <td>0.007054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.285979</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.813174</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.975922</td>\n",
       "      <td>0.989752</td>\n",
       "      <td>0.990589</td>\n",
       "      <td>0.112118</td>\n",
       "      <td>0.916349</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220644</td>\n",
       "      <td>0.004977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.289899</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.799034</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0.978641</td>\n",
       "      <td>0.981992</td>\n",
       "      <td>0.986231</td>\n",
       "      <td>0.274556</td>\n",
       "      <td>0.121213</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100530</td>\n",
       "      <td>0.006116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.306761</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.765533</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.973107</td>\n",
       "      <td>0.982390</td>\n",
       "      <td>0.984051</td>\n",
       "      <td>0.839987</td>\n",
       "      <td>0.611703</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037775</td>\n",
       "      <td>0.006997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.288114</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>0.813801</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447412</td>\n",
       "      <td>0.243256</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143117</td>\n",
       "      <td>0.006969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CPW.Name  CPW.ANODE_FZLENGTH  CPW.ANODE_LENGTH  CPW.CATHODE_FZLENGTH_UPPER  \\\n",
       "0  0.192308            0.301151          0.003236                    0.686540   \n",
       "1  0.076923            0.285979          0.003219                    0.813174   \n",
       "2  0.615385            0.289899          0.003248                    0.799034   \n",
       "3  0.230769            0.306761          0.003250                    0.765533   \n",
       "4  0.076923            0.288114          0.003240                    0.813801   \n",
       "\n",
       "   CPW.CATHODE_LENGTH  CPW.DIAMTER_MAX  CPW.DIAMTER_MIN  CPW.DIAMTER_AVERAGE  \\\n",
       "0            0.006666         0.977767         0.981295             0.984448   \n",
       "1            0.006653         0.975922         0.989752             0.990589   \n",
       "2            0.006668         0.978641         0.981992             0.986231   \n",
       "3            0.006681         0.973107         0.982390             0.984051   \n",
       "4            0.006843         0.000000         0.000000             0.000000   \n",
       "\n",
       "   CPW.ANODETABPOSITION  CPW.CATHODETABPOSITION  ...  CPX.AI_ACOHs055  \\\n",
       "0              0.209158                0.002674  ...              NaN   \n",
       "1              0.112118                0.916349  ...              NaN   \n",
       "2              0.274556                0.121213  ...              NaN   \n",
       "3              0.839987                0.611703  ...              NaN   \n",
       "4              0.447412                0.243256  ...              NaN   \n",
       "\n",
       "   CPX.AI_ACOHs056  CPX.CONV_ACOHs045_1  CPX.CONV_ACOHs046_1  \\\n",
       "0              NaN                  NaN                  NaN   \n",
       "1              NaN                  NaN                  NaN   \n",
       "2              NaN                  NaN                  NaN   \n",
       "3              NaN                  NaN                  NaN   \n",
       "4              NaN                  NaN                  NaN   \n",
       "\n",
       "   CPX.CONV_ACOHs047_1  CPX.CONV_ACOHs048_1  CPX.Retest_Bool  CPX.Retest_Num  \\\n",
       "0                  NaN                  NaN              0.0             0.0   \n",
       "1                  NaN                  NaN              0.0             0.0   \n",
       "2                  NaN                  NaN              0.0             0.0   \n",
       "3                  NaN                  NaN              0.0             0.0   \n",
       "4                  NaN                  NaN              0.0             0.0   \n",
       "\n",
       "   CPW.Duration  CPM.Duration  \n",
       "0      0.118489      0.007054  \n",
       "1      0.220644      0.004977  \n",
       "2      0.100530      0.006116  \n",
       "3      0.037775      0.006997  \n",
       "4      0.143117      0.006969  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove N/A values --> Categorical data with modus / Numerical Data with mean (Categorical values are all stored in the encoding dict; manual encoding was all on numerical values)\n",
    "\n",
    "--> After checking the values, there is no missing value for the categorical data, so only the missing numerical values will be calculated (can be checked with code below but takes 30min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col_idx, column in enumerate(df_scaled.columns):\n",
    "#     for row_idx, cell in enumerate(df_scaled[column]):\n",
    "#         if pd.isna(df_scaled.loc[row_idx, column]):\n",
    "#             if column in encoding_dict.keys():\n",
    "#                 print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df_scaled.copy()\n",
    "\n",
    "for column in final_df.columns:\n",
    "    mean_value = final_df[column].mean()\n",
    "    final_df[column] = final_df[column].fillna(mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no N/A is remaining\n",
    "for val in final_df.isna().sum():\n",
    "    if val != 0:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPW.Name</th>\n",
       "      <th>CPW.ANODE_FZLENGTH</th>\n",
       "      <th>CPW.ANODE_LENGTH</th>\n",
       "      <th>CPW.CATHODE_FZLENGTH_UPPER</th>\n",
       "      <th>CPW.CATHODE_LENGTH</th>\n",
       "      <th>CPW.DIAMTER_MAX</th>\n",
       "      <th>CPW.DIAMTER_MIN</th>\n",
       "      <th>CPW.DIAMTER_AVERAGE</th>\n",
       "      <th>CPW.ANODETABPOSITION</th>\n",
       "      <th>CPW.CATHODETABPOSITION</th>\n",
       "      <th>...</th>\n",
       "      <th>CPX.AI_ACOHs055</th>\n",
       "      <th>CPX.AI_ACOHs056</th>\n",
       "      <th>CPX.CONV_ACOHs045_1</th>\n",
       "      <th>CPX.CONV_ACOHs046_1</th>\n",
       "      <th>CPX.CONV_ACOHs047_1</th>\n",
       "      <th>CPX.CONV_ACOHs048_1</th>\n",
       "      <th>CPX.Retest_Bool</th>\n",
       "      <th>CPX.Retest_Num</th>\n",
       "      <th>CPW.Duration</th>\n",
       "      <th>CPM.Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.301151</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.686540</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>0.977767</td>\n",
       "      <td>0.981295</td>\n",
       "      <td>0.984448</td>\n",
       "      <td>0.209158</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346099</td>\n",
       "      <td>0.323453</td>\n",
       "      <td>0.407145</td>\n",
       "      <td>0.53664</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118489</td>\n",
       "      <td>0.007054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.285979</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.813174</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.975922</td>\n",
       "      <td>0.989752</td>\n",
       "      <td>0.990589</td>\n",
       "      <td>0.112118</td>\n",
       "      <td>0.916349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346099</td>\n",
       "      <td>0.323453</td>\n",
       "      <td>0.407145</td>\n",
       "      <td>0.53664</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220644</td>\n",
       "      <td>0.004977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.289899</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.799034</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0.978641</td>\n",
       "      <td>0.981992</td>\n",
       "      <td>0.986231</td>\n",
       "      <td>0.274556</td>\n",
       "      <td>0.121213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346099</td>\n",
       "      <td>0.323453</td>\n",
       "      <td>0.407145</td>\n",
       "      <td>0.53664</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100530</td>\n",
       "      <td>0.006116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.306761</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.765533</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.973107</td>\n",
       "      <td>0.982390</td>\n",
       "      <td>0.984051</td>\n",
       "      <td>0.839987</td>\n",
       "      <td>0.611703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346099</td>\n",
       "      <td>0.323453</td>\n",
       "      <td>0.407145</td>\n",
       "      <td>0.53664</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037775</td>\n",
       "      <td>0.006997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.288114</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>0.813801</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447412</td>\n",
       "      <td>0.243256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346099</td>\n",
       "      <td>0.323453</td>\n",
       "      <td>0.407145</td>\n",
       "      <td>0.53664</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143117</td>\n",
       "      <td>0.006969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CPW.Name  CPW.ANODE_FZLENGTH  CPW.ANODE_LENGTH  CPW.CATHODE_FZLENGTH_UPPER  \\\n",
       "0  0.192308            0.301151          0.003236                    0.686540   \n",
       "1  0.076923            0.285979          0.003219                    0.813174   \n",
       "2  0.615385            0.289899          0.003248                    0.799034   \n",
       "3  0.230769            0.306761          0.003250                    0.765533   \n",
       "4  0.076923            0.288114          0.003240                    0.813801   \n",
       "\n",
       "   CPW.CATHODE_LENGTH  CPW.DIAMTER_MAX  CPW.DIAMTER_MIN  CPW.DIAMTER_AVERAGE  \\\n",
       "0            0.006666         0.977767         0.981295             0.984448   \n",
       "1            0.006653         0.975922         0.989752             0.990589   \n",
       "2            0.006668         0.978641         0.981992             0.986231   \n",
       "3            0.006681         0.973107         0.982390             0.984051   \n",
       "4            0.006843         0.000000         0.000000             0.000000   \n",
       "\n",
       "   CPW.ANODETABPOSITION  CPW.CATHODETABPOSITION  ...  CPX.AI_ACOHs055  \\\n",
       "0              0.209158                0.002674  ...         0.346099   \n",
       "1              0.112118                0.916349  ...         0.346099   \n",
       "2              0.274556                0.121213  ...         0.346099   \n",
       "3              0.839987                0.611703  ...         0.346099   \n",
       "4              0.447412                0.243256  ...         0.346099   \n",
       "\n",
       "   CPX.AI_ACOHs056  CPX.CONV_ACOHs045_1  CPX.CONV_ACOHs046_1  \\\n",
       "0         0.323453             0.407145              0.53664   \n",
       "1         0.323453             0.407145              0.53664   \n",
       "2         0.323453             0.407145              0.53664   \n",
       "3         0.323453             0.407145              0.53664   \n",
       "4         0.323453             0.407145              0.53664   \n",
       "\n",
       "   CPX.CONV_ACOHs047_1  CPX.CONV_ACOHs048_1  CPX.Retest_Bool  CPX.Retest_Num  \\\n",
       "0                  0.5                  0.0              0.0             0.0   \n",
       "1                  0.5                  0.0              0.0             0.0   \n",
       "2                  0.5                  0.0              0.0             0.0   \n",
       "3                  0.5                  0.0              0.0             0.0   \n",
       "4                  0.5                  0.0              0.0             0.0   \n",
       "\n",
       "   CPW.Duration  CPM.Duration  \n",
       "0      0.118489      0.007054  \n",
       "1      0.220644      0.004977  \n",
       "2      0.100530      0.006116  \n",
       "3      0.037775      0.006997  \n",
       "4      0.143117      0.006969  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"final_df.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(final_df, f)\n",
    "\n",
    "# with open(\"initial_df.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(df, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------- LABELS ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPPG.STATUS_SPS</th>\n",
       "      <th>CPPG.STATUS_U0</th>\n",
       "      <th>CPPG.STATUS_HEIGHT</th>\n",
       "      <th>CPPG.STATUS_IMPEDANCE</th>\n",
       "      <th>CPPG.STATUS_FORMATION</th>\n",
       "      <th>CPPG.STATUS_MODUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CPPG.STATUS_SPS CPPG.STATUS_U0 CPPG.STATUS_HEIGHT CPPG.STATUS_IMPEDANCE  \\\n",
       "0            PASS           PASS               PASS                  PASS   \n",
       "1            PASS           PASS               PASS                  PASS   \n",
       "2            PASS           PASS               PASS                  PASS   \n",
       "3            PASS           PASS               PASS                  PASS   \n",
       "4            PASS           PASS               PASS                  PASS   \n",
       "\n",
       "  CPPG.STATUS_FORMATION CPPG.STATUS_MODUL  \n",
       "0                  PASS               NaN  \n",
       "1                   NaN              PASS  \n",
       "2                   NaN              PASS  \n",
       "3                  PASS               NaN  \n",
       "4                  PASS               NaN  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cppg_df = df[LABEL_COLS]\n",
    "cppg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPPG.STATUS_SPS\n",
      "PASS              973404\n",
      "IMPEDANCE_FAIL     12876\n",
      "VOLTAGE_FAIL        8392\n",
      "U0_FAIL             2560\n",
      "FORMATION_FAIL      1507\n",
      "HEIGHT_FAIL         1201\n",
      "NO CELL               51\n",
      "_FAIL                  9\n",
      "Name: count, dtype: int64\n",
      "CPPG.STATUS_U0\n",
      "PASS       987590\n",
      "FAIL        12359\n",
      "NO CELL        51\n",
      "Name: count, dtype: int64\n",
      "CPPG.STATUS_HEIGHT\n",
      "PASS       998619\n",
      "FAIL         1330\n",
      "NO CELL        51\n",
      "Name: count, dtype: int64\n",
      "CPPG.STATUS_IMPEDANCE\n",
      "PASS       985586\n",
      "FAIL        14363\n",
      "NO CELL        51\n",
      "Name: count, dtype: int64\n",
      "CPPG.STATUS_FORMATION\n",
      "PASS       400555\n",
      "FAIL         1507\n",
      "NO CELL        51\n",
      "Name: count, dtype: int64\n",
      "CPPG.STATUS_MODUL\n",
      "PASS    597887\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in cppg_df.columns:\n",
    "    print(cppg_df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column in cppg_df.columns:\n",
    "    plt.figure()\n",
    "    cppg_df[column].value_counts().plot.bar()\n",
    "    plt.title(f'{column} Value Counts')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: zuerst prÃ¼fen ob Classification Binary mÃ¶glich, dann multi-class (different Failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check here, whether other Fail Values are in DF\n",
    "y = []\n",
    "\n",
    "contains_failure = cppg_df.isin([\"FAIL\"]).any(axis=1)\n",
    "\n",
    "for item in contains_failure:\n",
    "    if item:\n",
    "        y.append(\"FAIL\")\n",
    "    else:\n",
    "        y.append(\"PASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"labels_clustered.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(y, f)\n",
    "\n",
    "# with open(\"labels.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(cppg_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_df.pickle\", \"rb\") as f:\n",
    "    final_df = pickle.load(f)\n",
    "\n",
    "with open(\"labels.pickle\", \"rb\") as f:\n",
    "    y = pickle.load(f)\n",
    "\n",
    "with open(\"labels_clustered.pickle\", \"rb\") as f:\n",
    "    y_clustered = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS    973464\n",
      "FAIL     26536\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_clustered)\n",
    "\n",
    "value_distribution = pd.DataFrame([le.classes_[line] for line in y_encoded])\n",
    "print(value_distribution.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_one_hot = to_categorical(y_encoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling values for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "\n",
    "x_resampled, y_resampled = rus.fit_resample(final_df, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_resampled = to_categorical(y_resampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Models Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_models():\n",
    "    return [\n",
    "        ('Decision Tree', DecisionTreeClassifier(random_state=RANDOM_STATE)),\n",
    "        ('Random Forest', RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    "        ('Extremely Randomized Trees', ExtraTreesClassifier(random_state=RANDOM_STATE)),\n",
    "        ('Ada Boost', AdaBoostClassifier(random_state=RANDOM_STATE)),\n",
    "        ('Gradient Boosting', GradientBoostingClassifier(random_state=RANDOM_STATE)),\n",
    "        ('Support Vector Machine', SVC(random_state=RANDOM_STATE)),\n",
    "        ('Multilayer Perceptron', MLPClassifier(random_state=RANDOM_STATE)),\n",
    "        ('Naive Bayes', GaussianNB()),\n",
    "        # ('KNN', KNeighborsClassifier())\n",
    "    ]\n",
    "\n",
    "scorings = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'f1_score': make_scorer(f1_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [44:10<24:12, 726.27s/it]c:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [47:52<00:00, 359.12s/it]\n"
     ]
    }
   ],
   "source": [
    "all_cv_scores = []\n",
    "\n",
    "for classifier_name, classifier in tqdm(all_models()):\n",
    "    formatted_result = {}\n",
    "    formatted_result['Classifier'] = classifier_name\n",
    "\n",
    "    cv_score = cross_validate(estimator=classifier, X=x_resampled, y=y_resampled, scoring=scorings)\n",
    "\n",
    "    for score_name, scores in cv_score.items():\n",
    "        formatted_result[f'{score_name}_mean'] = np.mean(scores)\n",
    "        formatted_result[f'{score_name}_std'] = np.std(scores)\n",
    "\n",
    "    all_cv_scores.append(formatted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>test_accuracy_mean</th>\n",
       "      <th>test_accuracy_std</th>\n",
       "      <th>test_balanced_accuracy_mean</th>\n",
       "      <th>test_balanced_accuracy_std</th>\n",
       "      <th>test_f1_score_mean</th>\n",
       "      <th>test_f1_score_std</th>\n",
       "      <th>test_mcc_mean</th>\n",
       "      <th>test_mcc_std</th>\n",
       "      <th>test_precision_mean</th>\n",
       "      <th>test_precision_std</th>\n",
       "      <th>test_recall_mean</th>\n",
       "      <th>test_recall_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>8.326296</td>\n",
       "      <td>0.164635</td>\n",
       "      <td>0.026807</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.643371</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.643372</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.642428</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.286777</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.644180</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.640752</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>37.364999</td>\n",
       "      <td>0.088898</td>\n",
       "      <td>0.201645</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.731478</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.731478</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.727898</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.463144</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.737793</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.718307</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extremely Randomized Trees</td>\n",
       "      <td>13.962944</td>\n",
       "      <td>0.094414</td>\n",
       "      <td>0.276862</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>0.727936</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.727936</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.727555</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.010377</td>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.726523</td>\n",
       "      <td>0.004680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>28.227951</td>\n",
       "      <td>0.252147</td>\n",
       "      <td>0.387487</td>\n",
       "      <td>0.009954</td>\n",
       "      <td>0.715537</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.715537</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.713480</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.431120</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.718677</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.708358</td>\n",
       "      <td>0.004332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>144.577302</td>\n",
       "      <td>1.635258</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.723809</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.723809</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.716517</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.448223</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.735947</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.698108</td>\n",
       "      <td>0.005284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>245.712112</td>\n",
       "      <td>0.995928</td>\n",
       "      <td>50.914860</td>\n",
       "      <td>0.071796</td>\n",
       "      <td>0.693643</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.693643</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.679901</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.009139</td>\n",
       "      <td>0.711849</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>0.650777</td>\n",
       "      <td>0.008879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>44.139722</td>\n",
       "      <td>11.553525</td>\n",
       "      <td>0.037208</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.698071</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.698071</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.711023</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.398341</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.743218</td>\n",
       "      <td>0.023813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.267060</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.063414</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.521801</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.521801</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.675157</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.132380</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.511214</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.993895</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Classifier  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "0               Decision Tree       8.326296      0.164635         0.026807   \n",
       "1               Random Forest      37.364999      0.088898         0.201645   \n",
       "2  Extremely Randomized Trees      13.962944      0.094414         0.276862   \n",
       "3                   Ada Boost      28.227951      0.252147         0.387487   \n",
       "4           Gradient Boosting     144.577302      1.635258         0.042810   \n",
       "5      Support Vector Machine     245.712112      0.995928        50.914860   \n",
       "6       Multilayer Perceptron      44.139722     11.553525         0.037208   \n",
       "7                 Naive Bayes       0.267060      0.014659         0.063414   \n",
       "\n",
       "   score_time_std  test_accuracy_mean  test_accuracy_std  \\\n",
       "0        0.000980            0.643371           0.002257   \n",
       "1        0.000800            0.731478           0.004971   \n",
       "2        0.006243            0.727936           0.005188   \n",
       "3        0.009954            0.715537           0.004136   \n",
       "4        0.004119            0.723809           0.003254   \n",
       "5        0.071796            0.693643           0.004563   \n",
       "6        0.003488            0.698071           0.006902   \n",
       "7        0.003323            0.521801           0.000985   \n",
       "\n",
       "   test_balanced_accuracy_mean  test_balanced_accuracy_std  \\\n",
       "0                     0.643372                    0.002257   \n",
       "1                     0.731478                    0.004971   \n",
       "2                     0.727936                    0.005188   \n",
       "3                     0.715537                    0.004136   \n",
       "4                     0.723809                    0.003255   \n",
       "5                     0.693643                    0.004562   \n",
       "6                     0.698071                    0.006902   \n",
       "7                     0.521801                    0.001001   \n",
       "\n",
       "   test_f1_score_mean  test_f1_score_std  test_mcc_mean  test_mcc_std  \\\n",
       "0            0.642428           0.001805       0.286777      0.004537   \n",
       "1            0.727898           0.004593       0.463144      0.009978   \n",
       "2            0.727555           0.004881       0.455882      0.010377   \n",
       "3            0.713480           0.004214       0.431120      0.008271   \n",
       "4            0.716517           0.003677       0.448223      0.006486   \n",
       "5            0.679901           0.005506       0.388759      0.009139   \n",
       "6            0.711023           0.006081       0.398341      0.012110   \n",
       "7            0.675157           0.000559       0.132380      0.005102   \n",
       "\n",
       "   test_precision_mean  test_precision_std  test_recall_mean  test_recall_std  \n",
       "0             0.644180            0.004076          0.640752         0.005731  \n",
       "1             0.737793            0.006616          0.718307         0.005435  \n",
       "2             0.728605            0.005983          0.726523         0.004680  \n",
       "3             0.718677            0.004190          0.708358         0.004332  \n",
       "4             0.735947            0.003632          0.698108         0.005284  \n",
       "5             0.711849            0.005853          0.650777         0.008879  \n",
       "6             0.682315            0.013476          0.743218         0.023813  \n",
       "7             0.511214            0.000506          0.993895         0.001029  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_cv_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Accuracy Mean: Random Forest 73,15%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot Checking with previously removed imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "all_cv_scores_without_imbalance = []\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "x_over, y_over = oversampler.fit_resample(X=df_no_na, y=le.fit_transform(y))\n",
    "\n",
    "for classifier_name, classifier in tqdm(all_models()):\n",
    "    formatted_result_over = {}\n",
    "    formatted_result_over['Classifier'] = classifier_name\n",
    "\n",
    "    cv_score = cross_validate(estimator=classifier, X=x_over, y=y_over, scoring=scorings)\n",
    "\n",
    "    for score_name, scores in cv_score.items():\n",
    "        formatted_result_over[f'{score_name}_mean'] = np.mean(scores)\n",
    "        formatted_result_over[f'{score_name}_std'] = np.std(scores)\n",
    "\n",
    "    all_cv_scores_without_imbalance.append(formatted_result_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>test_accuracy_mean</th>\n",
       "      <th>test_accuracy_std</th>\n",
       "      <th>test_balanced_accuracy_mean</th>\n",
       "      <th>test_balanced_accuracy_std</th>\n",
       "      <th>test_f1_score_mean</th>\n",
       "      <th>test_f1_score_std</th>\n",
       "      <th>test_mcc_mean</th>\n",
       "      <th>test_mcc_std</th>\n",
       "      <th>test_precision_mean</th>\n",
       "      <th>test_precision_std</th>\n",
       "      <th>test_recall_mean</th>\n",
       "      <th>test_recall_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.995892</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.995866</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.991829</td>\n",
       "      <td>0.006093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991784</td>\n",
       "      <td>0.006149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.112172</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.009962</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.998972</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.998972</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.997949</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997949</td>\n",
       "      <td>0.002512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extremely Randomized Trees</td>\n",
       "      <td>0.080817</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>0.079149</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.995375</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.995374</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.995343</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990748</td>\n",
       "      <td>0.005993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.223380</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.995374</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.995371</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.995335</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990743</td>\n",
       "      <td>0.007566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.052081</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.037913</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.560641</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.560653</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.691683</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.230188</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.532810</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.985615</td>\n",
       "      <td>0.005041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>0.062324</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.608409</td>\n",
       "      <td>0.044981</td>\n",
       "      <td>0.608388</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.583019</td>\n",
       "      <td>0.182454</td>\n",
       "      <td>0.279745</td>\n",
       "      <td>0.118470</td>\n",
       "      <td>0.607535</td>\n",
       "      <td>0.024857</td>\n",
       "      <td>0.680185</td>\n",
       "      <td>0.348492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.504112</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.504116</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.016255</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.061013</td>\n",
       "      <td>0.020590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.006194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.014380</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.944498</td>\n",
       "      <td>0.020993</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.020995</td>\n",
       "      <td>0.943279</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.892480</td>\n",
       "      <td>0.042413</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>0.048309</td>\n",
       "      <td>0.914692</td>\n",
       "      <td>0.018328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Classifier  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "0               Decision Tree       0.003702      0.000748         0.003200   \n",
       "1               Random Forest       0.112172      0.001289         0.009962   \n",
       "2  Extremely Randomized Trees       0.080817      0.002773         0.011203   \n",
       "3                   Ada Boost       0.079149      0.000696         0.007608   \n",
       "4           Gradient Boosting       0.223380      0.001430         0.002939   \n",
       "5      Support Vector Machine       0.052081      0.001980         0.037913   \n",
       "6       Multilayer Perceptron       0.062324      0.004194         0.003198   \n",
       "7                 Naive Bayes       0.001600      0.000490         0.002800   \n",
       "8                         KNN       0.001800      0.000400         0.014380   \n",
       "\n",
       "   score_time_std  test_accuracy_mean  test_accuracy_std  \\\n",
       "0        0.000401            0.995888           0.003085   \n",
       "1        0.000083            0.998972           0.001259   \n",
       "2        0.000980            1.000000           0.000000   \n",
       "3        0.000487            0.995375           0.002997   \n",
       "4        0.000123            0.995374           0.003779   \n",
       "5        0.002800            0.560641           0.007405   \n",
       "6        0.000402            0.608409           0.044981   \n",
       "7        0.000400            0.504112           0.003848   \n",
       "8        0.000512            0.944498           0.020993   \n",
       "\n",
       "   test_balanced_accuracy_mean  test_balanced_accuracy_std  \\\n",
       "0                     0.995892                    0.003074   \n",
       "1                     0.998974                    0.001256   \n",
       "2                     1.000000                    0.000000   \n",
       "3                     0.995374                    0.002997   \n",
       "4                     0.995371                    0.003783   \n",
       "5                     0.560653                    0.006770   \n",
       "6                     0.608388                    0.044990   \n",
       "7                     0.504116                    0.003097   \n",
       "8                     0.944526                    0.020995   \n",
       "\n",
       "   test_f1_score_mean  test_f1_score_std  test_mcc_mean  test_mcc_std  \\\n",
       "0            0.995866           0.003114       0.991829      0.006093   \n",
       "1            0.998972           0.001259       0.997949      0.002512   \n",
       "2            1.000000           0.000000       1.000000      0.000000   \n",
       "3            0.995343           0.003021       0.990811      0.005947   \n",
       "4            0.995335           0.003823       0.990818      0.007480   \n",
       "5            0.691683           0.004281       0.230188      0.019414   \n",
       "6            0.583019           0.182454       0.279745      0.118470   \n",
       "7            0.016255           0.012075       0.061013      0.020590   \n",
       "8            0.943279           0.019389       0.892480      0.042413   \n",
       "\n",
       "   test_precision_mean  test_precision_std  test_recall_mean  test_recall_std  \n",
       "0             1.000000            0.000000          0.991784         0.006149  \n",
       "1             1.000000            0.000000          0.997949         0.002512  \n",
       "2             1.000000            0.000000          1.000000         0.000000  \n",
       "3             1.000000            0.000000          0.990748         0.005993  \n",
       "4             1.000000            0.000000          0.990743         0.007566  \n",
       "5             0.532810            0.004697          0.985615         0.005041  \n",
       "6             0.607535            0.024857          0.680185         0.348492  \n",
       "7             1.000000            0.000000          0.008232         0.006194  \n",
       "8             0.975845            0.048309          0.914692         0.018328  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_cv_scores_without_imbalance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything except Naive Bayes/KNN Performing quite Well\n",
    "\n",
    "Best: Extremely Randomized Trees: Balanced Acc: 100%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Here for the Dataset all features will be taken into consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_features = 75\n",
    "\n",
    "x_train_feat, x_test_feat, y_train_feat, y_test_feat = train_test_split(x_resampled, y_resampled, random_state=RANDOM_STATE)\n",
    "\n",
    "# oversampler = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "# x_train_feat_over, y_train_feat_over = oversampler.fit_resample(x_train_feat, y_train_feat)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "random_forest.fit(x_train_feat, y_train_feat)\n",
    "feature_importances = random_forest.feature_importances_[:number_of_features]\n",
    "standard_deviation_importances = np.std([tree.feature_importances_ for tree in random_forest.estimators_], axis=0)[:number_of_features]\n",
    "\n",
    "forest_importances = pd.Series(feature_importances, index=x_resampled.columns[:number_of_features])\n",
    "forest_importances = forest_importances.sort_values()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(12)\n",
    "forest_importances.plot.bar(yerr=standard_deviation_importances, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPW.Name</th>\n",
       "      <th>CPW.ANODE_FZLENGTH</th>\n",
       "      <th>CPW.ANODE_LENGTH</th>\n",
       "      <th>CPW.CATHODE_FZLENGTH_UPPER</th>\n",
       "      <th>CPW.CATHODE_LENGTH</th>\n",
       "      <th>CPW.DIAMTER_MAX</th>\n",
       "      <th>CPW.DIAMTER_MIN</th>\n",
       "      <th>CPW.DIAMTER_AVERAGE</th>\n",
       "      <th>CPW.ANODETABPOSITION</th>\n",
       "      <th>CPW.CATHODETABPOSITION</th>\n",
       "      <th>...</th>\n",
       "      <th>CPM.St5VakSollw</th>\n",
       "      <th>CPM.St3VakIstw</th>\n",
       "      <th>CPM.St3VakSollw</th>\n",
       "      <th>CPM.WeldCount</th>\n",
       "      <th>CPM.WeldResistance_microOhm</th>\n",
       "      <th>CPM.Name</th>\n",
       "      <th>CPX.AI_ACOHs001</th>\n",
       "      <th>CPX.AI_ACOHs002</th>\n",
       "      <th>CPX.AI_ACOHs003</th>\n",
       "      <th>CPX.AI_ACOHs004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.288943</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.763647</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.974757</td>\n",
       "      <td>0.982987</td>\n",
       "      <td>0.984151</td>\n",
       "      <td>0.110626</td>\n",
       "      <td>0.952026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>0.122544</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>0.052935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.900881</td>\n",
       "      <td>0.817471</td>\n",
       "      <td>0.531747</td>\n",
       "      <td>0.550890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.286520</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.793200</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.979029</td>\n",
       "      <td>0.982788</td>\n",
       "      <td>0.984250</td>\n",
       "      <td>0.719249</td>\n",
       "      <td>0.555135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.149431</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.235452</td>\n",
       "      <td>0.492316</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.878451</td>\n",
       "      <td>0.815640</td>\n",
       "      <td>0.541570</td>\n",
       "      <td>0.498932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.287636</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.781832</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>0.976893</td>\n",
       "      <td>0.981196</td>\n",
       "      <td>0.984844</td>\n",
       "      <td>0.274082</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>0.125336</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>0.512466</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.891279</td>\n",
       "      <td>0.813061</td>\n",
       "      <td>0.557568</td>\n",
       "      <td>0.573244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.287253</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.916610</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.978738</td>\n",
       "      <td>0.984579</td>\n",
       "      <td>0.987023</td>\n",
       "      <td>0.992854</td>\n",
       "      <td>0.810332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>0.125336</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>0.063165</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.907719</td>\n",
       "      <td>0.826853</td>\n",
       "      <td>0.537943</td>\n",
       "      <td>0.574129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.291270</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.709362</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.984369</td>\n",
       "      <td>0.982589</td>\n",
       "      <td>0.986330</td>\n",
       "      <td>0.756578</td>\n",
       "      <td>0.632159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>0.117890</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>0.089072</td>\n",
       "      <td>0.546960</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900945</td>\n",
       "      <td>0.823193</td>\n",
       "      <td>0.593688</td>\n",
       "      <td>0.572338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CPW.Name  CPW.ANODE_FZLENGTH  CPW.ANODE_LENGTH  CPW.CATHODE_FZLENGTH_UPPER  \\\n",
       "0  0.192308            0.288943          0.003238                    0.763647   \n",
       "1  0.807692            0.286520          0.003200                    0.793200   \n",
       "2  0.076923            0.287636          0.003203                    0.781832   \n",
       "3  0.230769            0.287253          0.003256                    0.916610   \n",
       "4  0.038462            0.291270          0.003234                    0.709362   \n",
       "\n",
       "   CPW.CATHODE_LENGTH  CPW.DIAMTER_MAX  CPW.DIAMTER_MIN  CPW.DIAMTER_AVERAGE  \\\n",
       "0            0.006635         0.974757         0.982987             0.984151   \n",
       "1            0.006651         0.979029         0.982788             0.984250   \n",
       "2            0.006657         0.976893         0.981196             0.984844   \n",
       "3            0.006683         0.978738         0.984579             0.987023   \n",
       "4            0.006690         0.984369         0.982589             0.986330   \n",
       "\n",
       "   CPW.ANODETABPOSITION  CPW.CATHODETABPOSITION  ...  CPM.St5VakSollw  \\\n",
       "0              0.110626                0.952026  ...         0.898333   \n",
       "1              0.719249                0.555135  ...         0.900000   \n",
       "2              0.274082                0.046617  ...         0.898333   \n",
       "3              0.992854                0.810332  ...         0.898333   \n",
       "4              0.756578                0.632159  ...         0.898333   \n",
       "\n",
       "   CPM.St3VakIstw  CPM.St3VakSollw  CPM.WeldCount  \\\n",
       "0        0.122544         0.898333       0.052935   \n",
       "1        0.149431         0.900000       0.235452   \n",
       "2        0.125336         0.898333       0.007438   \n",
       "3        0.125336         0.898333       0.063165   \n",
       "4        0.117890         0.898333       0.089072   \n",
       "\n",
       "   CPM.WeldResistance_microOhm  CPM.Name  CPX.AI_ACOHs001  CPX.AI_ACOHs002  \\\n",
       "0                     0.000000  0.866667         0.900881         0.817471   \n",
       "1                     0.492316  0.666667         0.878451         0.815640   \n",
       "2                     0.512466  0.800000         0.891279         0.813061   \n",
       "3                     0.516393  0.800000         0.907719         0.826853   \n",
       "4                     0.546960  0.800000         0.900945         0.823193   \n",
       "\n",
       "   CPX.AI_ACOHs003  CPX.AI_ACOHs004  \n",
       "0         0.531747         0.550890  \n",
       "1         0.541570         0.498932  \n",
       "2         0.557568         0.573244  \n",
       "3         0.537943         0.574129  \n",
       "4         0.593688         0.572338  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = SelectFromModel(estimator=random_forest, prefit=True)\n",
    "x_data_selected = selector.transform(x_resampled)\n",
    "best_features = selector.get_feature_names_out(x_resampled.columns)\n",
    "x_data_selected = pd.DataFrame(x_data_selected[:,:number_of_features], columns=best_features[:number_of_features])\n",
    "x_data_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ---- Validation for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–Ž        | 1/8 [00:20<02:23, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ---- Validation for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 2/8 [03:10<10:49, 108.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ---- Validation for Extremely Randomized Trees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [03:40<06:03, 72.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ---- Validation for Ada Boost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [04:59<05:00, 75.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ---- Validation for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [12:00<10:00, 200.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ---- Validation for Support Vector Machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [20:11<09:57, 298.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ---- Validation for Multilayer Perceptron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [22:12<04:00, 240.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ---- Validation for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [22:13<00:00, 166.65s/it]\n"
     ]
    }
   ],
   "source": [
    "all_cv_scores_selected = []\n",
    "\n",
    "# oversampler = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "# Important to use the selected features in here to see if the feature selection has a benefit onto the different classifiers\n",
    "# x_over_selected, y_over_selected = oversampler.fit_resample(X=x_data_selected, y=le.fit_transform(y))\n",
    "\n",
    "for classifier_name, classifier in tqdm(all_models()):\n",
    "    print(f\"[INFO] ---- Validation for {classifier_name}\")\n",
    "    formatted_result_selected = {}\n",
    "    formatted_result_selected['Classifier'] = classifier_name\n",
    "\n",
    "    cv_score = cross_validate(estimator=classifier, X=x_data_selected, y=y_resampled, scoring=scorings)\n",
    "\n",
    "    for score_name, scores in cv_score.items():\n",
    "        formatted_result_selected[f'{score_name}_mean'] = np.mean(scores)\n",
    "        formatted_result_selected[f'{score_name}_std'] = np.std(scores)\n",
    "\n",
    "    all_cv_scores_selected.append(formatted_result_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>fit_time_mean</th>\n",
       "      <th>fit_time_std</th>\n",
       "      <th>score_time_mean</th>\n",
       "      <th>score_time_std</th>\n",
       "      <th>test_accuracy_mean</th>\n",
       "      <th>test_accuracy_std</th>\n",
       "      <th>test_balanced_accuracy_mean</th>\n",
       "      <th>test_balanced_accuracy_std</th>\n",
       "      <th>test_f1_score_mean</th>\n",
       "      <th>test_f1_score_std</th>\n",
       "      <th>test_mcc_mean</th>\n",
       "      <th>test_mcc_std</th>\n",
       "      <th>test_precision_mean</th>\n",
       "      <th>test_precision_std</th>\n",
       "      <th>test_recall_mean</th>\n",
       "      <th>test_recall_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>4.092727</td>\n",
       "      <td>0.059730</td>\n",
       "      <td>0.013803</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.641751</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.641751</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.641800</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>0.283508</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.641732</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.641883</td>\n",
       "      <td>0.003729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>33.729350</td>\n",
       "      <td>0.102464</td>\n",
       "      <td>0.181441</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.739411</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.739411</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.732605</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.479465</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>0.752274</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.713974</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extremely Randomized Trees</td>\n",
       "      <td>5.861821</td>\n",
       "      <td>0.120664</td>\n",
       "      <td>0.241654</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.734267</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>0.734267</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>0.733040</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.468560</td>\n",
       "      <td>0.012440</td>\n",
       "      <td>0.736472</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>0.729650</td>\n",
       "      <td>0.005520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>15.663872</td>\n",
       "      <td>0.027555</td>\n",
       "      <td>0.086419</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.707190</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.707191</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.414668</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>0.714743</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.689742</td>\n",
       "      <td>0.005572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>84.263469</td>\n",
       "      <td>0.816913</td>\n",
       "      <td>0.026602</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.720568</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.720568</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.709168</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.442505</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.739304</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.681414</td>\n",
       "      <td>0.007273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>76.081218</td>\n",
       "      <td>4.485435</td>\n",
       "      <td>22.066962</td>\n",
       "      <td>0.394343</td>\n",
       "      <td>0.688744</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.688744</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.666565</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.380893</td>\n",
       "      <td>0.010776</td>\n",
       "      <td>0.717730</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.622249</td>\n",
       "      <td>0.007104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>24.210455</td>\n",
       "      <td>0.452801</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.701971</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.701970</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.694110</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.404818</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>0.713191</td>\n",
       "      <td>0.012441</td>\n",
       "      <td>0.676665</td>\n",
       "      <td>0.021219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.635212</td>\n",
       "      <td>0.022391</td>\n",
       "      <td>0.635210</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>0.545788</td>\n",
       "      <td>0.053447</td>\n",
       "      <td>0.293076</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>0.718835</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.443884</td>\n",
       "      <td>0.069481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Classifier  fit_time_mean  fit_time_std  score_time_mean  \\\n",
       "0               Decision Tree       4.092727      0.059730         0.013803   \n",
       "1               Random Forest      33.729350      0.102464         0.181441   \n",
       "2  Extremely Randomized Trees       5.861821      0.120664         0.241654   \n",
       "3                   Ada Boost      15.663872      0.027555         0.086419   \n",
       "4           Gradient Boosting      84.263469      0.816913         0.026602   \n",
       "5      Support Vector Machine      76.081218      4.485435        22.066962   \n",
       "6       Multilayer Perceptron      24.210455      0.452801         0.017804   \n",
       "7                 Naive Bayes       0.048611      0.006313         0.019604   \n",
       "\n",
       "   score_time_std  test_accuracy_mean  test_accuracy_std  \\\n",
       "0        0.000748            0.641751           0.003905   \n",
       "1        0.004500            0.739411           0.004363   \n",
       "2        0.004801            0.734267           0.006218   \n",
       "3        0.000490            0.707190           0.003836   \n",
       "4        0.003203            0.720568           0.004662   \n",
       "5        0.394343            0.688744           0.005313   \n",
       "6        0.002228            0.701971           0.006944   \n",
       "7        0.001356            0.635212           0.022391   \n",
       "\n",
       "   test_balanced_accuracy_mean  test_balanced_accuracy_std  \\\n",
       "0                     0.641751                    0.003905   \n",
       "1                     0.739411                    0.004363   \n",
       "2                     0.734267                    0.006218   \n",
       "3                     0.707191                    0.003836   \n",
       "4                     0.720568                    0.004662   \n",
       "5                     0.688744                    0.005311   \n",
       "6                     0.701970                    0.006944   \n",
       "7                     0.635210                    0.022399   \n",
       "\n",
       "   test_f1_score_mean  test_f1_score_std  test_mcc_mean  test_mcc_std  \\\n",
       "0            0.641800           0.003497       0.283508      0.007809   \n",
       "1            0.732605           0.004514       0.479465      0.008753   \n",
       "2            0.733040           0.005954       0.468560      0.012440   \n",
       "3            0.701990           0.003415       0.414668      0.007750   \n",
       "4            0.709168           0.005501       0.442505      0.009225   \n",
       "5            0.666565           0.005872       0.380893      0.010776   \n",
       "6            0.694110           0.009140       0.404818      0.013873   \n",
       "7            0.545788           0.053447       0.293076      0.036722   \n",
       "\n",
       "   test_precision_mean  test_precision_std  test_recall_mean  test_recall_std  \n",
       "0             0.641732            0.004396          0.641883         0.003729  \n",
       "1             0.752274            0.005457          0.713974         0.006071  \n",
       "2             0.736472            0.006925          0.729650         0.005520  \n",
       "3             0.714743            0.005856          0.689742         0.005572  \n",
       "4             0.739304            0.004444          0.681414         0.007273  \n",
       "5             0.717730            0.006836          0.622249         0.007104  \n",
       "6             0.713191            0.012441          0.676665         0.021219  \n",
       "7             0.718835            0.009131          0.443884         0.069481  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_cv_scores_selected)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Accuracy Mean: Random Forest 73,62%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparable Results as in the previous check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19938, number of negative: 19866\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17070\n",
      "[LightGBM] [Info] Number of data points in the train set: 39804, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500904 -> initscore=0.003618\n",
      "[LightGBM] [Info] Start training from score 0.003618\n",
      "Accuracy: 0.7307808260476334\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data_selected, y_resampled, random_state=RANDOM_STATE)\n",
    "train_data = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.215,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "model = lgb.train(params, train_data, num_boost_round=100)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = [round(p) for p in y_pred]\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x12995c46d30>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
    "cm_display.plot(cmap=\"Reds\", xticks_rotation=90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6730795\ttotal: 18.5ms\tremaining: 18.4s\n",
      "1:\tlearn: 0.6570974\ttotal: 36.5ms\tremaining: 18.2s\n",
      "2:\tlearn: 0.6434471\ttotal: 56ms\tremaining: 18.6s\n",
      "3:\tlearn: 0.6325197\ttotal: 74.5ms\tremaining: 18.5s\n",
      "4:\tlearn: 0.6227838\ttotal: 91.6ms\tremaining: 18.2s\n",
      "5:\tlearn: 0.6152268\ttotal: 111ms\tremaining: 18.4s\n",
      "6:\tlearn: 0.6091001\ttotal: 128ms\tremaining: 18.1s\n",
      "7:\tlearn: 0.6040541\ttotal: 144ms\tremaining: 17.9s\n",
      "8:\tlearn: 0.6002691\ttotal: 160ms\tremaining: 17.6s\n",
      "9:\tlearn: 0.5966397\ttotal: 178ms\tremaining: 17.6s\n",
      "10:\tlearn: 0.5934930\ttotal: 195ms\tremaining: 17.5s\n",
      "11:\tlearn: 0.5903688\ttotal: 212ms\tremaining: 17.5s\n",
      "12:\tlearn: 0.5879294\ttotal: 229ms\tremaining: 17.4s\n",
      "13:\tlearn: 0.5851681\ttotal: 246ms\tremaining: 17.4s\n",
      "14:\tlearn: 0.5831697\ttotal: 263ms\tremaining: 17.3s\n",
      "15:\tlearn: 0.5813061\ttotal: 280ms\tremaining: 17.2s\n",
      "16:\tlearn: 0.5792557\ttotal: 303ms\tremaining: 17.5s\n",
      "17:\tlearn: 0.5776547\ttotal: 321ms\tremaining: 17.5s\n",
      "18:\tlearn: 0.5761808\ttotal: 338ms\tremaining: 17.4s\n",
      "19:\tlearn: 0.5748910\ttotal: 355ms\tremaining: 17.4s\n",
      "20:\tlearn: 0.5736580\ttotal: 372ms\tremaining: 17.4s\n",
      "21:\tlearn: 0.5726352\ttotal: 389ms\tremaining: 17.3s\n",
      "22:\tlearn: 0.5716991\ttotal: 406ms\tremaining: 17.3s\n",
      "23:\tlearn: 0.5701557\ttotal: 424ms\tremaining: 17.2s\n",
      "24:\tlearn: 0.5692475\ttotal: 442ms\tremaining: 17.3s\n",
      "25:\tlearn: 0.5683718\ttotal: 461ms\tremaining: 17.3s\n",
      "26:\tlearn: 0.5676387\ttotal: 478ms\tremaining: 17.2s\n",
      "27:\tlearn: 0.5667907\ttotal: 495ms\tremaining: 17.2s\n",
      "28:\tlearn: 0.5659739\ttotal: 512ms\tremaining: 17.1s\n",
      "29:\tlearn: 0.5652838\ttotal: 530ms\tremaining: 17.1s\n",
      "30:\tlearn: 0.5646063\ttotal: 547ms\tremaining: 17.1s\n",
      "31:\tlearn: 0.5637850\ttotal: 565ms\tremaining: 17.1s\n",
      "32:\tlearn: 0.5630859\ttotal: 582ms\tremaining: 17.1s\n",
      "33:\tlearn: 0.5623362\ttotal: 599ms\tremaining: 17s\n",
      "34:\tlearn: 0.5614852\ttotal: 616ms\tremaining: 17s\n",
      "35:\tlearn: 0.5609216\ttotal: 632ms\tremaining: 16.9s\n",
      "36:\tlearn: 0.5599728\ttotal: 662ms\tremaining: 17.2s\n",
      "37:\tlearn: 0.5595021\ttotal: 682ms\tremaining: 17.3s\n",
      "38:\tlearn: 0.5589294\ttotal: 702ms\tremaining: 17.3s\n",
      "39:\tlearn: 0.5583622\ttotal: 720ms\tremaining: 17.3s\n",
      "40:\tlearn: 0.5578354\ttotal: 737ms\tremaining: 17.2s\n",
      "41:\tlearn: 0.5570263\ttotal: 756ms\tremaining: 17.2s\n",
      "42:\tlearn: 0.5564172\ttotal: 775ms\tremaining: 17.2s\n",
      "43:\tlearn: 0.5559956\ttotal: 791ms\tremaining: 17.2s\n",
      "44:\tlearn: 0.5555041\ttotal: 810ms\tremaining: 17.2s\n",
      "45:\tlearn: 0.5549820\ttotal: 829ms\tremaining: 17.2s\n",
      "46:\tlearn: 0.5543359\ttotal: 848ms\tremaining: 17.2s\n",
      "47:\tlearn: 0.5536651\ttotal: 865ms\tremaining: 17.1s\n",
      "48:\tlearn: 0.5532433\ttotal: 882ms\tremaining: 17.1s\n",
      "49:\tlearn: 0.5526669\ttotal: 900ms\tremaining: 17.1s\n",
      "50:\tlearn: 0.5520724\ttotal: 916ms\tremaining: 17s\n",
      "51:\tlearn: 0.5514014\ttotal: 932ms\tremaining: 17s\n",
      "52:\tlearn: 0.5508849\ttotal: 949ms\tremaining: 16.9s\n",
      "53:\tlearn: 0.5504792\ttotal: 965ms\tremaining: 16.9s\n",
      "54:\tlearn: 0.5499484\ttotal: 982ms\tremaining: 16.9s\n",
      "55:\tlearn: 0.5495363\ttotal: 998ms\tremaining: 16.8s\n",
      "56:\tlearn: 0.5490379\ttotal: 1.01s\tremaining: 16.8s\n",
      "57:\tlearn: 0.5483999\ttotal: 1.03s\tremaining: 16.8s\n",
      "58:\tlearn: 0.5478378\ttotal: 1.05s\tremaining: 16.7s\n",
      "59:\tlearn: 0.5474703\ttotal: 1.06s\tremaining: 16.7s\n",
      "60:\tlearn: 0.5468571\ttotal: 1.08s\tremaining: 16.6s\n",
      "61:\tlearn: 0.5462374\ttotal: 1.1s\tremaining: 16.6s\n",
      "62:\tlearn: 0.5458633\ttotal: 1.11s\tremaining: 16.6s\n",
      "63:\tlearn: 0.5454162\ttotal: 1.13s\tremaining: 16.6s\n",
      "64:\tlearn: 0.5450603\ttotal: 1.15s\tremaining: 16.5s\n",
      "65:\tlearn: 0.5446055\ttotal: 1.17s\tremaining: 16.5s\n",
      "66:\tlearn: 0.5442436\ttotal: 1.18s\tremaining: 16.5s\n",
      "67:\tlearn: 0.5439310\ttotal: 1.2s\tremaining: 16.4s\n",
      "68:\tlearn: 0.5435863\ttotal: 1.22s\tremaining: 16.4s\n",
      "69:\tlearn: 0.5432167\ttotal: 1.23s\tremaining: 16.4s\n",
      "70:\tlearn: 0.5427463\ttotal: 1.25s\tremaining: 16.4s\n",
      "71:\tlearn: 0.5423790\ttotal: 1.27s\tremaining: 16.3s\n",
      "72:\tlearn: 0.5420468\ttotal: 1.28s\tremaining: 16.3s\n",
      "73:\tlearn: 0.5416664\ttotal: 1.3s\tremaining: 16.3s\n",
      "74:\tlearn: 0.5412403\ttotal: 1.32s\tremaining: 16.3s\n",
      "75:\tlearn: 0.5408971\ttotal: 1.34s\tremaining: 16.3s\n",
      "76:\tlearn: 0.5405365\ttotal: 1.35s\tremaining: 16.2s\n",
      "77:\tlearn: 0.5402048\ttotal: 1.37s\tremaining: 16.2s\n",
      "78:\tlearn: 0.5398888\ttotal: 1.39s\tremaining: 16.2s\n",
      "79:\tlearn: 0.5395788\ttotal: 1.41s\tremaining: 16.2s\n",
      "80:\tlearn: 0.5392922\ttotal: 1.42s\tremaining: 16.1s\n",
      "81:\tlearn: 0.5387278\ttotal: 1.44s\tremaining: 16.1s\n",
      "82:\tlearn: 0.5382957\ttotal: 1.45s\tremaining: 16.1s\n",
      "83:\tlearn: 0.5377873\ttotal: 1.47s\tremaining: 16s\n",
      "84:\tlearn: 0.5375830\ttotal: 1.49s\tremaining: 16s\n",
      "85:\tlearn: 0.5372924\ttotal: 1.5s\tremaining: 16s\n",
      "86:\tlearn: 0.5369542\ttotal: 1.52s\tremaining: 15.9s\n",
      "87:\tlearn: 0.5364083\ttotal: 1.53s\tremaining: 15.9s\n",
      "88:\tlearn: 0.5361202\ttotal: 1.55s\tremaining: 15.8s\n",
      "89:\tlearn: 0.5357314\ttotal: 1.56s\tremaining: 15.8s\n",
      "90:\tlearn: 0.5352376\ttotal: 1.58s\tremaining: 15.8s\n",
      "91:\tlearn: 0.5348559\ttotal: 1.6s\tremaining: 15.8s\n",
      "92:\tlearn: 0.5345023\ttotal: 1.61s\tremaining: 15.7s\n",
      "93:\tlearn: 0.5341253\ttotal: 1.63s\tremaining: 15.7s\n",
      "94:\tlearn: 0.5337134\ttotal: 1.64s\tremaining: 15.7s\n",
      "95:\tlearn: 0.5333776\ttotal: 1.66s\tremaining: 15.6s\n",
      "96:\tlearn: 0.5331850\ttotal: 1.67s\tremaining: 15.6s\n",
      "97:\tlearn: 0.5329397\ttotal: 1.69s\tremaining: 15.5s\n",
      "98:\tlearn: 0.5326047\ttotal: 1.7s\tremaining: 15.5s\n",
      "99:\tlearn: 0.5321240\ttotal: 1.72s\tremaining: 15.5s\n",
      "100:\tlearn: 0.5319234\ttotal: 1.74s\tremaining: 15.4s\n",
      "101:\tlearn: 0.5316145\ttotal: 1.75s\tremaining: 15.4s\n",
      "102:\tlearn: 0.5312054\ttotal: 1.77s\tremaining: 15.4s\n",
      "103:\tlearn: 0.5307954\ttotal: 1.78s\tremaining: 15.4s\n",
      "104:\tlearn: 0.5305024\ttotal: 1.8s\tremaining: 15.4s\n",
      "105:\tlearn: 0.5301130\ttotal: 1.82s\tremaining: 15.3s\n",
      "106:\tlearn: 0.5295857\ttotal: 1.84s\tremaining: 15.3s\n",
      "107:\tlearn: 0.5292876\ttotal: 1.85s\tremaining: 15.3s\n",
      "108:\tlearn: 0.5289033\ttotal: 1.87s\tremaining: 15.3s\n",
      "109:\tlearn: 0.5286002\ttotal: 1.89s\tremaining: 15.3s\n",
      "110:\tlearn: 0.5281965\ttotal: 1.9s\tremaining: 15.2s\n",
      "111:\tlearn: 0.5279012\ttotal: 1.92s\tremaining: 15.2s\n",
      "112:\tlearn: 0.5274491\ttotal: 1.93s\tremaining: 15.2s\n",
      "113:\tlearn: 0.5268259\ttotal: 1.95s\tremaining: 15.2s\n",
      "114:\tlearn: 0.5264626\ttotal: 1.97s\tremaining: 15.1s\n",
      "115:\tlearn: 0.5260580\ttotal: 1.98s\tremaining: 15.1s\n",
      "116:\tlearn: 0.5255881\ttotal: 2s\tremaining: 15.1s\n",
      "117:\tlearn: 0.5252670\ttotal: 2.01s\tremaining: 15.1s\n",
      "118:\tlearn: 0.5249437\ttotal: 2.03s\tremaining: 15s\n",
      "119:\tlearn: 0.5245493\ttotal: 2.04s\tremaining: 15s\n",
      "120:\tlearn: 0.5240681\ttotal: 2.06s\tremaining: 15s\n",
      "121:\tlearn: 0.5237070\ttotal: 2.08s\tremaining: 14.9s\n",
      "122:\tlearn: 0.5233720\ttotal: 2.09s\tremaining: 14.9s\n",
      "123:\tlearn: 0.5229720\ttotal: 2.11s\tremaining: 14.9s\n",
      "124:\tlearn: 0.5227037\ttotal: 2.12s\tremaining: 14.9s\n",
      "125:\tlearn: 0.5222121\ttotal: 2.14s\tremaining: 14.8s\n",
      "126:\tlearn: 0.5219117\ttotal: 2.15s\tremaining: 14.8s\n",
      "127:\tlearn: 0.5215863\ttotal: 2.17s\tremaining: 14.8s\n",
      "128:\tlearn: 0.5211046\ttotal: 2.19s\tremaining: 14.8s\n",
      "129:\tlearn: 0.5207575\ttotal: 2.2s\tremaining: 14.7s\n",
      "130:\tlearn: 0.5202829\ttotal: 2.22s\tremaining: 14.7s\n",
      "131:\tlearn: 0.5199401\ttotal: 2.23s\tremaining: 14.7s\n",
      "132:\tlearn: 0.5195677\ttotal: 2.25s\tremaining: 14.7s\n",
      "133:\tlearn: 0.5192598\ttotal: 2.26s\tremaining: 14.6s\n",
      "134:\tlearn: 0.5188631\ttotal: 2.28s\tremaining: 14.6s\n",
      "135:\tlearn: 0.5186309\ttotal: 2.29s\tremaining: 14.6s\n",
      "136:\tlearn: 0.5183138\ttotal: 2.31s\tremaining: 14.5s\n",
      "137:\tlearn: 0.5178807\ttotal: 2.33s\tremaining: 14.5s\n",
      "138:\tlearn: 0.5175119\ttotal: 2.34s\tremaining: 14.5s\n",
      "139:\tlearn: 0.5172217\ttotal: 2.36s\tremaining: 14.5s\n",
      "140:\tlearn: 0.5168682\ttotal: 2.37s\tremaining: 14.5s\n",
      "141:\tlearn: 0.5164308\ttotal: 2.39s\tremaining: 14.4s\n",
      "142:\tlearn: 0.5159340\ttotal: 2.4s\tremaining: 14.4s\n",
      "143:\tlearn: 0.5156212\ttotal: 2.42s\tremaining: 14.4s\n",
      "144:\tlearn: 0.5151399\ttotal: 2.44s\tremaining: 14.4s\n",
      "145:\tlearn: 0.5147241\ttotal: 2.45s\tremaining: 14.3s\n",
      "146:\tlearn: 0.5143893\ttotal: 2.47s\tremaining: 14.3s\n",
      "147:\tlearn: 0.5139829\ttotal: 2.48s\tremaining: 14.3s\n",
      "148:\tlearn: 0.5136042\ttotal: 2.5s\tremaining: 14.3s\n",
      "149:\tlearn: 0.5131891\ttotal: 2.51s\tremaining: 14.2s\n",
      "150:\tlearn: 0.5127479\ttotal: 2.53s\tremaining: 14.2s\n",
      "151:\tlearn: 0.5124331\ttotal: 2.54s\tremaining: 14.2s\n",
      "152:\tlearn: 0.5121552\ttotal: 2.56s\tremaining: 14.2s\n",
      "153:\tlearn: 0.5118152\ttotal: 2.58s\tremaining: 14.2s\n",
      "154:\tlearn: 0.5114568\ttotal: 2.59s\tremaining: 14.1s\n",
      "155:\tlearn: 0.5110550\ttotal: 2.61s\tremaining: 14.1s\n",
      "156:\tlearn: 0.5106878\ttotal: 2.62s\tremaining: 14.1s\n",
      "157:\tlearn: 0.5104536\ttotal: 2.64s\tremaining: 14.1s\n",
      "158:\tlearn: 0.5100828\ttotal: 2.65s\tremaining: 14s\n",
      "159:\tlearn: 0.5098092\ttotal: 2.67s\tremaining: 14s\n",
      "160:\tlearn: 0.5094440\ttotal: 2.69s\tremaining: 14s\n",
      "161:\tlearn: 0.5090205\ttotal: 2.7s\tremaining: 14s\n",
      "162:\tlearn: 0.5085838\ttotal: 2.72s\tremaining: 14s\n",
      "163:\tlearn: 0.5082070\ttotal: 2.73s\tremaining: 13.9s\n",
      "164:\tlearn: 0.5080191\ttotal: 2.75s\tremaining: 13.9s\n",
      "165:\tlearn: 0.5076872\ttotal: 2.77s\tremaining: 13.9s\n",
      "166:\tlearn: 0.5072064\ttotal: 2.78s\tremaining: 13.9s\n",
      "167:\tlearn: 0.5069073\ttotal: 2.8s\tremaining: 13.9s\n",
      "168:\tlearn: 0.5065009\ttotal: 2.82s\tremaining: 13.9s\n",
      "169:\tlearn: 0.5061262\ttotal: 2.83s\tremaining: 13.8s\n",
      "170:\tlearn: 0.5057498\ttotal: 2.85s\tremaining: 13.8s\n",
      "171:\tlearn: 0.5054806\ttotal: 2.86s\tremaining: 13.8s\n",
      "172:\tlearn: 0.5051556\ttotal: 2.88s\tremaining: 13.8s\n",
      "173:\tlearn: 0.5047792\ttotal: 2.9s\tremaining: 13.7s\n",
      "174:\tlearn: 0.5043988\ttotal: 2.91s\tremaining: 13.7s\n",
      "175:\tlearn: 0.5040200\ttotal: 2.93s\tremaining: 13.7s\n",
      "176:\tlearn: 0.5037399\ttotal: 2.94s\tremaining: 13.7s\n",
      "177:\tlearn: 0.5033809\ttotal: 2.96s\tremaining: 13.7s\n",
      "178:\tlearn: 0.5031068\ttotal: 2.97s\tremaining: 13.6s\n",
      "179:\tlearn: 0.5028123\ttotal: 2.99s\tremaining: 13.6s\n",
      "180:\tlearn: 0.5025444\ttotal: 3s\tremaining: 13.6s\n",
      "181:\tlearn: 0.5022085\ttotal: 3.02s\tremaining: 13.6s\n",
      "182:\tlearn: 0.5018461\ttotal: 3.03s\tremaining: 13.5s\n",
      "183:\tlearn: 0.5014405\ttotal: 3.05s\tremaining: 13.5s\n",
      "184:\tlearn: 0.5011248\ttotal: 3.07s\tremaining: 13.5s\n",
      "185:\tlearn: 0.5008367\ttotal: 3.08s\tremaining: 13.5s\n",
      "186:\tlearn: 0.5005063\ttotal: 3.1s\tremaining: 13.5s\n",
      "187:\tlearn: 0.5001131\ttotal: 3.11s\tremaining: 13.4s\n",
      "188:\tlearn: 0.4997652\ttotal: 3.13s\tremaining: 13.4s\n",
      "189:\tlearn: 0.4994596\ttotal: 3.14s\tremaining: 13.4s\n",
      "190:\tlearn: 0.4991511\ttotal: 3.16s\tremaining: 13.4s\n",
      "191:\tlearn: 0.4988211\ttotal: 3.17s\tremaining: 13.4s\n",
      "192:\tlearn: 0.4984834\ttotal: 3.19s\tremaining: 13.3s\n",
      "193:\tlearn: 0.4980738\ttotal: 3.2s\tremaining: 13.3s\n",
      "194:\tlearn: 0.4977213\ttotal: 3.22s\tremaining: 13.3s\n",
      "195:\tlearn: 0.4973863\ttotal: 3.23s\tremaining: 13.3s\n",
      "196:\tlearn: 0.4971209\ttotal: 3.25s\tremaining: 13.3s\n",
      "197:\tlearn: 0.4968380\ttotal: 3.27s\tremaining: 13.2s\n",
      "198:\tlearn: 0.4965882\ttotal: 3.28s\tremaining: 13.2s\n",
      "199:\tlearn: 0.4962001\ttotal: 3.3s\tremaining: 13.2s\n",
      "200:\tlearn: 0.4958717\ttotal: 3.32s\tremaining: 13.2s\n",
      "201:\tlearn: 0.4954964\ttotal: 3.33s\tremaining: 13.2s\n",
      "202:\tlearn: 0.4951896\ttotal: 3.35s\tremaining: 13.1s\n",
      "203:\tlearn: 0.4947801\ttotal: 3.36s\tremaining: 13.1s\n",
      "204:\tlearn: 0.4944041\ttotal: 3.38s\tremaining: 13.1s\n",
      "205:\tlearn: 0.4941295\ttotal: 3.39s\tremaining: 13.1s\n",
      "206:\tlearn: 0.4939056\ttotal: 3.41s\tremaining: 13.1s\n",
      "207:\tlearn: 0.4935651\ttotal: 3.43s\tremaining: 13s\n",
      "208:\tlearn: 0.4932218\ttotal: 3.44s\tremaining: 13s\n",
      "209:\tlearn: 0.4928476\ttotal: 3.46s\tremaining: 13s\n",
      "210:\tlearn: 0.4926451\ttotal: 3.47s\tremaining: 13s\n",
      "211:\tlearn: 0.4923045\ttotal: 3.49s\tremaining: 13s\n",
      "212:\tlearn: 0.4919600\ttotal: 3.5s\tremaining: 12.9s\n",
      "213:\tlearn: 0.4915559\ttotal: 3.52s\tremaining: 12.9s\n",
      "214:\tlearn: 0.4913622\ttotal: 3.54s\tremaining: 12.9s\n",
      "215:\tlearn: 0.4910522\ttotal: 3.55s\tremaining: 12.9s\n",
      "216:\tlearn: 0.4907111\ttotal: 3.57s\tremaining: 12.9s\n",
      "217:\tlearn: 0.4904173\ttotal: 3.58s\tremaining: 12.8s\n",
      "218:\tlearn: 0.4901450\ttotal: 3.6s\tremaining: 12.8s\n",
      "219:\tlearn: 0.4897923\ttotal: 3.61s\tremaining: 12.8s\n",
      "220:\tlearn: 0.4895267\ttotal: 3.63s\tremaining: 12.8s\n",
      "221:\tlearn: 0.4891749\ttotal: 3.64s\tremaining: 12.8s\n",
      "222:\tlearn: 0.4888458\ttotal: 3.66s\tremaining: 12.7s\n",
      "223:\tlearn: 0.4884610\ttotal: 3.67s\tremaining: 12.7s\n",
      "224:\tlearn: 0.4880975\ttotal: 3.69s\tremaining: 12.7s\n",
      "225:\tlearn: 0.4878286\ttotal: 3.71s\tremaining: 12.7s\n",
      "226:\tlearn: 0.4875385\ttotal: 3.72s\tremaining: 12.7s\n",
      "227:\tlearn: 0.4872141\ttotal: 3.74s\tremaining: 12.7s\n",
      "228:\tlearn: 0.4869317\ttotal: 3.75s\tremaining: 12.6s\n",
      "229:\tlearn: 0.4866322\ttotal: 3.77s\tremaining: 12.6s\n",
      "230:\tlearn: 0.4862832\ttotal: 3.79s\tremaining: 12.6s\n",
      "231:\tlearn: 0.4858925\ttotal: 3.81s\tremaining: 12.6s\n",
      "232:\tlearn: 0.4855871\ttotal: 3.82s\tremaining: 12.6s\n",
      "233:\tlearn: 0.4853054\ttotal: 3.84s\tremaining: 12.6s\n",
      "234:\tlearn: 0.4849185\ttotal: 3.85s\tremaining: 12.6s\n",
      "235:\tlearn: 0.4846488\ttotal: 3.87s\tremaining: 12.5s\n",
      "236:\tlearn: 0.4844357\ttotal: 3.88s\tremaining: 12.5s\n",
      "237:\tlearn: 0.4841371\ttotal: 3.9s\tremaining: 12.5s\n",
      "238:\tlearn: 0.4837677\ttotal: 3.92s\tremaining: 12.5s\n",
      "239:\tlearn: 0.4834836\ttotal: 3.93s\tremaining: 12.5s\n",
      "240:\tlearn: 0.4832122\ttotal: 3.95s\tremaining: 12.4s\n",
      "241:\tlearn: 0.4828605\ttotal: 3.96s\tremaining: 12.4s\n",
      "242:\tlearn: 0.4825847\ttotal: 3.98s\tremaining: 12.4s\n",
      "243:\tlearn: 0.4823942\ttotal: 3.99s\tremaining: 12.4s\n",
      "244:\tlearn: 0.4821081\ttotal: 4.01s\tremaining: 12.4s\n",
      "245:\tlearn: 0.4818375\ttotal: 4.02s\tremaining: 12.3s\n",
      "246:\tlearn: 0.4815893\ttotal: 4.04s\tremaining: 12.3s\n",
      "247:\tlearn: 0.4813672\ttotal: 4.05s\tremaining: 12.3s\n",
      "248:\tlearn: 0.4811454\ttotal: 4.07s\tremaining: 12.3s\n",
      "249:\tlearn: 0.4808559\ttotal: 4.08s\tremaining: 12.3s\n",
      "250:\tlearn: 0.4805960\ttotal: 4.1s\tremaining: 12.2s\n",
      "251:\tlearn: 0.4803064\ttotal: 4.12s\tremaining: 12.2s\n",
      "252:\tlearn: 0.4799941\ttotal: 4.13s\tremaining: 12.2s\n",
      "253:\tlearn: 0.4796356\ttotal: 4.15s\tremaining: 12.2s\n",
      "254:\tlearn: 0.4793439\ttotal: 4.16s\tremaining: 12.2s\n",
      "255:\tlearn: 0.4791544\ttotal: 4.18s\tremaining: 12.1s\n",
      "256:\tlearn: 0.4788698\ttotal: 4.19s\tremaining: 12.1s\n",
      "257:\tlearn: 0.4786601\ttotal: 4.21s\tremaining: 12.1s\n",
      "258:\tlearn: 0.4784128\ttotal: 4.22s\tremaining: 12.1s\n",
      "259:\tlearn: 0.4781012\ttotal: 4.24s\tremaining: 12.1s\n",
      "260:\tlearn: 0.4778048\ttotal: 4.25s\tremaining: 12s\n",
      "261:\tlearn: 0.4775301\ttotal: 4.27s\tremaining: 12s\n",
      "262:\tlearn: 0.4772132\ttotal: 4.29s\tremaining: 12s\n",
      "263:\tlearn: 0.4768540\ttotal: 4.3s\tremaining: 12s\n",
      "264:\tlearn: 0.4766432\ttotal: 4.32s\tremaining: 12s\n",
      "265:\tlearn: 0.4762930\ttotal: 4.34s\tremaining: 12s\n",
      "266:\tlearn: 0.4759858\ttotal: 4.36s\tremaining: 12s\n",
      "267:\tlearn: 0.4758120\ttotal: 4.37s\tremaining: 11.9s\n",
      "268:\tlearn: 0.4755101\ttotal: 4.39s\tremaining: 11.9s\n",
      "269:\tlearn: 0.4752414\ttotal: 4.4s\tremaining: 11.9s\n",
      "270:\tlearn: 0.4748739\ttotal: 4.42s\tremaining: 11.9s\n",
      "271:\tlearn: 0.4745765\ttotal: 4.44s\tremaining: 11.9s\n",
      "272:\tlearn: 0.4743013\ttotal: 4.45s\tremaining: 11.9s\n",
      "273:\tlearn: 0.4740614\ttotal: 4.47s\tremaining: 11.8s\n",
      "274:\tlearn: 0.4737882\ttotal: 4.48s\tremaining: 11.8s\n",
      "275:\tlearn: 0.4734512\ttotal: 4.5s\tremaining: 11.8s\n",
      "276:\tlearn: 0.4732116\ttotal: 4.52s\tremaining: 11.8s\n",
      "277:\tlearn: 0.4729904\ttotal: 4.53s\tremaining: 11.8s\n",
      "278:\tlearn: 0.4726516\ttotal: 4.55s\tremaining: 11.8s\n",
      "279:\tlearn: 0.4724518\ttotal: 4.56s\tremaining: 11.7s\n",
      "280:\tlearn: 0.4722514\ttotal: 4.58s\tremaining: 11.7s\n",
      "281:\tlearn: 0.4719674\ttotal: 4.6s\tremaining: 11.7s\n",
      "282:\tlearn: 0.4717326\ttotal: 4.61s\tremaining: 11.7s\n",
      "283:\tlearn: 0.4713980\ttotal: 4.63s\tremaining: 11.7s\n",
      "284:\tlearn: 0.4710879\ttotal: 4.64s\tremaining: 11.7s\n",
      "285:\tlearn: 0.4708147\ttotal: 4.66s\tremaining: 11.6s\n",
      "286:\tlearn: 0.4704309\ttotal: 4.67s\tremaining: 11.6s\n",
      "287:\tlearn: 0.4701372\ttotal: 4.69s\tremaining: 11.6s\n",
      "288:\tlearn: 0.4699165\ttotal: 4.71s\tremaining: 11.6s\n",
      "289:\tlearn: 0.4696957\ttotal: 4.72s\tremaining: 11.6s\n",
      "290:\tlearn: 0.4695137\ttotal: 4.74s\tremaining: 11.5s\n",
      "291:\tlearn: 0.4693120\ttotal: 4.75s\tremaining: 11.5s\n",
      "292:\tlearn: 0.4690332\ttotal: 4.77s\tremaining: 11.5s\n",
      "293:\tlearn: 0.4687291\ttotal: 4.79s\tremaining: 11.5s\n",
      "294:\tlearn: 0.4684728\ttotal: 4.81s\tremaining: 11.5s\n",
      "295:\tlearn: 0.4681733\ttotal: 4.83s\tremaining: 11.5s\n",
      "296:\tlearn: 0.4679217\ttotal: 4.84s\tremaining: 11.5s\n",
      "297:\tlearn: 0.4676261\ttotal: 4.86s\tremaining: 11.4s\n",
      "298:\tlearn: 0.4674185\ttotal: 4.87s\tremaining: 11.4s\n",
      "299:\tlearn: 0.4671575\ttotal: 4.89s\tremaining: 11.4s\n",
      "300:\tlearn: 0.4669074\ttotal: 4.9s\tremaining: 11.4s\n",
      "301:\tlearn: 0.4666888\ttotal: 4.92s\tremaining: 11.4s\n",
      "302:\tlearn: 0.4664255\ttotal: 4.93s\tremaining: 11.3s\n",
      "303:\tlearn: 0.4661316\ttotal: 4.95s\tremaining: 11.3s\n",
      "304:\tlearn: 0.4658521\ttotal: 4.97s\tremaining: 11.3s\n",
      "305:\tlearn: 0.4655589\ttotal: 4.98s\tremaining: 11.3s\n",
      "306:\tlearn: 0.4652477\ttotal: 5s\tremaining: 11.3s\n",
      "307:\tlearn: 0.4649624\ttotal: 5.03s\tremaining: 11.3s\n",
      "308:\tlearn: 0.4646935\ttotal: 5.04s\tremaining: 11.3s\n",
      "309:\tlearn: 0.4644644\ttotal: 5.06s\tremaining: 11.3s\n",
      "310:\tlearn: 0.4642015\ttotal: 5.08s\tremaining: 11.2s\n",
      "311:\tlearn: 0.4639396\ttotal: 5.09s\tremaining: 11.2s\n",
      "312:\tlearn: 0.4637341\ttotal: 5.11s\tremaining: 11.2s\n",
      "313:\tlearn: 0.4634457\ttotal: 5.13s\tremaining: 11.2s\n",
      "314:\tlearn: 0.4631520\ttotal: 5.14s\tremaining: 11.2s\n",
      "315:\tlearn: 0.4629020\ttotal: 5.16s\tremaining: 11.2s\n",
      "316:\tlearn: 0.4626816\ttotal: 5.18s\tremaining: 11.2s\n",
      "317:\tlearn: 0.4624556\ttotal: 5.2s\tremaining: 11.1s\n",
      "318:\tlearn: 0.4623089\ttotal: 5.21s\tremaining: 11.1s\n",
      "319:\tlearn: 0.4620774\ttotal: 5.23s\tremaining: 11.1s\n",
      "320:\tlearn: 0.4618431\ttotal: 5.24s\tremaining: 11.1s\n",
      "321:\tlearn: 0.4616027\ttotal: 5.26s\tremaining: 11.1s\n",
      "322:\tlearn: 0.4613661\ttotal: 5.28s\tremaining: 11.1s\n",
      "323:\tlearn: 0.4611346\ttotal: 5.29s\tremaining: 11s\n",
      "324:\tlearn: 0.4608200\ttotal: 5.31s\tremaining: 11s\n",
      "325:\tlearn: 0.4604724\ttotal: 5.33s\tremaining: 11s\n",
      "326:\tlearn: 0.4601602\ttotal: 5.34s\tremaining: 11s\n",
      "327:\tlearn: 0.4600357\ttotal: 5.36s\tremaining: 11s\n",
      "328:\tlearn: 0.4598066\ttotal: 5.38s\tremaining: 11s\n",
      "329:\tlearn: 0.4595077\ttotal: 5.39s\tremaining: 10.9s\n",
      "330:\tlearn: 0.4592213\ttotal: 5.41s\tremaining: 10.9s\n",
      "331:\tlearn: 0.4590163\ttotal: 5.42s\tremaining: 10.9s\n",
      "332:\tlearn: 0.4587188\ttotal: 5.44s\tremaining: 10.9s\n",
      "333:\tlearn: 0.4584810\ttotal: 5.46s\tremaining: 10.9s\n",
      "334:\tlearn: 0.4582388\ttotal: 5.47s\tremaining: 10.9s\n",
      "335:\tlearn: 0.4579796\ttotal: 5.49s\tremaining: 10.8s\n",
      "336:\tlearn: 0.4578140\ttotal: 5.5s\tremaining: 10.8s\n",
      "337:\tlearn: 0.4575664\ttotal: 5.52s\tremaining: 10.8s\n",
      "338:\tlearn: 0.4573074\ttotal: 5.53s\tremaining: 10.8s\n",
      "339:\tlearn: 0.4570051\ttotal: 5.55s\tremaining: 10.8s\n",
      "340:\tlearn: 0.4567217\ttotal: 5.56s\tremaining: 10.8s\n",
      "341:\tlearn: 0.4564051\ttotal: 5.58s\tremaining: 10.7s\n",
      "342:\tlearn: 0.4561362\ttotal: 5.6s\tremaining: 10.7s\n",
      "343:\tlearn: 0.4558802\ttotal: 5.61s\tremaining: 10.7s\n",
      "344:\tlearn: 0.4555864\ttotal: 5.63s\tremaining: 10.7s\n",
      "345:\tlearn: 0.4553593\ttotal: 5.64s\tremaining: 10.7s\n",
      "346:\tlearn: 0.4550720\ttotal: 5.66s\tremaining: 10.7s\n",
      "347:\tlearn: 0.4548223\ttotal: 5.67s\tremaining: 10.6s\n",
      "348:\tlearn: 0.4545559\ttotal: 5.69s\tremaining: 10.6s\n",
      "349:\tlearn: 0.4542332\ttotal: 5.71s\tremaining: 10.6s\n",
      "350:\tlearn: 0.4539084\ttotal: 5.72s\tremaining: 10.6s\n",
      "351:\tlearn: 0.4537547\ttotal: 5.74s\tremaining: 10.6s\n",
      "352:\tlearn: 0.4535545\ttotal: 5.75s\tremaining: 10.5s\n",
      "353:\tlearn: 0.4533299\ttotal: 5.77s\tremaining: 10.5s\n",
      "354:\tlearn: 0.4530765\ttotal: 5.79s\tremaining: 10.5s\n",
      "355:\tlearn: 0.4527982\ttotal: 5.81s\tremaining: 10.5s\n",
      "356:\tlearn: 0.4526385\ttotal: 5.82s\tremaining: 10.5s\n",
      "357:\tlearn: 0.4523983\ttotal: 5.84s\tremaining: 10.5s\n",
      "358:\tlearn: 0.4520916\ttotal: 5.86s\tremaining: 10.5s\n",
      "359:\tlearn: 0.4518838\ttotal: 5.87s\tremaining: 10.4s\n",
      "360:\tlearn: 0.4516179\ttotal: 5.89s\tremaining: 10.4s\n",
      "361:\tlearn: 0.4515012\ttotal: 5.9s\tremaining: 10.4s\n",
      "362:\tlearn: 0.4513003\ttotal: 5.92s\tremaining: 10.4s\n",
      "363:\tlearn: 0.4511066\ttotal: 5.93s\tremaining: 10.4s\n",
      "364:\tlearn: 0.4508875\ttotal: 5.95s\tremaining: 10.4s\n",
      "365:\tlearn: 0.4506888\ttotal: 5.96s\tremaining: 10.3s\n",
      "366:\tlearn: 0.4504311\ttotal: 5.98s\tremaining: 10.3s\n",
      "367:\tlearn: 0.4501859\ttotal: 6s\tremaining: 10.3s\n",
      "368:\tlearn: 0.4499271\ttotal: 6.01s\tremaining: 10.3s\n",
      "369:\tlearn: 0.4496999\ttotal: 6.03s\tremaining: 10.3s\n",
      "370:\tlearn: 0.4494558\ttotal: 6.04s\tremaining: 10.3s\n",
      "371:\tlearn: 0.4492764\ttotal: 6.06s\tremaining: 10.2s\n",
      "372:\tlearn: 0.4491354\ttotal: 6.08s\tremaining: 10.2s\n",
      "373:\tlearn: 0.4488327\ttotal: 6.09s\tremaining: 10.2s\n",
      "374:\tlearn: 0.4485625\ttotal: 6.11s\tremaining: 10.2s\n",
      "375:\tlearn: 0.4482194\ttotal: 6.12s\tremaining: 10.2s\n",
      "376:\tlearn: 0.4479456\ttotal: 6.14s\tremaining: 10.1s\n",
      "377:\tlearn: 0.4476501\ttotal: 6.15s\tremaining: 10.1s\n",
      "378:\tlearn: 0.4474026\ttotal: 6.17s\tremaining: 10.1s\n",
      "379:\tlearn: 0.4472638\ttotal: 6.18s\tremaining: 10.1s\n",
      "380:\tlearn: 0.4470083\ttotal: 6.2s\tremaining: 10.1s\n",
      "381:\tlearn: 0.4467029\ttotal: 6.22s\tremaining: 10.1s\n",
      "382:\tlearn: 0.4464015\ttotal: 6.23s\tremaining: 10s\n",
      "383:\tlearn: 0.4461783\ttotal: 6.25s\tremaining: 10s\n",
      "384:\tlearn: 0.4460017\ttotal: 6.27s\tremaining: 10s\n",
      "385:\tlearn: 0.4457176\ttotal: 6.29s\tremaining: 10s\n",
      "386:\tlearn: 0.4454311\ttotal: 6.3s\tremaining: 9.98s\n",
      "387:\tlearn: 0.4451107\ttotal: 6.32s\tremaining: 9.96s\n",
      "388:\tlearn: 0.4448259\ttotal: 6.33s\tremaining: 9.95s\n",
      "389:\tlearn: 0.4445712\ttotal: 6.35s\tremaining: 9.93s\n",
      "390:\tlearn: 0.4443289\ttotal: 6.37s\tremaining: 9.91s\n",
      "391:\tlearn: 0.4441439\ttotal: 6.38s\tremaining: 9.9s\n",
      "392:\tlearn: 0.4438818\ttotal: 6.4s\tremaining: 9.88s\n",
      "393:\tlearn: 0.4436250\ttotal: 6.41s\tremaining: 9.86s\n",
      "394:\tlearn: 0.4434186\ttotal: 6.43s\tremaining: 9.85s\n",
      "395:\tlearn: 0.4431686\ttotal: 6.45s\tremaining: 9.83s\n",
      "396:\tlearn: 0.4428776\ttotal: 6.46s\tremaining: 9.81s\n",
      "397:\tlearn: 0.4427032\ttotal: 6.47s\tremaining: 9.79s\n",
      "398:\tlearn: 0.4424856\ttotal: 6.49s\tremaining: 9.78s\n",
      "399:\tlearn: 0.4422648\ttotal: 6.51s\tremaining: 9.76s\n",
      "400:\tlearn: 0.4420813\ttotal: 6.52s\tremaining: 9.74s\n",
      "401:\tlearn: 0.4417989\ttotal: 6.54s\tremaining: 9.73s\n",
      "402:\tlearn: 0.4416307\ttotal: 6.55s\tremaining: 9.71s\n",
      "403:\tlearn: 0.4413788\ttotal: 6.57s\tremaining: 9.69s\n",
      "404:\tlearn: 0.4411231\ttotal: 6.58s\tremaining: 9.67s\n",
      "405:\tlearn: 0.4409105\ttotal: 6.6s\tremaining: 9.66s\n",
      "406:\tlearn: 0.4406402\ttotal: 6.62s\tremaining: 9.64s\n",
      "407:\tlearn: 0.4404280\ttotal: 6.63s\tremaining: 9.62s\n",
      "408:\tlearn: 0.4402149\ttotal: 6.65s\tremaining: 9.61s\n",
      "409:\tlearn: 0.4399929\ttotal: 6.66s\tremaining: 9.59s\n",
      "410:\tlearn: 0.4398003\ttotal: 6.68s\tremaining: 9.57s\n",
      "411:\tlearn: 0.4396071\ttotal: 6.69s\tremaining: 9.55s\n",
      "412:\tlearn: 0.4393316\ttotal: 6.71s\tremaining: 9.54s\n",
      "413:\tlearn: 0.4391271\ttotal: 6.72s\tremaining: 9.52s\n",
      "414:\tlearn: 0.4389167\ttotal: 6.74s\tremaining: 9.5s\n",
      "415:\tlearn: 0.4386519\ttotal: 6.76s\tremaining: 9.49s\n",
      "416:\tlearn: 0.4384545\ttotal: 6.78s\tremaining: 9.47s\n",
      "417:\tlearn: 0.4382058\ttotal: 6.79s\tremaining: 9.46s\n",
      "418:\tlearn: 0.4379198\ttotal: 6.81s\tremaining: 9.44s\n",
      "419:\tlearn: 0.4376449\ttotal: 6.82s\tremaining: 9.42s\n",
      "420:\tlearn: 0.4374675\ttotal: 6.84s\tremaining: 9.4s\n",
      "421:\tlearn: 0.4372398\ttotal: 6.85s\tremaining: 9.39s\n",
      "422:\tlearn: 0.4370827\ttotal: 6.87s\tremaining: 9.37s\n",
      "423:\tlearn: 0.4368254\ttotal: 6.88s\tremaining: 9.35s\n",
      "424:\tlearn: 0.4365728\ttotal: 6.9s\tremaining: 9.34s\n",
      "425:\tlearn: 0.4363354\ttotal: 6.92s\tremaining: 9.32s\n",
      "426:\tlearn: 0.4360387\ttotal: 6.93s\tremaining: 9.3s\n",
      "427:\tlearn: 0.4358230\ttotal: 6.95s\tremaining: 9.28s\n",
      "428:\tlearn: 0.4356306\ttotal: 6.96s\tremaining: 9.26s\n",
      "429:\tlearn: 0.4353969\ttotal: 6.97s\tremaining: 9.25s\n",
      "430:\tlearn: 0.4350928\ttotal: 6.99s\tremaining: 9.23s\n",
      "431:\tlearn: 0.4348823\ttotal: 7.01s\tremaining: 9.21s\n",
      "432:\tlearn: 0.4346558\ttotal: 7.02s\tremaining: 9.2s\n",
      "433:\tlearn: 0.4344597\ttotal: 7.04s\tremaining: 9.18s\n",
      "434:\tlearn: 0.4341972\ttotal: 7.05s\tremaining: 9.16s\n",
      "435:\tlearn: 0.4340363\ttotal: 7.07s\tremaining: 9.14s\n",
      "436:\tlearn: 0.4338146\ttotal: 7.08s\tremaining: 9.13s\n",
      "437:\tlearn: 0.4335857\ttotal: 7.1s\tremaining: 9.11s\n",
      "438:\tlearn: 0.4333654\ttotal: 7.12s\tremaining: 9.09s\n",
      "439:\tlearn: 0.4332159\ttotal: 7.13s\tremaining: 9.08s\n",
      "440:\tlearn: 0.4330177\ttotal: 7.15s\tremaining: 9.06s\n",
      "441:\tlearn: 0.4327844\ttotal: 7.16s\tremaining: 9.04s\n",
      "442:\tlearn: 0.4325613\ttotal: 7.18s\tremaining: 9.03s\n",
      "443:\tlearn: 0.4323584\ttotal: 7.19s\tremaining: 9.01s\n",
      "444:\tlearn: 0.4320729\ttotal: 7.21s\tremaining: 8.99s\n",
      "445:\tlearn: 0.4318571\ttotal: 7.23s\tremaining: 8.98s\n",
      "446:\tlearn: 0.4316127\ttotal: 7.24s\tremaining: 8.96s\n",
      "447:\tlearn: 0.4313199\ttotal: 7.26s\tremaining: 8.94s\n",
      "448:\tlearn: 0.4310889\ttotal: 7.28s\tremaining: 8.93s\n",
      "449:\tlearn: 0.4308018\ttotal: 7.29s\tremaining: 8.91s\n",
      "450:\tlearn: 0.4305960\ttotal: 7.31s\tremaining: 8.89s\n",
      "451:\tlearn: 0.4302967\ttotal: 7.32s\tremaining: 8.88s\n",
      "452:\tlearn: 0.4300291\ttotal: 7.34s\tremaining: 8.86s\n",
      "453:\tlearn: 0.4298399\ttotal: 7.35s\tremaining: 8.84s\n",
      "454:\tlearn: 0.4296401\ttotal: 7.37s\tremaining: 8.82s\n",
      "455:\tlearn: 0.4294049\ttotal: 7.38s\tremaining: 8.81s\n",
      "456:\tlearn: 0.4291424\ttotal: 7.4s\tremaining: 8.79s\n",
      "457:\tlearn: 0.4289259\ttotal: 7.41s\tremaining: 8.77s\n",
      "458:\tlearn: 0.4286806\ttotal: 7.43s\tremaining: 8.76s\n",
      "459:\tlearn: 0.4285266\ttotal: 7.45s\tremaining: 8.74s\n",
      "460:\tlearn: 0.4282705\ttotal: 7.46s\tremaining: 8.72s\n",
      "461:\tlearn: 0.4280645\ttotal: 7.48s\tremaining: 8.71s\n",
      "462:\tlearn: 0.4278572\ttotal: 7.49s\tremaining: 8.69s\n",
      "463:\tlearn: 0.4275735\ttotal: 7.51s\tremaining: 8.67s\n",
      "464:\tlearn: 0.4273198\ttotal: 7.52s\tremaining: 8.66s\n",
      "465:\tlearn: 0.4270556\ttotal: 7.54s\tremaining: 8.64s\n",
      "466:\tlearn: 0.4269173\ttotal: 7.55s\tremaining: 8.62s\n",
      "467:\tlearn: 0.4266790\ttotal: 7.57s\tremaining: 8.61s\n",
      "468:\tlearn: 0.4264306\ttotal: 7.58s\tremaining: 8.59s\n",
      "469:\tlearn: 0.4261649\ttotal: 7.6s\tremaining: 8.57s\n",
      "470:\tlearn: 0.4259004\ttotal: 7.62s\tremaining: 8.55s\n",
      "471:\tlearn: 0.4257149\ttotal: 7.63s\tremaining: 8.54s\n",
      "472:\tlearn: 0.4255298\ttotal: 7.65s\tremaining: 8.52s\n",
      "473:\tlearn: 0.4252874\ttotal: 7.66s\tremaining: 8.5s\n",
      "474:\tlearn: 0.4250767\ttotal: 7.68s\tremaining: 8.49s\n",
      "475:\tlearn: 0.4249042\ttotal: 7.7s\tremaining: 8.47s\n",
      "476:\tlearn: 0.4247214\ttotal: 7.71s\tremaining: 8.46s\n",
      "477:\tlearn: 0.4245028\ttotal: 7.73s\tremaining: 8.44s\n",
      "478:\tlearn: 0.4243475\ttotal: 7.75s\tremaining: 8.42s\n",
      "479:\tlearn: 0.4241055\ttotal: 7.76s\tremaining: 8.41s\n",
      "480:\tlearn: 0.4238728\ttotal: 7.78s\tremaining: 8.4s\n",
      "481:\tlearn: 0.4236351\ttotal: 7.8s\tremaining: 8.38s\n",
      "482:\tlearn: 0.4233978\ttotal: 7.81s\tremaining: 8.36s\n",
      "483:\tlearn: 0.4231809\ttotal: 7.83s\tremaining: 8.35s\n",
      "484:\tlearn: 0.4229336\ttotal: 7.84s\tremaining: 8.33s\n",
      "485:\tlearn: 0.4227763\ttotal: 7.86s\tremaining: 8.31s\n",
      "486:\tlearn: 0.4225449\ttotal: 7.88s\tremaining: 8.3s\n",
      "487:\tlearn: 0.4223208\ttotal: 7.89s\tremaining: 8.28s\n",
      "488:\tlearn: 0.4221487\ttotal: 7.91s\tremaining: 8.26s\n",
      "489:\tlearn: 0.4219027\ttotal: 7.92s\tremaining: 8.25s\n",
      "490:\tlearn: 0.4216506\ttotal: 7.94s\tremaining: 8.23s\n",
      "491:\tlearn: 0.4214053\ttotal: 7.96s\tremaining: 8.21s\n",
      "492:\tlearn: 0.4211854\ttotal: 7.97s\tremaining: 8.2s\n",
      "493:\tlearn: 0.4210385\ttotal: 7.99s\tremaining: 8.18s\n",
      "494:\tlearn: 0.4207883\ttotal: 8s\tremaining: 8.16s\n",
      "495:\tlearn: 0.4205329\ttotal: 8.02s\tremaining: 8.15s\n",
      "496:\tlearn: 0.4202927\ttotal: 8.03s\tremaining: 8.13s\n",
      "497:\tlearn: 0.4200444\ttotal: 8.05s\tremaining: 8.11s\n",
      "498:\tlearn: 0.4197858\ttotal: 8.06s\tremaining: 8.1s\n",
      "499:\tlearn: 0.4195450\ttotal: 8.08s\tremaining: 8.08s\n",
      "500:\tlearn: 0.4193562\ttotal: 8.09s\tremaining: 8.06s\n",
      "501:\tlearn: 0.4191144\ttotal: 8.11s\tremaining: 8.04s\n",
      "502:\tlearn: 0.4188577\ttotal: 8.13s\tremaining: 8.03s\n",
      "503:\tlearn: 0.4186722\ttotal: 8.14s\tremaining: 8.01s\n",
      "504:\tlearn: 0.4184056\ttotal: 8.15s\tremaining: 7.99s\n",
      "505:\tlearn: 0.4182010\ttotal: 8.17s\tremaining: 7.98s\n",
      "506:\tlearn: 0.4179597\ttotal: 8.19s\tremaining: 7.96s\n",
      "507:\tlearn: 0.4178001\ttotal: 8.2s\tremaining: 7.94s\n",
      "508:\tlearn: 0.4176367\ttotal: 8.22s\tremaining: 7.93s\n",
      "509:\tlearn: 0.4174797\ttotal: 8.23s\tremaining: 7.91s\n",
      "510:\tlearn: 0.4172825\ttotal: 8.25s\tremaining: 7.89s\n",
      "511:\tlearn: 0.4170574\ttotal: 8.26s\tremaining: 7.88s\n",
      "512:\tlearn: 0.4168944\ttotal: 8.28s\tremaining: 7.86s\n",
      "513:\tlearn: 0.4167008\ttotal: 8.29s\tremaining: 7.84s\n",
      "514:\tlearn: 0.4165291\ttotal: 8.31s\tremaining: 7.83s\n",
      "515:\tlearn: 0.4162104\ttotal: 8.32s\tremaining: 7.81s\n",
      "516:\tlearn: 0.4159996\ttotal: 8.34s\tremaining: 7.79s\n",
      "517:\tlearn: 0.4157670\ttotal: 8.36s\tremaining: 7.77s\n",
      "518:\tlearn: 0.4155952\ttotal: 8.37s\tremaining: 7.76s\n",
      "519:\tlearn: 0.4153801\ttotal: 8.38s\tremaining: 7.74s\n",
      "520:\tlearn: 0.4152141\ttotal: 8.4s\tremaining: 7.72s\n",
      "521:\tlearn: 0.4149874\ttotal: 8.41s\tremaining: 7.71s\n",
      "522:\tlearn: 0.4147731\ttotal: 8.43s\tremaining: 7.69s\n",
      "523:\tlearn: 0.4145232\ttotal: 8.45s\tremaining: 7.67s\n",
      "524:\tlearn: 0.4143344\ttotal: 8.46s\tremaining: 7.65s\n",
      "525:\tlearn: 0.4141621\ttotal: 8.47s\tremaining: 7.64s\n",
      "526:\tlearn: 0.4139214\ttotal: 8.49s\tremaining: 7.62s\n",
      "527:\tlearn: 0.4137519\ttotal: 8.51s\tremaining: 7.6s\n",
      "528:\tlearn: 0.4135277\ttotal: 8.52s\tremaining: 7.59s\n",
      "529:\tlearn: 0.4132696\ttotal: 8.54s\tremaining: 7.57s\n",
      "530:\tlearn: 0.4130324\ttotal: 8.55s\tremaining: 7.55s\n",
      "531:\tlearn: 0.4128874\ttotal: 8.56s\tremaining: 7.54s\n",
      "532:\tlearn: 0.4126874\ttotal: 8.58s\tremaining: 7.52s\n",
      "533:\tlearn: 0.4124607\ttotal: 8.6s\tremaining: 7.5s\n",
      "534:\tlearn: 0.4122151\ttotal: 8.61s\tremaining: 7.48s\n",
      "535:\tlearn: 0.4120063\ttotal: 8.63s\tremaining: 7.47s\n",
      "536:\tlearn: 0.4117994\ttotal: 8.64s\tremaining: 7.45s\n",
      "537:\tlearn: 0.4115844\ttotal: 8.66s\tremaining: 7.43s\n",
      "538:\tlearn: 0.4113272\ttotal: 8.67s\tremaining: 7.42s\n",
      "539:\tlearn: 0.4110676\ttotal: 8.69s\tremaining: 7.4s\n",
      "540:\tlearn: 0.4108284\ttotal: 8.7s\tremaining: 7.38s\n",
      "541:\tlearn: 0.4106521\ttotal: 8.72s\tremaining: 7.37s\n",
      "542:\tlearn: 0.4105157\ttotal: 8.73s\tremaining: 7.35s\n",
      "543:\tlearn: 0.4102666\ttotal: 8.75s\tremaining: 7.34s\n",
      "544:\tlearn: 0.4100321\ttotal: 8.77s\tremaining: 7.32s\n",
      "545:\tlearn: 0.4098334\ttotal: 8.79s\tremaining: 7.31s\n",
      "546:\tlearn: 0.4096297\ttotal: 8.8s\tremaining: 7.29s\n",
      "547:\tlearn: 0.4094837\ttotal: 8.82s\tremaining: 7.27s\n",
      "548:\tlearn: 0.4092799\ttotal: 8.83s\tremaining: 7.25s\n",
      "549:\tlearn: 0.4090704\ttotal: 8.85s\tremaining: 7.24s\n",
      "550:\tlearn: 0.4088383\ttotal: 8.86s\tremaining: 7.22s\n",
      "551:\tlearn: 0.4086702\ttotal: 8.88s\tremaining: 7.2s\n",
      "552:\tlearn: 0.4085016\ttotal: 8.89s\tremaining: 7.19s\n",
      "553:\tlearn: 0.4082809\ttotal: 8.91s\tremaining: 7.17s\n",
      "554:\tlearn: 0.4080558\ttotal: 8.92s\tremaining: 7.15s\n",
      "555:\tlearn: 0.4078359\ttotal: 8.94s\tremaining: 7.13s\n",
      "556:\tlearn: 0.4076438\ttotal: 8.95s\tremaining: 7.12s\n",
      "557:\tlearn: 0.4074364\ttotal: 8.97s\tremaining: 7.1s\n",
      "558:\tlearn: 0.4071600\ttotal: 8.98s\tremaining: 7.08s\n",
      "559:\tlearn: 0.4069575\ttotal: 9s\tremaining: 7.07s\n",
      "560:\tlearn: 0.4067842\ttotal: 9.01s\tremaining: 7.05s\n",
      "561:\tlearn: 0.4065519\ttotal: 9.03s\tremaining: 7.03s\n",
      "562:\tlearn: 0.4063406\ttotal: 9.04s\tremaining: 7.02s\n",
      "563:\tlearn: 0.4061321\ttotal: 9.05s\tremaining: 7s\n",
      "564:\tlearn: 0.4059577\ttotal: 9.07s\tremaining: 6.98s\n",
      "565:\tlearn: 0.4057260\ttotal: 9.08s\tremaining: 6.96s\n",
      "566:\tlearn: 0.4055809\ttotal: 9.1s\tremaining: 6.95s\n",
      "567:\tlearn: 0.4052698\ttotal: 9.11s\tremaining: 6.93s\n",
      "568:\tlearn: 0.4051006\ttotal: 9.13s\tremaining: 6.91s\n",
      "569:\tlearn: 0.4049266\ttotal: 9.14s\tremaining: 6.9s\n",
      "570:\tlearn: 0.4047095\ttotal: 9.16s\tremaining: 6.88s\n",
      "571:\tlearn: 0.4045609\ttotal: 9.17s\tremaining: 6.86s\n",
      "572:\tlearn: 0.4043399\ttotal: 9.19s\tremaining: 6.85s\n",
      "573:\tlearn: 0.4041734\ttotal: 9.2s\tremaining: 6.83s\n",
      "574:\tlearn: 0.4040098\ttotal: 9.22s\tremaining: 6.81s\n",
      "575:\tlearn: 0.4037938\ttotal: 9.23s\tremaining: 6.79s\n",
      "576:\tlearn: 0.4035660\ttotal: 9.25s\tremaining: 6.78s\n",
      "577:\tlearn: 0.4033298\ttotal: 9.26s\tremaining: 6.76s\n",
      "578:\tlearn: 0.4031186\ttotal: 9.28s\tremaining: 6.75s\n",
      "579:\tlearn: 0.4029454\ttotal: 9.29s\tremaining: 6.73s\n",
      "580:\tlearn: 0.4027238\ttotal: 9.31s\tremaining: 6.71s\n",
      "581:\tlearn: 0.4025513\ttotal: 9.32s\tremaining: 6.7s\n",
      "582:\tlearn: 0.4023431\ttotal: 9.34s\tremaining: 6.68s\n",
      "583:\tlearn: 0.4021250\ttotal: 9.35s\tremaining: 6.66s\n",
      "584:\tlearn: 0.4018935\ttotal: 9.37s\tremaining: 6.65s\n",
      "585:\tlearn: 0.4016727\ttotal: 9.38s\tremaining: 6.63s\n",
      "586:\tlearn: 0.4013877\ttotal: 9.4s\tremaining: 6.61s\n",
      "587:\tlearn: 0.4012204\ttotal: 9.41s\tremaining: 6.6s\n",
      "588:\tlearn: 0.4009692\ttotal: 9.43s\tremaining: 6.58s\n",
      "589:\tlearn: 0.4007624\ttotal: 9.46s\tremaining: 6.57s\n",
      "590:\tlearn: 0.4004853\ttotal: 9.47s\tremaining: 6.55s\n",
      "591:\tlearn: 0.4003306\ttotal: 9.49s\tremaining: 6.54s\n",
      "592:\tlearn: 0.4000949\ttotal: 9.5s\tremaining: 6.52s\n",
      "593:\tlearn: 0.3999499\ttotal: 9.52s\tremaining: 6.51s\n",
      "594:\tlearn: 0.3997186\ttotal: 9.53s\tremaining: 6.49s\n",
      "595:\tlearn: 0.3995078\ttotal: 9.55s\tremaining: 6.47s\n",
      "596:\tlearn: 0.3993059\ttotal: 9.56s\tremaining: 6.46s\n",
      "597:\tlearn: 0.3990622\ttotal: 9.58s\tremaining: 6.44s\n",
      "598:\tlearn: 0.3988522\ttotal: 9.6s\tremaining: 6.42s\n",
      "599:\tlearn: 0.3986609\ttotal: 9.61s\tremaining: 6.41s\n",
      "600:\tlearn: 0.3984395\ttotal: 9.63s\tremaining: 6.39s\n",
      "601:\tlearn: 0.3982650\ttotal: 9.64s\tremaining: 6.37s\n",
      "602:\tlearn: 0.3980596\ttotal: 9.65s\tremaining: 6.36s\n",
      "603:\tlearn: 0.3978616\ttotal: 9.67s\tremaining: 6.34s\n",
      "604:\tlearn: 0.3975943\ttotal: 9.69s\tremaining: 6.32s\n",
      "605:\tlearn: 0.3974374\ttotal: 9.7s\tremaining: 6.31s\n",
      "606:\tlearn: 0.3972936\ttotal: 9.71s\tremaining: 6.29s\n",
      "607:\tlearn: 0.3971065\ttotal: 9.73s\tremaining: 6.28s\n",
      "608:\tlearn: 0.3969615\ttotal: 9.75s\tremaining: 6.26s\n",
      "609:\tlearn: 0.3966959\ttotal: 9.77s\tremaining: 6.24s\n",
      "610:\tlearn: 0.3964819\ttotal: 9.78s\tremaining: 6.23s\n",
      "611:\tlearn: 0.3962833\ttotal: 9.8s\tremaining: 6.21s\n",
      "612:\tlearn: 0.3960574\ttotal: 9.81s\tremaining: 6.2s\n",
      "613:\tlearn: 0.3958793\ttotal: 9.83s\tremaining: 6.18s\n",
      "614:\tlearn: 0.3956135\ttotal: 9.84s\tremaining: 6.16s\n",
      "615:\tlearn: 0.3953245\ttotal: 9.86s\tremaining: 6.14s\n",
      "616:\tlearn: 0.3951195\ttotal: 9.87s\tremaining: 6.13s\n",
      "617:\tlearn: 0.3948791\ttotal: 9.89s\tremaining: 6.11s\n",
      "618:\tlearn: 0.3947184\ttotal: 9.9s\tremaining: 6.09s\n",
      "619:\tlearn: 0.3945938\ttotal: 9.92s\tremaining: 6.08s\n",
      "620:\tlearn: 0.3943960\ttotal: 9.93s\tremaining: 6.06s\n",
      "621:\tlearn: 0.3941586\ttotal: 9.95s\tremaining: 6.04s\n",
      "622:\tlearn: 0.3939476\ttotal: 9.96s\tremaining: 6.03s\n",
      "623:\tlearn: 0.3937358\ttotal: 9.98s\tremaining: 6.01s\n",
      "624:\tlearn: 0.3935302\ttotal: 9.99s\tremaining: 5.99s\n",
      "625:\tlearn: 0.3932757\ttotal: 10s\tremaining: 5.98s\n",
      "626:\tlearn: 0.3930327\ttotal: 10s\tremaining: 5.96s\n",
      "627:\tlearn: 0.3928036\ttotal: 10s\tremaining: 5.95s\n",
      "628:\tlearn: 0.3925977\ttotal: 10.1s\tremaining: 5.93s\n",
      "629:\tlearn: 0.3923467\ttotal: 10.1s\tremaining: 5.91s\n",
      "630:\tlearn: 0.3921113\ttotal: 10.1s\tremaining: 5.9s\n",
      "631:\tlearn: 0.3918863\ttotal: 10.1s\tremaining: 5.88s\n",
      "632:\tlearn: 0.3916965\ttotal: 10.1s\tremaining: 5.86s\n",
      "633:\tlearn: 0.3915125\ttotal: 10.1s\tremaining: 5.84s\n",
      "634:\tlearn: 0.3913226\ttotal: 10.1s\tremaining: 5.83s\n",
      "635:\tlearn: 0.3911493\ttotal: 10.2s\tremaining: 5.81s\n",
      "636:\tlearn: 0.3910023\ttotal: 10.2s\tremaining: 5.79s\n",
      "637:\tlearn: 0.3907842\ttotal: 10.2s\tremaining: 5.78s\n",
      "638:\tlearn: 0.3905466\ttotal: 10.2s\tremaining: 5.76s\n",
      "639:\tlearn: 0.3903238\ttotal: 10.2s\tremaining: 5.74s\n",
      "640:\tlearn: 0.3901067\ttotal: 10.2s\tremaining: 5.73s\n",
      "641:\tlearn: 0.3899346\ttotal: 10.2s\tremaining: 5.71s\n",
      "642:\tlearn: 0.3896843\ttotal: 10.3s\tremaining: 5.69s\n",
      "643:\tlearn: 0.3895276\ttotal: 10.3s\tremaining: 5.68s\n",
      "644:\tlearn: 0.3893761\ttotal: 10.3s\tremaining: 5.66s\n",
      "645:\tlearn: 0.3891673\ttotal: 10.3s\tremaining: 5.65s\n",
      "646:\tlearn: 0.3889509\ttotal: 10.3s\tremaining: 5.63s\n",
      "647:\tlearn: 0.3887425\ttotal: 10.3s\tremaining: 5.61s\n",
      "648:\tlearn: 0.3886008\ttotal: 10.4s\tremaining: 5.6s\n",
      "649:\tlearn: 0.3883784\ttotal: 10.4s\tremaining: 5.59s\n",
      "650:\tlearn: 0.3882023\ttotal: 10.4s\tremaining: 5.57s\n",
      "651:\tlearn: 0.3879836\ttotal: 10.4s\tremaining: 5.55s\n",
      "652:\tlearn: 0.3878031\ttotal: 10.4s\tremaining: 5.54s\n",
      "653:\tlearn: 0.3876641\ttotal: 10.4s\tremaining: 5.52s\n",
      "654:\tlearn: 0.3874480\ttotal: 10.5s\tremaining: 5.51s\n",
      "655:\tlearn: 0.3872032\ttotal: 10.5s\tremaining: 5.49s\n",
      "656:\tlearn: 0.3869850\ttotal: 10.5s\tremaining: 5.47s\n",
      "657:\tlearn: 0.3867453\ttotal: 10.5s\tremaining: 5.46s\n",
      "658:\tlearn: 0.3865766\ttotal: 10.5s\tremaining: 5.44s\n",
      "659:\tlearn: 0.3863606\ttotal: 10.5s\tremaining: 5.42s\n",
      "660:\tlearn: 0.3861954\ttotal: 10.5s\tremaining: 5.41s\n",
      "661:\tlearn: 0.3860320\ttotal: 10.6s\tremaining: 5.39s\n",
      "662:\tlearn: 0.3858408\ttotal: 10.6s\tremaining: 5.38s\n",
      "663:\tlearn: 0.3856662\ttotal: 10.6s\tremaining: 5.36s\n",
      "664:\tlearn: 0.3855386\ttotal: 10.6s\tremaining: 5.34s\n",
      "665:\tlearn: 0.3853130\ttotal: 10.6s\tremaining: 5.33s\n",
      "666:\tlearn: 0.3850963\ttotal: 10.6s\tremaining: 5.31s\n",
      "667:\tlearn: 0.3849021\ttotal: 10.7s\tremaining: 5.29s\n",
      "668:\tlearn: 0.3846763\ttotal: 10.7s\tremaining: 5.28s\n",
      "669:\tlearn: 0.3844777\ttotal: 10.7s\tremaining: 5.26s\n",
      "670:\tlearn: 0.3842689\ttotal: 10.7s\tremaining: 5.25s\n",
      "671:\tlearn: 0.3840767\ttotal: 10.7s\tremaining: 5.23s\n",
      "672:\tlearn: 0.3839227\ttotal: 10.7s\tremaining: 5.21s\n",
      "673:\tlearn: 0.3837373\ttotal: 10.8s\tremaining: 5.2s\n",
      "674:\tlearn: 0.3835407\ttotal: 10.8s\tremaining: 5.18s\n",
      "675:\tlearn: 0.3833952\ttotal: 10.8s\tremaining: 5.17s\n",
      "676:\tlearn: 0.3831900\ttotal: 10.8s\tremaining: 5.15s\n",
      "677:\tlearn: 0.3830160\ttotal: 10.8s\tremaining: 5.13s\n",
      "678:\tlearn: 0.3827889\ttotal: 10.8s\tremaining: 5.12s\n",
      "679:\tlearn: 0.3826135\ttotal: 10.8s\tremaining: 5.1s\n",
      "680:\tlearn: 0.3824500\ttotal: 10.9s\tremaining: 5.08s\n",
      "681:\tlearn: 0.3823208\ttotal: 10.9s\tremaining: 5.07s\n",
      "682:\tlearn: 0.3821234\ttotal: 10.9s\tremaining: 5.05s\n",
      "683:\tlearn: 0.3819395\ttotal: 10.9s\tremaining: 5.04s\n",
      "684:\tlearn: 0.3817375\ttotal: 10.9s\tremaining: 5.02s\n",
      "685:\tlearn: 0.3815256\ttotal: 10.9s\tremaining: 5s\n",
      "686:\tlearn: 0.3813582\ttotal: 10.9s\tremaining: 4.99s\n",
      "687:\tlearn: 0.3811269\ttotal: 11s\tremaining: 4.97s\n",
      "688:\tlearn: 0.3808994\ttotal: 11s\tremaining: 4.95s\n",
      "689:\tlearn: 0.3807497\ttotal: 11s\tremaining: 4.94s\n",
      "690:\tlearn: 0.3805335\ttotal: 11s\tremaining: 4.92s\n",
      "691:\tlearn: 0.3803579\ttotal: 11s\tremaining: 4.9s\n",
      "692:\tlearn: 0.3801798\ttotal: 11s\tremaining: 4.89s\n",
      "693:\tlearn: 0.3800108\ttotal: 11s\tremaining: 4.87s\n",
      "694:\tlearn: 0.3798731\ttotal: 11.1s\tremaining: 4.85s\n",
      "695:\tlearn: 0.3796789\ttotal: 11.1s\tremaining: 4.84s\n",
      "696:\tlearn: 0.3795167\ttotal: 11.1s\tremaining: 4.82s\n",
      "697:\tlearn: 0.3793909\ttotal: 11.1s\tremaining: 4.81s\n",
      "698:\tlearn: 0.3792044\ttotal: 11.1s\tremaining: 4.79s\n",
      "699:\tlearn: 0.3790046\ttotal: 11.1s\tremaining: 4.77s\n",
      "700:\tlearn: 0.3787853\ttotal: 11.2s\tremaining: 4.76s\n",
      "701:\tlearn: 0.3786457\ttotal: 11.2s\tremaining: 4.74s\n",
      "702:\tlearn: 0.3784767\ttotal: 11.2s\tremaining: 4.72s\n",
      "703:\tlearn: 0.3783414\ttotal: 11.2s\tremaining: 4.71s\n",
      "704:\tlearn: 0.3780926\ttotal: 11.2s\tremaining: 4.69s\n",
      "705:\tlearn: 0.3778653\ttotal: 11.2s\tremaining: 4.68s\n",
      "706:\tlearn: 0.3776427\ttotal: 11.2s\tremaining: 4.66s\n",
      "707:\tlearn: 0.3774996\ttotal: 11.3s\tremaining: 4.64s\n",
      "708:\tlearn: 0.3773842\ttotal: 11.3s\tremaining: 4.63s\n",
      "709:\tlearn: 0.3771646\ttotal: 11.3s\tremaining: 4.61s\n",
      "710:\tlearn: 0.3769939\ttotal: 11.3s\tremaining: 4.6s\n",
      "711:\tlearn: 0.3768067\ttotal: 11.3s\tremaining: 4.58s\n",
      "712:\tlearn: 0.3765982\ttotal: 11.3s\tremaining: 4.56s\n",
      "713:\tlearn: 0.3764468\ttotal: 11.4s\tremaining: 4.55s\n",
      "714:\tlearn: 0.3762581\ttotal: 11.4s\tremaining: 4.53s\n",
      "715:\tlearn: 0.3760564\ttotal: 11.4s\tremaining: 4.51s\n",
      "716:\tlearn: 0.3758286\ttotal: 11.4s\tremaining: 4.5s\n",
      "717:\tlearn: 0.3756858\ttotal: 11.4s\tremaining: 4.48s\n",
      "718:\tlearn: 0.3755142\ttotal: 11.4s\tremaining: 4.47s\n",
      "719:\tlearn: 0.3753479\ttotal: 11.4s\tremaining: 4.45s\n",
      "720:\tlearn: 0.3751138\ttotal: 11.5s\tremaining: 4.43s\n",
      "721:\tlearn: 0.3749375\ttotal: 11.5s\tremaining: 4.42s\n",
      "722:\tlearn: 0.3747772\ttotal: 11.5s\tremaining: 4.4s\n",
      "723:\tlearn: 0.3746097\ttotal: 11.5s\tremaining: 4.38s\n",
      "724:\tlearn: 0.3744483\ttotal: 11.5s\tremaining: 4.37s\n",
      "725:\tlearn: 0.3742623\ttotal: 11.5s\tremaining: 4.35s\n",
      "726:\tlearn: 0.3740380\ttotal: 11.5s\tremaining: 4.34s\n",
      "727:\tlearn: 0.3738417\ttotal: 11.6s\tremaining: 4.32s\n",
      "728:\tlearn: 0.3736715\ttotal: 11.6s\tremaining: 4.3s\n",
      "729:\tlearn: 0.3734659\ttotal: 11.6s\tremaining: 4.29s\n",
      "730:\tlearn: 0.3733290\ttotal: 11.6s\tremaining: 4.27s\n",
      "731:\tlearn: 0.3731195\ttotal: 11.6s\tremaining: 4.26s\n",
      "732:\tlearn: 0.3729735\ttotal: 11.6s\tremaining: 4.24s\n",
      "733:\tlearn: 0.3727778\ttotal: 11.7s\tremaining: 4.22s\n",
      "734:\tlearn: 0.3726081\ttotal: 11.7s\tremaining: 4.21s\n",
      "735:\tlearn: 0.3724358\ttotal: 11.7s\tremaining: 4.19s\n",
      "736:\tlearn: 0.3722545\ttotal: 11.7s\tremaining: 4.17s\n",
      "737:\tlearn: 0.3720175\ttotal: 11.7s\tremaining: 4.16s\n",
      "738:\tlearn: 0.3718613\ttotal: 11.7s\tremaining: 4.14s\n",
      "739:\tlearn: 0.3716618\ttotal: 11.8s\tremaining: 4.13s\n",
      "740:\tlearn: 0.3714429\ttotal: 11.8s\tremaining: 4.11s\n",
      "741:\tlearn: 0.3712270\ttotal: 11.8s\tremaining: 4.1s\n",
      "742:\tlearn: 0.3710306\ttotal: 11.8s\tremaining: 4.08s\n",
      "743:\tlearn: 0.3708619\ttotal: 11.8s\tremaining: 4.06s\n",
      "744:\tlearn: 0.3706804\ttotal: 11.8s\tremaining: 4.05s\n",
      "745:\tlearn: 0.3704629\ttotal: 11.8s\tremaining: 4.03s\n",
      "746:\tlearn: 0.3702558\ttotal: 11.9s\tremaining: 4.01s\n",
      "747:\tlearn: 0.3701011\ttotal: 11.9s\tremaining: 4s\n",
      "748:\tlearn: 0.3699743\ttotal: 11.9s\tremaining: 3.98s\n",
      "749:\tlearn: 0.3697863\ttotal: 11.9s\tremaining: 3.97s\n",
      "750:\tlearn: 0.3696763\ttotal: 11.9s\tremaining: 3.95s\n",
      "751:\tlearn: 0.3695272\ttotal: 11.9s\tremaining: 3.93s\n",
      "752:\tlearn: 0.3692720\ttotal: 11.9s\tremaining: 3.92s\n",
      "753:\tlearn: 0.3691546\ttotal: 12s\tremaining: 3.9s\n",
      "754:\tlearn: 0.3689492\ttotal: 12s\tremaining: 3.89s\n",
      "755:\tlearn: 0.3687931\ttotal: 12s\tremaining: 3.87s\n",
      "756:\tlearn: 0.3685990\ttotal: 12s\tremaining: 3.85s\n",
      "757:\tlearn: 0.3684153\ttotal: 12s\tremaining: 3.84s\n",
      "758:\tlearn: 0.3682136\ttotal: 12s\tremaining: 3.82s\n",
      "759:\tlearn: 0.3680171\ttotal: 12s\tremaining: 3.8s\n",
      "760:\tlearn: 0.3677626\ttotal: 12.1s\tremaining: 3.79s\n",
      "761:\tlearn: 0.3675986\ttotal: 12.1s\tremaining: 3.77s\n",
      "762:\tlearn: 0.3674262\ttotal: 12.1s\tremaining: 3.76s\n",
      "763:\tlearn: 0.3672346\ttotal: 12.1s\tremaining: 3.74s\n",
      "764:\tlearn: 0.3670901\ttotal: 12.1s\tremaining: 3.72s\n",
      "765:\tlearn: 0.3669348\ttotal: 12.1s\tremaining: 3.71s\n",
      "766:\tlearn: 0.3667549\ttotal: 12.2s\tremaining: 3.69s\n",
      "767:\tlearn: 0.3666109\ttotal: 12.2s\tremaining: 3.67s\n",
      "768:\tlearn: 0.3664339\ttotal: 12.2s\tremaining: 3.66s\n",
      "769:\tlearn: 0.3662873\ttotal: 12.2s\tremaining: 3.64s\n",
      "770:\tlearn: 0.3661259\ttotal: 12.2s\tremaining: 3.63s\n",
      "771:\tlearn: 0.3659407\ttotal: 12.2s\tremaining: 3.61s\n",
      "772:\tlearn: 0.3657859\ttotal: 12.2s\tremaining: 3.59s\n",
      "773:\tlearn: 0.3656270\ttotal: 12.3s\tremaining: 3.58s\n",
      "774:\tlearn: 0.3654756\ttotal: 12.3s\tremaining: 3.56s\n",
      "775:\tlearn: 0.3652808\ttotal: 12.3s\tremaining: 3.54s\n",
      "776:\tlearn: 0.3651142\ttotal: 12.3s\tremaining: 3.53s\n",
      "777:\tlearn: 0.3649289\ttotal: 12.3s\tremaining: 3.51s\n",
      "778:\tlearn: 0.3647856\ttotal: 12.3s\tremaining: 3.5s\n",
      "779:\tlearn: 0.3645827\ttotal: 12.3s\tremaining: 3.48s\n",
      "780:\tlearn: 0.3644000\ttotal: 12.4s\tremaining: 3.46s\n",
      "781:\tlearn: 0.3642006\ttotal: 12.4s\tremaining: 3.45s\n",
      "782:\tlearn: 0.3639928\ttotal: 12.4s\tremaining: 3.43s\n",
      "783:\tlearn: 0.3638353\ttotal: 12.4s\tremaining: 3.42s\n",
      "784:\tlearn: 0.3636249\ttotal: 12.4s\tremaining: 3.4s\n",
      "785:\tlearn: 0.3633870\ttotal: 12.4s\tremaining: 3.38s\n",
      "786:\tlearn: 0.3631945\ttotal: 12.4s\tremaining: 3.37s\n",
      "787:\tlearn: 0.3629931\ttotal: 12.5s\tremaining: 3.35s\n",
      "788:\tlearn: 0.3628122\ttotal: 12.5s\tremaining: 3.34s\n",
      "789:\tlearn: 0.3626757\ttotal: 12.5s\tremaining: 3.32s\n",
      "790:\tlearn: 0.3625385\ttotal: 12.5s\tremaining: 3.3s\n",
      "791:\tlearn: 0.3623691\ttotal: 12.5s\tremaining: 3.29s\n",
      "792:\tlearn: 0.3622110\ttotal: 12.5s\tremaining: 3.27s\n",
      "793:\tlearn: 0.3620114\ttotal: 12.6s\tremaining: 3.26s\n",
      "794:\tlearn: 0.3618599\ttotal: 12.6s\tremaining: 3.24s\n",
      "795:\tlearn: 0.3616901\ttotal: 12.6s\tremaining: 3.22s\n",
      "796:\tlearn: 0.3615572\ttotal: 12.6s\tremaining: 3.21s\n",
      "797:\tlearn: 0.3614459\ttotal: 12.6s\tremaining: 3.19s\n",
      "798:\tlearn: 0.3612105\ttotal: 12.6s\tremaining: 3.18s\n",
      "799:\tlearn: 0.3610440\ttotal: 12.6s\tremaining: 3.16s\n",
      "800:\tlearn: 0.3608492\ttotal: 12.7s\tremaining: 3.14s\n",
      "801:\tlearn: 0.3607075\ttotal: 12.7s\tremaining: 3.13s\n",
      "802:\tlearn: 0.3605505\ttotal: 12.7s\tremaining: 3.11s\n",
      "803:\tlearn: 0.3603502\ttotal: 12.7s\tremaining: 3.1s\n",
      "804:\tlearn: 0.3601351\ttotal: 12.7s\tremaining: 3.08s\n",
      "805:\tlearn: 0.3600522\ttotal: 12.7s\tremaining: 3.06s\n",
      "806:\tlearn: 0.3599423\ttotal: 12.8s\tremaining: 3.05s\n",
      "807:\tlearn: 0.3597565\ttotal: 12.8s\tremaining: 3.03s\n",
      "808:\tlearn: 0.3595851\ttotal: 12.8s\tremaining: 3.02s\n",
      "809:\tlearn: 0.3594783\ttotal: 12.8s\tremaining: 3s\n",
      "810:\tlearn: 0.3593544\ttotal: 12.8s\tremaining: 2.99s\n",
      "811:\tlearn: 0.3592148\ttotal: 12.8s\tremaining: 2.97s\n",
      "812:\tlearn: 0.3590568\ttotal: 12.8s\tremaining: 2.95s\n",
      "813:\tlearn: 0.3588454\ttotal: 12.9s\tremaining: 2.94s\n",
      "814:\tlearn: 0.3586914\ttotal: 12.9s\tremaining: 2.92s\n",
      "815:\tlearn: 0.3585165\ttotal: 12.9s\tremaining: 2.9s\n",
      "816:\tlearn: 0.3583791\ttotal: 12.9s\tremaining: 2.89s\n",
      "817:\tlearn: 0.3582056\ttotal: 12.9s\tremaining: 2.87s\n",
      "818:\tlearn: 0.3580248\ttotal: 12.9s\tremaining: 2.86s\n",
      "819:\tlearn: 0.3578224\ttotal: 12.9s\tremaining: 2.84s\n",
      "820:\tlearn: 0.3576230\ttotal: 13s\tremaining: 2.83s\n",
      "821:\tlearn: 0.3574549\ttotal: 13s\tremaining: 2.81s\n",
      "822:\tlearn: 0.3572894\ttotal: 13s\tremaining: 2.79s\n",
      "823:\tlearn: 0.3570915\ttotal: 13s\tremaining: 2.78s\n",
      "824:\tlearn: 0.3568645\ttotal: 13s\tremaining: 2.76s\n",
      "825:\tlearn: 0.3567066\ttotal: 13s\tremaining: 2.75s\n",
      "826:\tlearn: 0.3565709\ttotal: 13.1s\tremaining: 2.73s\n",
      "827:\tlearn: 0.3563922\ttotal: 13.1s\tremaining: 2.71s\n",
      "828:\tlearn: 0.3561718\ttotal: 13.1s\tremaining: 2.7s\n",
      "829:\tlearn: 0.3560112\ttotal: 13.1s\tremaining: 2.68s\n",
      "830:\tlearn: 0.3557991\ttotal: 13.1s\tremaining: 2.67s\n",
      "831:\tlearn: 0.3556200\ttotal: 13.1s\tremaining: 2.65s\n",
      "832:\tlearn: 0.3554346\ttotal: 13.1s\tremaining: 2.63s\n",
      "833:\tlearn: 0.3552743\ttotal: 13.2s\tremaining: 2.62s\n",
      "834:\tlearn: 0.3551525\ttotal: 13.2s\tremaining: 2.6s\n",
      "835:\tlearn: 0.3549522\ttotal: 13.2s\tremaining: 2.59s\n",
      "836:\tlearn: 0.3548146\ttotal: 13.2s\tremaining: 2.57s\n",
      "837:\tlearn: 0.3546705\ttotal: 13.2s\tremaining: 2.55s\n",
      "838:\tlearn: 0.3545025\ttotal: 13.2s\tremaining: 2.54s\n",
      "839:\tlearn: 0.3543161\ttotal: 13.2s\tremaining: 2.52s\n",
      "840:\tlearn: 0.3540899\ttotal: 13.3s\tremaining: 2.51s\n",
      "841:\tlearn: 0.3538933\ttotal: 13.3s\tremaining: 2.49s\n",
      "842:\tlearn: 0.3537258\ttotal: 13.3s\tremaining: 2.48s\n",
      "843:\tlearn: 0.3536074\ttotal: 13.3s\tremaining: 2.46s\n",
      "844:\tlearn: 0.3535035\ttotal: 13.3s\tremaining: 2.44s\n",
      "845:\tlearn: 0.3533049\ttotal: 13.3s\tremaining: 2.43s\n",
      "846:\tlearn: 0.3531540\ttotal: 13.3s\tremaining: 2.41s\n",
      "847:\tlearn: 0.3530057\ttotal: 13.4s\tremaining: 2.4s\n",
      "848:\tlearn: 0.3527915\ttotal: 13.4s\tremaining: 2.38s\n",
      "849:\tlearn: 0.3526296\ttotal: 13.4s\tremaining: 2.36s\n",
      "850:\tlearn: 0.3524438\ttotal: 13.4s\tremaining: 2.35s\n",
      "851:\tlearn: 0.3522284\ttotal: 13.4s\tremaining: 2.33s\n",
      "852:\tlearn: 0.3520285\ttotal: 13.4s\tremaining: 2.32s\n",
      "853:\tlearn: 0.3518698\ttotal: 13.5s\tremaining: 2.3s\n",
      "854:\tlearn: 0.3517058\ttotal: 13.5s\tremaining: 2.28s\n",
      "855:\tlearn: 0.3515277\ttotal: 13.5s\tremaining: 2.27s\n",
      "856:\tlearn: 0.3513650\ttotal: 13.5s\tremaining: 2.25s\n",
      "857:\tlearn: 0.3511987\ttotal: 13.5s\tremaining: 2.24s\n",
      "858:\tlearn: 0.3510113\ttotal: 13.5s\tremaining: 2.22s\n",
      "859:\tlearn: 0.3508637\ttotal: 13.5s\tremaining: 2.21s\n",
      "860:\tlearn: 0.3506762\ttotal: 13.6s\tremaining: 2.19s\n",
      "861:\tlearn: 0.3505075\ttotal: 13.6s\tremaining: 2.17s\n",
      "862:\tlearn: 0.3503486\ttotal: 13.6s\tremaining: 2.16s\n",
      "863:\tlearn: 0.3501805\ttotal: 13.6s\tremaining: 2.14s\n",
      "864:\tlearn: 0.3500126\ttotal: 13.6s\tremaining: 2.13s\n",
      "865:\tlearn: 0.3498651\ttotal: 13.6s\tremaining: 2.11s\n",
      "866:\tlearn: 0.3496900\ttotal: 13.7s\tremaining: 2.09s\n",
      "867:\tlearn: 0.3495395\ttotal: 13.7s\tremaining: 2.08s\n",
      "868:\tlearn: 0.3493855\ttotal: 13.7s\tremaining: 2.06s\n",
      "869:\tlearn: 0.3492181\ttotal: 13.7s\tremaining: 2.05s\n",
      "870:\tlearn: 0.3490709\ttotal: 13.7s\tremaining: 2.03s\n",
      "871:\tlearn: 0.3488593\ttotal: 13.7s\tremaining: 2.02s\n",
      "872:\tlearn: 0.3487491\ttotal: 13.7s\tremaining: 2s\n",
      "873:\tlearn: 0.3485973\ttotal: 13.8s\tremaining: 1.98s\n",
      "874:\tlearn: 0.3484296\ttotal: 13.8s\tremaining: 1.97s\n",
      "875:\tlearn: 0.3482801\ttotal: 13.8s\tremaining: 1.95s\n",
      "876:\tlearn: 0.3480931\ttotal: 13.8s\tremaining: 1.94s\n",
      "877:\tlearn: 0.3479597\ttotal: 13.8s\tremaining: 1.92s\n",
      "878:\tlearn: 0.3477666\ttotal: 13.8s\tremaining: 1.9s\n",
      "879:\tlearn: 0.3476385\ttotal: 13.9s\tremaining: 1.89s\n",
      "880:\tlearn: 0.3474345\ttotal: 13.9s\tremaining: 1.87s\n",
      "881:\tlearn: 0.3472635\ttotal: 13.9s\tremaining: 1.86s\n",
      "882:\tlearn: 0.3470866\ttotal: 13.9s\tremaining: 1.84s\n",
      "883:\tlearn: 0.3469293\ttotal: 13.9s\tremaining: 1.82s\n",
      "884:\tlearn: 0.3467505\ttotal: 13.9s\tremaining: 1.81s\n",
      "885:\tlearn: 0.3466081\ttotal: 13.9s\tremaining: 1.79s\n",
      "886:\tlearn: 0.3464929\ttotal: 14s\tremaining: 1.78s\n",
      "887:\tlearn: 0.3463310\ttotal: 14s\tremaining: 1.76s\n",
      "888:\tlearn: 0.3462292\ttotal: 14s\tremaining: 1.75s\n",
      "889:\tlearn: 0.3460582\ttotal: 14s\tremaining: 1.73s\n",
      "890:\tlearn: 0.3458640\ttotal: 14s\tremaining: 1.71s\n",
      "891:\tlearn: 0.3457153\ttotal: 14s\tremaining: 1.7s\n",
      "892:\tlearn: 0.3455602\ttotal: 14s\tremaining: 1.68s\n",
      "893:\tlearn: 0.3454503\ttotal: 14.1s\tremaining: 1.67s\n",
      "894:\tlearn: 0.3452859\ttotal: 14.1s\tremaining: 1.65s\n",
      "895:\tlearn: 0.3451438\ttotal: 14.1s\tremaining: 1.64s\n",
      "896:\tlearn: 0.3449869\ttotal: 14.1s\tremaining: 1.62s\n",
      "897:\tlearn: 0.3448340\ttotal: 14.1s\tremaining: 1.6s\n",
      "898:\tlearn: 0.3446288\ttotal: 14.1s\tremaining: 1.59s\n",
      "899:\tlearn: 0.3444570\ttotal: 14.2s\tremaining: 1.57s\n",
      "900:\tlearn: 0.3442928\ttotal: 14.2s\tremaining: 1.56s\n",
      "901:\tlearn: 0.3441776\ttotal: 14.2s\tremaining: 1.54s\n",
      "902:\tlearn: 0.3439917\ttotal: 14.2s\tremaining: 1.52s\n",
      "903:\tlearn: 0.3438611\ttotal: 14.2s\tremaining: 1.51s\n",
      "904:\tlearn: 0.3436985\ttotal: 14.2s\tremaining: 1.49s\n",
      "905:\tlearn: 0.3434868\ttotal: 14.2s\tremaining: 1.48s\n",
      "906:\tlearn: 0.3433194\ttotal: 14.3s\tremaining: 1.46s\n",
      "907:\tlearn: 0.3431951\ttotal: 14.3s\tremaining: 1.45s\n",
      "908:\tlearn: 0.3430107\ttotal: 14.3s\tremaining: 1.43s\n",
      "909:\tlearn: 0.3428592\ttotal: 14.3s\tremaining: 1.41s\n",
      "910:\tlearn: 0.3426903\ttotal: 14.3s\tremaining: 1.4s\n",
      "911:\tlearn: 0.3425501\ttotal: 14.3s\tremaining: 1.38s\n",
      "912:\tlearn: 0.3424092\ttotal: 14.3s\tremaining: 1.37s\n",
      "913:\tlearn: 0.3422522\ttotal: 14.4s\tremaining: 1.35s\n",
      "914:\tlearn: 0.3420689\ttotal: 14.4s\tremaining: 1.33s\n",
      "915:\tlearn: 0.3419285\ttotal: 14.4s\tremaining: 1.32s\n",
      "916:\tlearn: 0.3417838\ttotal: 14.4s\tremaining: 1.3s\n",
      "917:\tlearn: 0.3416246\ttotal: 14.4s\tremaining: 1.29s\n",
      "918:\tlearn: 0.3414684\ttotal: 14.4s\tremaining: 1.27s\n",
      "919:\tlearn: 0.3413113\ttotal: 14.4s\tremaining: 1.26s\n",
      "920:\tlearn: 0.3411170\ttotal: 14.5s\tremaining: 1.24s\n",
      "921:\tlearn: 0.3409539\ttotal: 14.5s\tremaining: 1.22s\n",
      "922:\tlearn: 0.3408124\ttotal: 14.5s\tremaining: 1.21s\n",
      "923:\tlearn: 0.3407294\ttotal: 14.5s\tremaining: 1.19s\n",
      "924:\tlearn: 0.3405850\ttotal: 14.5s\tremaining: 1.18s\n",
      "925:\tlearn: 0.3404655\ttotal: 14.5s\tremaining: 1.16s\n",
      "926:\tlearn: 0.3402761\ttotal: 14.6s\tremaining: 1.15s\n",
      "927:\tlearn: 0.3401147\ttotal: 14.6s\tremaining: 1.13s\n",
      "928:\tlearn: 0.3399613\ttotal: 14.6s\tremaining: 1.11s\n",
      "929:\tlearn: 0.3398529\ttotal: 14.6s\tremaining: 1.1s\n",
      "930:\tlearn: 0.3397224\ttotal: 14.6s\tremaining: 1.08s\n",
      "931:\tlearn: 0.3395355\ttotal: 14.6s\tremaining: 1.07s\n",
      "932:\tlearn: 0.3393600\ttotal: 14.6s\tremaining: 1.05s\n",
      "933:\tlearn: 0.3392015\ttotal: 14.7s\tremaining: 1.03s\n",
      "934:\tlearn: 0.3391051\ttotal: 14.7s\tremaining: 1.02s\n",
      "935:\tlearn: 0.3389048\ttotal: 14.7s\tremaining: 1s\n",
      "936:\tlearn: 0.3387783\ttotal: 14.7s\tremaining: 989ms\n",
      "937:\tlearn: 0.3385796\ttotal: 14.7s\tremaining: 973ms\n",
      "938:\tlearn: 0.3384341\ttotal: 14.7s\tremaining: 957ms\n",
      "939:\tlearn: 0.3383488\ttotal: 14.8s\tremaining: 942ms\n",
      "940:\tlearn: 0.3381835\ttotal: 14.8s\tremaining: 926ms\n",
      "941:\tlearn: 0.3380356\ttotal: 14.8s\tremaining: 910ms\n",
      "942:\tlearn: 0.3378961\ttotal: 14.8s\tremaining: 894ms\n",
      "943:\tlearn: 0.3376976\ttotal: 14.8s\tremaining: 879ms\n",
      "944:\tlearn: 0.3375266\ttotal: 14.8s\tremaining: 863ms\n",
      "945:\tlearn: 0.3373648\ttotal: 14.8s\tremaining: 847ms\n",
      "946:\tlearn: 0.3372136\ttotal: 14.9s\tremaining: 831ms\n",
      "947:\tlearn: 0.3370749\ttotal: 14.9s\tremaining: 816ms\n",
      "948:\tlearn: 0.3368780\ttotal: 14.9s\tremaining: 800ms\n",
      "949:\tlearn: 0.3366817\ttotal: 14.9s\tremaining: 784ms\n",
      "950:\tlearn: 0.3365574\ttotal: 14.9s\tremaining: 769ms\n",
      "951:\tlearn: 0.3364660\ttotal: 14.9s\tremaining: 753ms\n",
      "952:\tlearn: 0.3363152\ttotal: 14.9s\tremaining: 737ms\n",
      "953:\tlearn: 0.3361682\ttotal: 15s\tremaining: 721ms\n",
      "954:\tlearn: 0.3360651\ttotal: 15s\tremaining: 706ms\n",
      "955:\tlearn: 0.3358809\ttotal: 15s\tremaining: 690ms\n",
      "956:\tlearn: 0.3357578\ttotal: 15s\tremaining: 674ms\n",
      "957:\tlearn: 0.3355419\ttotal: 15s\tremaining: 659ms\n",
      "958:\tlearn: 0.3354132\ttotal: 15s\tremaining: 643ms\n",
      "959:\tlearn: 0.3352685\ttotal: 15s\tremaining: 627ms\n",
      "960:\tlearn: 0.3351196\ttotal: 15.1s\tremaining: 611ms\n",
      "961:\tlearn: 0.3349976\ttotal: 15.1s\tremaining: 596ms\n",
      "962:\tlearn: 0.3349127\ttotal: 15.1s\tremaining: 580ms\n",
      "963:\tlearn: 0.3347280\ttotal: 15.1s\tremaining: 564ms\n",
      "964:\tlearn: 0.3345074\ttotal: 15.1s\tremaining: 549ms\n",
      "965:\tlearn: 0.3344024\ttotal: 15.1s\tremaining: 533ms\n",
      "966:\tlearn: 0.3342300\ttotal: 15.2s\tremaining: 517ms\n",
      "967:\tlearn: 0.3340859\ttotal: 15.2s\tremaining: 502ms\n",
      "968:\tlearn: 0.3339131\ttotal: 15.2s\tremaining: 486ms\n",
      "969:\tlearn: 0.3338276\ttotal: 15.2s\tremaining: 470ms\n",
      "970:\tlearn: 0.3336010\ttotal: 15.2s\tremaining: 454ms\n",
      "971:\tlearn: 0.3334265\ttotal: 15.2s\tremaining: 439ms\n",
      "972:\tlearn: 0.3332371\ttotal: 15.2s\tremaining: 423ms\n",
      "973:\tlearn: 0.3331190\ttotal: 15.3s\tremaining: 407ms\n",
      "974:\tlearn: 0.3329849\ttotal: 15.3s\tremaining: 392ms\n",
      "975:\tlearn: 0.3328128\ttotal: 15.3s\tremaining: 376ms\n",
      "976:\tlearn: 0.3326662\ttotal: 15.3s\tremaining: 360ms\n",
      "977:\tlearn: 0.3324759\ttotal: 15.3s\tremaining: 345ms\n",
      "978:\tlearn: 0.3323804\ttotal: 15.3s\tremaining: 329ms\n",
      "979:\tlearn: 0.3322287\ttotal: 15.3s\tremaining: 313ms\n",
      "980:\tlearn: 0.3320397\ttotal: 15.4s\tremaining: 298ms\n",
      "981:\tlearn: 0.3319049\ttotal: 15.4s\tremaining: 282ms\n",
      "982:\tlearn: 0.3317602\ttotal: 15.4s\tremaining: 266ms\n",
      "983:\tlearn: 0.3315754\ttotal: 15.4s\tremaining: 251ms\n",
      "984:\tlearn: 0.3314232\ttotal: 15.4s\tremaining: 235ms\n",
      "985:\tlearn: 0.3313048\ttotal: 15.4s\tremaining: 219ms\n",
      "986:\tlearn: 0.3311048\ttotal: 15.5s\tremaining: 204ms\n",
      "987:\tlearn: 0.3309718\ttotal: 15.5s\tremaining: 188ms\n",
      "988:\tlearn: 0.3308443\ttotal: 15.5s\tremaining: 172ms\n",
      "989:\tlearn: 0.3307097\ttotal: 15.5s\tremaining: 157ms\n",
      "990:\tlearn: 0.3305335\ttotal: 15.5s\tremaining: 141ms\n",
      "991:\tlearn: 0.3304145\ttotal: 15.5s\tremaining: 125ms\n",
      "992:\tlearn: 0.3302875\ttotal: 15.5s\tremaining: 110ms\n",
      "993:\tlearn: 0.3301551\ttotal: 15.6s\tremaining: 93.9ms\n",
      "994:\tlearn: 0.3299993\ttotal: 15.6s\tremaining: 78.3ms\n",
      "995:\tlearn: 0.3298501\ttotal: 15.6s\tremaining: 62.6ms\n",
      "996:\tlearn: 0.3297030\ttotal: 15.6s\tremaining: 47ms\n",
      "997:\tlearn: 0.3295777\ttotal: 15.6s\tremaining: 31.3ms\n",
      "998:\tlearn: 0.3294154\ttotal: 15.6s\tremaining: 15.7ms\n",
      "999:\tlearn: 0.3292538\ttotal: 15.7s\tremaining: 0us\n",
      "Accuracy: 0.7328911667169129\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1297e0bddc0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
    "cm_display.plot(cmap=\"Reds\", xticks_rotation=90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 33965 --- Validation Size: 8492 --- Test Size: 10615\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data_selected, to_categorical(y_resampled), test_size=0.2, random_state=RANDOM_STATE)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=RANDOM_STATE)\n",
    "print(f\"Train Size: {len(y_train)} --- Validation Size: {len(y_val)} --- Test Size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_layers': [1, 2, 3, 4, 5, 6],\n",
    "    'n_nodes': [32, 64, 128, 256, 512],\n",
    "    'dropout': [0.1, 0.2, 0.3, 0.4],\n",
    "    'lr': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "param_grid_2 = {\n",
    "    'n_nodes1': [32, 64, 128],\n",
    "    'n_nodes2': [64, 128, 256],\n",
    "    'n_nodes3': [128, 256, 512],\n",
    "    'n_nodes4': [64, 128, 256],\n",
    "    'n_nodes5': [32, 64, 128],\n",
    "    'dropout': [0.2, 0.3],\n",
    "    'lr': [0.0001, 0.001],\n",
    "    'activation': ['sigmoid', 'softmax']\n",
    "}\n",
    "\n",
    "# define the callbacks\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr= 0.0001, n_layers=1, n_nodes=10, dropout=0.1):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            model.add(Dense(n_nodes, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes, activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominik Hahn\\AppData\\Local\\Temp\\ipykernel_26164\\2087463641.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 480 candidates, totalling 1440 fits\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6889 - accuracy: 0.5417\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6811 - accuracy: 0.5694\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=32;, score=0.569 total time=   3.7s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6880 - accuracy: 0.5676\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6707 - accuracy: 0.6562\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=32;, score=0.656 total time=   4.2s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6973 - accuracy: 0.5362\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6804 - accuracy: 0.6210\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=32;, score=0.621 total time=   4.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6816 - accuracy: 0.5756\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6702 - accuracy: 0.5942\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=64;, score=0.594 total time=   4.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6943 - accuracy: 0.5510\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6705 - accuracy: 0.6427\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=64;, score=0.643 total time=   4.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6833 - accuracy: 0.5739\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6645 - accuracy: 0.6529\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=64;, score=0.653 total time=   4.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6809 - accuracy: 0.5811\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6644 - accuracy: 0.6207\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=128;, score=0.621 total time=   4.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6767 - accuracy: 0.6015\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6568 - accuracy: 0.6668\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=128;, score=0.667 total time=   4.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6777 - accuracy: 0.5908\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6612 - accuracy: 0.6585\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=128;, score=0.659 total time=   4.2s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6693 - accuracy: 0.6184\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6472 - accuracy: 0.6649\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=256;, score=0.665 total time=   3.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6729 - accuracy: 0.6090\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6465 - accuracy: 0.6700\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=256;, score=0.670 total time=   3.8s\n",
      "708/708 [==============================] - 3s 3ms/step - loss: 0.6736 - accuracy: 0.6076\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6531 - accuracy: 0.6603\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=256;, score=0.660 total time=   3.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6589 - accuracy: 0.6367\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6399 - accuracy: 0.6663\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=512;, score=0.666 total time=   4.2s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6627 - accuracy: 0.6261\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6400 - accuracy: 0.6540\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=512;, score=0.654 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6592 - accuracy: 0.6325\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.6607\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=1, n_nodes=512;, score=0.661 total time=   4.3s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7076 - accuracy: 0.5125\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6801 - accuracy: 0.6237\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=32;, score=0.624 total time=   5.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6911 - accuracy: 0.5381\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6740 - accuracy: 0.6459\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=32;, score=0.646 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6858 - accuracy: 0.5654\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6637 - accuracy: 0.6375\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=32;, score=0.637 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6707 - accuracy: 0.6088\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6515 - accuracy: 0.6668\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=64;, score=0.667 total time=   5.0s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6731 - accuracy: 0.5934\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6424 - accuracy: 0.6535\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=64;, score=0.654 total time=   3.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6858 - accuracy: 0.5764\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6565 - accuracy: 0.6234\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=64;, score=0.623 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6670 - accuracy: 0.6122\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6391 - accuracy: 0.6684\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=128;, score=0.668 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6617 - accuracy: 0.6191\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6704\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=128;, score=0.670 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6684 - accuracy: 0.6090\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6367 - accuracy: 0.6730\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=128;, score=0.673 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6507 - accuracy: 0.6324\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6319 - accuracy: 0.6660\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=256;, score=0.666 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6577 - accuracy: 0.6215\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6240 - accuracy: 0.6700\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=256;, score=0.670 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6511 - accuracy: 0.6369\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6248 - accuracy: 0.6769\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=256;, score=0.677 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6409 - accuracy: 0.6498\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6346 - accuracy: 0.6532\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=512;, score=0.653 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6463 - accuracy: 0.6431\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6175 - accuracy: 0.6751\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=512;, score=0.675 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6423 - accuracy: 0.6475\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6664\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=2, n_nodes=512;, score=0.666 total time=   5.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6924 - accuracy: 0.5497\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6705 - accuracy: 0.6547\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=32;, score=0.655 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6921 - accuracy: 0.5251\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6771 - accuracy: 0.6569\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=32;, score=0.657 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6842 - accuracy: 0.5658\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6646 - accuracy: 0.6480\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=32;, score=0.648 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6709 - accuracy: 0.6043\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6393 - accuracy: 0.6637\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=64;, score=0.664 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6860 - accuracy: 0.5617\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6623 - accuracy: 0.6645\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=64;, score=0.665 total time=   6.3s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6804 - accuracy: 0.5717\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6568 - accuracy: 0.6638\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=64;, score=0.664 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6618 - accuracy: 0.6092\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6490 - accuracy: 0.6264\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=128;, score=0.626 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6662 - accuracy: 0.6033\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6758\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=128;, score=0.676 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6618 - accuracy: 0.6159\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6270 - accuracy: 0.6725\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=128;, score=0.672 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6465 - accuracy: 0.6379\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6249 - accuracy: 0.6692\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=256;, score=0.669 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6505 - accuracy: 0.6327\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6171 - accuracy: 0.6759\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=256;, score=0.676 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6471 - accuracy: 0.6351\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6355 - accuracy: 0.6576\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=256;, score=0.658 total time=   6.1s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6362 - accuracy: 0.6506\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6642\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=512;, score=0.664 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6442 - accuracy: 0.6380\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6153 - accuracy: 0.6765\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=512;, score=0.676 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6397 - accuracy: 0.6454\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6451 - accuracy: 0.6501\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=3, n_nodes=512;, score=0.650 total time=   6.2s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6900 - accuracy: 0.5391\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6731 - accuracy: 0.6514\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=32;, score=0.651 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6868 - accuracy: 0.5664\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6645 - accuracy: 0.6623\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=32;, score=0.662 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6868 - accuracy: 0.5484\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6685 - accuracy: 0.6207\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=32;, score=0.621 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6795 - accuracy: 0.5736\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6443 - accuracy: 0.6623\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=64;, score=0.662 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6742 - accuracy: 0.5886\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6351 - accuracy: 0.6771\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=64;, score=0.677 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6734 - accuracy: 0.5873\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6302 - accuracy: 0.6720\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=64;, score=0.672 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6671 - accuracy: 0.5989\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6637\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=128;, score=0.664 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6619 - accuracy: 0.6058\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6147 - accuracy: 0.6790\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=128;, score=0.679 total time=   6.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6675 - accuracy: 0.6002\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6248 - accuracy: 0.6721\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=128;, score=0.672 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6477 - accuracy: 0.6313\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6302 - accuracy: 0.6603\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=256;, score=0.660 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6538 - accuracy: 0.6203\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6151 - accuracy: 0.6803\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=256;, score=0.680 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6484 - accuracy: 0.6344\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6221 - accuracy: 0.6668\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=256;, score=0.667 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6342 - accuracy: 0.6526\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6219 - accuracy: 0.6697\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=512;, score=0.670 total time=   6.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6421 - accuracy: 0.6400\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6110 - accuracy: 0.6797\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=512;, score=0.680 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6361 - accuracy: 0.6496\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6158 - accuracy: 0.6782\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=4, n_nodes=512;, score=0.678 total time=   6.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6892 - accuracy: 0.5423\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6729 - accuracy: 0.6350\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=32;, score=0.635 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6899 - accuracy: 0.5445\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6730 - accuracy: 0.6338\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=32;, score=0.634 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6906 - accuracy: 0.5385\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6797 - accuracy: 0.5999\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=32;, score=0.600 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6811 - accuracy: 0.5665\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6385 - accuracy: 0.6662\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=64;, score=0.666 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6748 - accuracy: 0.5820\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6759\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=64;, score=0.676 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6825 - accuracy: 0.5739\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6435 - accuracy: 0.6630\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=64;, score=0.663 total time=   8.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6583 - accuracy: 0.6128\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6276 - accuracy: 0.6636\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=128;, score=0.664 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6680 - accuracy: 0.5932\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6173 - accuracy: 0.6784\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=128;, score=0.678 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6568 - accuracy: 0.6119\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6236 - accuracy: 0.6652\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=128;, score=0.665 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6453 - accuracy: 0.6380\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6259 - accuracy: 0.6605\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=256;, score=0.660 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6463 - accuracy: 0.6318\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.6810\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=256;, score=0.681 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6451 - accuracy: 0.6320\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6214 - accuracy: 0.6714\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=256;, score=0.671 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6375 - accuracy: 0.6444\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6669\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=512;, score=0.667 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6435 - accuracy: 0.6383\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6230 - accuracy: 0.6708\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=512;, score=0.671 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6382 - accuracy: 0.6449\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6343 - accuracy: 0.6454\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=5, n_nodes=512;, score=0.645 total time=   7.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6915 - accuracy: 0.5338\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6840 - accuracy: 0.6235\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=32;, score=0.623 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6880 - accuracy: 0.5475\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6657 - accuracy: 0.6523\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=32;, score=0.652 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6900 - accuracy: 0.5424\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6714 - accuracy: 0.6536\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=32;, score=0.654 total time=   8.1s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6839 - accuracy: 0.5515\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6515 - accuracy: 0.6281\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=64;, score=0.628 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6821 - accuracy: 0.5619\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6389 - accuracy: 0.6704\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=64;, score=0.670 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6845 - accuracy: 0.5564\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6423 - accuracy: 0.6685\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=64;, score=0.668 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6621 - accuracy: 0.6026\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6256 - accuracy: 0.6661\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=128;, score=0.666 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6653 - accuracy: 0.5928\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6249 - accuracy: 0.6645\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=128;, score=0.665 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6603 - accuracy: 0.6057\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6218 - accuracy: 0.6733\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=128;, score=0.673 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6464 - accuracy: 0.6303\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6286 - accuracy: 0.6575\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=256;, score=0.657 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6507 - accuracy: 0.6208\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6120 - accuracy: 0.6804\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=256;, score=0.680 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6475 - accuracy: 0.6287\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6196 - accuracy: 0.6728\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=256;, score=0.673 total time=   8.8s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6388 - accuracy: 0.6449\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6287 - accuracy: 0.6560\n",
      "[CV 1/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=512;, score=0.656 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6447 - accuracy: 0.6330\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6197 - accuracy: 0.6737\n",
      "[CV 2/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=512;, score=0.674 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6382 - accuracy: 0.6389\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6161 - accuracy: 0.6774\n",
      "[CV 3/3] END dropout=0.1, lr=0.0001, n_layers=6, n_nodes=512;, score=0.677 total time=   8.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6554 - accuracy: 0.6274\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6675\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=32;, score=0.667 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6582 - accuracy: 0.6178\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.6689\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=32;, score=0.669 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6555 - accuracy: 0.6208\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.6721\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=32;, score=0.672 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6435 - accuracy: 0.6424\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6291 - accuracy: 0.6607\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=64;, score=0.661 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6444 - accuracy: 0.6402\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6163 - accuracy: 0.6776\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=64;, score=0.678 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6423 - accuracy: 0.6433\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6211 - accuracy: 0.6742\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=64;, score=0.674 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6438 - accuracy: 0.6449\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.6702\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=128;, score=0.670 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6436 - accuracy: 0.6466\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6166 - accuracy: 0.6782\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=128;, score=0.678 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6381 - accuracy: 0.6527\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6198 - accuracy: 0.6771\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=128;, score=0.677 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6351 - accuracy: 0.6560\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6309 - accuracy: 0.6579\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=256;, score=0.658 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6422 - accuracy: 0.6434\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6446 - accuracy: 0.6244\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=256;, score=0.624 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6388 - accuracy: 0.6500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6244 - accuracy: 0.6675\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=256;, score=0.668 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6363 - accuracy: 0.6517\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6271 - accuracy: 0.6616\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=512;, score=0.662 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6419 - accuracy: 0.6443\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6190 - accuracy: 0.6800\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=512;, score=0.680 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6406 - accuracy: 0.6467\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.6606\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=1, n_nodes=512;, score=0.661 total time=   5.0s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6449 - accuracy: 0.6374\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6683\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=32;, score=0.668 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6494 - accuracy: 0.6303\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6244 - accuracy: 0.6688\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=32;, score=0.669 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6490 - accuracy: 0.6347\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6439 - accuracy: 0.6369\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=32;, score=0.637 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6397 - accuracy: 0.6438\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6267 - accuracy: 0.6680\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=64;, score=0.668 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6436 - accuracy: 0.6400\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6250 - accuracy: 0.6625\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=64;, score=0.663 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6363 - accuracy: 0.6521\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6207 - accuracy: 0.6767\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=64;, score=0.677 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6395 - accuracy: 0.6464\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6219 - accuracy: 0.6716\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=128;, score=0.672 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6435 - accuracy: 0.6381\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.6785\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=128;, score=0.679 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6404 - accuracy: 0.6485\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6221 - accuracy: 0.6749\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=128;, score=0.675 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6334 - accuracy: 0.6532\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6309 - accuracy: 0.6590\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=256;, score=0.659 total time=   5.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6401 - accuracy: 0.6431\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6084 - accuracy: 0.6828\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=256;, score=0.683 total time=   6.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6344 - accuracy: 0.6546\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6210 - accuracy: 0.6719\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=256;, score=0.672 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6333 - accuracy: 0.6584\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6228 - accuracy: 0.6629\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=512;, score=0.663 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6374 - accuracy: 0.6504\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.6839\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=512;, score=0.684 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6346 - accuracy: 0.6525\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6384 - accuracy: 0.6575\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=2, n_nodes=512;, score=0.658 total time=   5.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6506 - accuracy: 0.6239\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6275 - accuracy: 0.6532\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=32;, score=0.653 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6478 - accuracy: 0.6334\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6141 - accuracy: 0.6835\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=32;, score=0.684 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6477 - accuracy: 0.6351\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6198 - accuracy: 0.6760\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=32;, score=0.676 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6373 - accuracy: 0.6491\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6194 - accuracy: 0.6680\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=64;, score=0.668 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6406 - accuracy: 0.6451\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6157 - accuracy: 0.6741\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=64;, score=0.674 total time=   6.0s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6428 - accuracy: 0.6399\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6187 - accuracy: 0.6784\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=64;, score=0.678 total time=   5.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6348 - accuracy: 0.6521\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6249 - accuracy: 0.6688\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=128;, score=0.669 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6409 - accuracy: 0.6449\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6124 - accuracy: 0.6764\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=128;, score=0.676 total time=   6.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6343 - accuracy: 0.6514\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6270 - accuracy: 0.6581\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=128;, score=0.658 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6336 - accuracy: 0.6552\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6242 - accuracy: 0.6735\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=256;, score=0.673 total time=   6.3s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6403 - accuracy: 0.6463\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6135 - accuracy: 0.6824\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=256;, score=0.682 total time=   6.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6374 - accuracy: 0.6471\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.6779\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=256;, score=0.678 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6376 - accuracy: 0.6542\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6236 - accuracy: 0.6720\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=512;, score=0.672 total time=   6.0s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6385 - accuracy: 0.6490\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6287 - accuracy: 0.6539\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=512;, score=0.654 total time=   5.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6360 - accuracy: 0.6485\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6401 - accuracy: 0.6348\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=3, n_nodes=512;, score=0.635 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6458 - accuracy: 0.6351\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6228 - accuracy: 0.6742\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=32;, score=0.674 total time=   6.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6508 - accuracy: 0.6239\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6160 - accuracy: 0.6773\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=32;, score=0.677 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6486 - accuracy: 0.6338\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6211 - accuracy: 0.6756\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=32;, score=0.676 total time=   7.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6379 - accuracy: 0.6484\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6214 - accuracy: 0.6728\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=64;, score=0.673 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6461 - accuracy: 0.6365\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6272 - accuracy: 0.6588\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=64;, score=0.659 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6384 - accuracy: 0.6468\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.6782\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=64;, score=0.678 total time=   6.4s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6348 - accuracy: 0.6525\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6274 - accuracy: 0.6775\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=128;, score=0.678 total time=   7.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6429 - accuracy: 0.6396\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.6721\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=128;, score=0.672 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6371 - accuracy: 0.6524\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6212 - accuracy: 0.6738\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=128;, score=0.674 total time=   6.7s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6382 - accuracy: 0.6492\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6228 - accuracy: 0.6729\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=256;, score=0.673 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6427 - accuracy: 0.6424\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6132 - accuracy: 0.6840\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=256;, score=0.684 total time=   6.7s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6366 - accuracy: 0.6480\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6203 - accuracy: 0.6746\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=256;, score=0.675 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6385 - accuracy: 0.6473\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6212 - accuracy: 0.6738\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=512;, score=0.674 total time=   6.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6399 - accuracy: 0.6510\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6162 - accuracy: 0.6801\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=512;, score=0.680 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6367 - accuracy: 0.6476\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6197 - accuracy: 0.6754\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=4, n_nodes=512;, score=0.675 total time=   6.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6501 - accuracy: 0.6295\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6242 - accuracy: 0.6698\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=32;, score=0.670 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6510 - accuracy: 0.6235\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6108 - accuracy: 0.6831\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=32;, score=0.683 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6516 - accuracy: 0.6246\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6354 - accuracy: 0.6464\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=32;, score=0.646 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6403 - accuracy: 0.6447\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6676\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=64;, score=0.668 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6483 - accuracy: 0.6301\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6233 - accuracy: 0.6857\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=64;, score=0.686 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6488 - accuracy: 0.6274\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6561 - accuracy: 0.6466\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=64;, score=0.647 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6387 - accuracy: 0.6466\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6525 - accuracy: 0.6239\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=128;, score=0.624 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6451 - accuracy: 0.6374\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6129 - accuracy: 0.6822\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=128;, score=0.682 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6405 - accuracy: 0.6456\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6171 - accuracy: 0.6764\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=128;, score=0.676 total time=   7.4s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6389 - accuracy: 0.6482\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6428 - accuracy: 0.6435\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=256;, score=0.644 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6439 - accuracy: 0.6405\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6282 - accuracy: 0.6591\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=256;, score=0.659 total time=   6.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6372 - accuracy: 0.6501\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6301 - accuracy: 0.6683\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=256;, score=0.668 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6390 - accuracy: 0.6489\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6226 - accuracy: 0.6740\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=512;, score=0.674 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6437 - accuracy: 0.6480\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.6747\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=512;, score=0.675 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6386 - accuracy: 0.6484\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6518 - accuracy: 0.6154\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=5, n_nodes=512;, score=0.615 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6603 - accuracy: 0.6095\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6293 - accuracy: 0.6671\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=32;, score=0.667 total time=   7.2s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6587 - accuracy: 0.6121\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6145 - accuracy: 0.6825\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=32;, score=0.682 total time=   7.7s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6560 - accuracy: 0.6181\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6343 - accuracy: 0.6515\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=32;, score=0.652 total time=   8.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6440 - accuracy: 0.6353\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6253 - accuracy: 0.6693\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=64;, score=0.669 total time=   7.7s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6506 - accuracy: 0.6313\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6121 - accuracy: 0.6834\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=64;, score=0.683 total time=   7.8s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6402 - accuracy: 0.6494\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6236 - accuracy: 0.6740\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=64;, score=0.674 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6426 - accuracy: 0.6390\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6370 - accuracy: 0.6753\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=128;, score=0.675 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6425 - accuracy: 0.6443\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6348 - accuracy: 0.6621\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=128;, score=0.662 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6431 - accuracy: 0.6443\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6232 - accuracy: 0.6771\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=128;, score=0.677 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6430 - accuracy: 0.6368\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6244 - accuracy: 0.6691\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=256;, score=0.669 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6439 - accuracy: 0.6386\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6104 - accuracy: 0.6842\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=256;, score=0.684 total time=   8.0s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6429 - accuracy: 0.6422\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6277 - accuracy: 0.6608\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=256;, score=0.661 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6445 - accuracy: 0.6431\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6349 - accuracy: 0.6671\n",
      "[CV 1/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=512;, score=0.667 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6450 - accuracy: 0.6438\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.6497\n",
      "[CV 2/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=512;, score=0.650 total time=   7.7s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6440 - accuracy: 0.6445\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6339 - accuracy: 0.6643\n",
      "[CV 3/3] END dropout=0.1, lr=0.001, n_layers=6, n_nodes=512;, score=0.664 total time=   8.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6449 - accuracy: 0.6296\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6451 - accuracy: 0.6255\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=32;, score=0.626 total time=   4.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6489 - accuracy: 0.6300\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6783\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=32;, score=0.678 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6448 - accuracy: 0.6393\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6182 - accuracy: 0.6758\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=32;, score=0.676 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6415 - accuracy: 0.6429\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6299 - accuracy: 0.6614\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=64;, score=0.661 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6456 - accuracy: 0.6409\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6230 - accuracy: 0.6699\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=64;, score=0.670 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6441 - accuracy: 0.6405\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6279 - accuracy: 0.6749\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=64;, score=0.675 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6411 - accuracy: 0.6479\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6201 - accuracy: 0.6728\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=128;, score=0.673 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6480 - accuracy: 0.6370\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6156 - accuracy: 0.6840\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=128;, score=0.684 total time=   5.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6406 - accuracy: 0.6475\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6188 - accuracy: 0.6771\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=128;, score=0.677 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6404 - accuracy: 0.6495\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6343 - accuracy: 0.6555\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=256;, score=0.656 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6427 - accuracy: 0.6432\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6269 - accuracy: 0.6547\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=256;, score=0.655 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6408 - accuracy: 0.6418\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6207 - accuracy: 0.6765\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=256;, score=0.677 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6449 - accuracy: 0.6412\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6212 - accuracy: 0.6723\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=512;, score=0.672 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6504 - accuracy: 0.6351\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6164 - accuracy: 0.6837\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=512;, score=0.684 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6466 - accuracy: 0.6438\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6546 - accuracy: 0.6070\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=1, n_nodes=512;, score=0.607 total time=   4.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6532 - accuracy: 0.6264\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6274 - accuracy: 0.6720\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=32;, score=0.672 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6631 - accuracy: 0.6096\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6367 - accuracy: 0.6556\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=32;, score=0.656 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6441 - accuracy: 0.6357\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.6782\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=32;, score=0.678 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6527 - accuracy: 0.6317\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6796 - accuracy: 0.5771\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=64;, score=0.577 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6530 - accuracy: 0.6305\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.6859\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=64;, score=0.686 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6476 - accuracy: 0.6275\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6487 - accuracy: 0.6533\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=64;, score=0.653 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6469 - accuracy: 0.6345\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6217 - accuracy: 0.6728\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=128;, score=0.673 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6478 - accuracy: 0.6357\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6158 - accuracy: 0.6848\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=128;, score=0.685 total time=   5.4s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6533 - accuracy: 0.6288\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6334 - accuracy: 0.6544\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=128;, score=0.654 total time=   5.1s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6505 - accuracy: 0.6338\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6708\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=256;, score=0.671 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6560 - accuracy: 0.6234\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6523 - accuracy: 0.6403\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=256;, score=0.640 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6958 - accuracy: 0.5062\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=256;, score=0.501 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6594 - accuracy: 0.6300\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6591 - accuracy: 0.6221\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=512;, score=0.622 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6611 - accuracy: 0.6178\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.6799\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=512;, score=0.680 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6534 - accuracy: 0.6328\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6798\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=2, n_nodes=512;, score=0.680 total time=   5.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6933 - accuracy: 0.5018\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4973\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=32;, score=0.497 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6548 - accuracy: 0.6243\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6766\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=32;, score=0.677 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6558 - accuracy: 0.6155\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.6756\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=32;, score=0.676 total time=   6.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6577 - accuracy: 0.6210\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.6644\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=64;, score=0.664 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6564 - accuracy: 0.6258\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.6857\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=64;, score=0.686 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6550 - accuracy: 0.6282\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6775\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=64;, score=0.678 total time=   5.9s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6544 - accuracy: 0.6262\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6267 - accuracy: 0.6774\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=128;, score=0.677 total time=   6.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6626 - accuracy: 0.6110\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6651\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=128;, score=0.665 total time=   5.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6578 - accuracy: 0.6217\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6233 - accuracy: 0.6768\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=128;, score=0.677 total time=   6.3s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6506 - accuracy: 0.6315\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6298 - accuracy: 0.6765\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=256;, score=0.676 total time=   5.9s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6609 - accuracy: 0.6203\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6400 - accuracy: 0.6501\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=256;, score=0.650 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6661 - accuracy: 0.6081\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.6560\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=256;, score=0.656 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6985 - accuracy: 0.5320\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=512;, score=0.503 total time=   6.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6647 - accuracy: 0.6192\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6210 - accuracy: 0.6849\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=512;, score=0.685 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7032 - accuracy: 0.5166\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6944 - accuracy: 0.4989\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=3, n_nodes=512;, score=0.499 total time=   5.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6916 - accuracy: 0.5108\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=32;, score=0.497 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6674 - accuracy: 0.5924\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6803\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=32;, score=0.680 total time=   6.5s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6923 - accuracy: 0.5081\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=32;, score=0.499 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6589 - accuracy: 0.6151\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.6630\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=64;, score=0.663 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6660 - accuracy: 0.6098\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6302 - accuracy: 0.6814\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=64;, score=0.681 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6594 - accuracy: 0.6113\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6346 - accuracy: 0.6485\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=64;, score=0.649 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6941 - accuracy: 0.5031\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=128;, score=0.497 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6941 - accuracy: 0.5004\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=128;, score=0.501 total time=   6.5s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6919 - accuracy: 0.5062\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=128;, score=0.501 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6955 - accuracy: 0.4908\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=256;, score=0.497 total time=   6.7s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6938 - accuracy: 0.5047\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=256;, score=0.501 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6967 - accuracy: 0.4972\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=256;, score=0.501 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7004 - accuracy: 0.5006\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=512;, score=0.497 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7100 - accuracy: 0.4995\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=512;, score=0.499 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7053 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=4, n_nodes=512;, score=0.501 total time=   6.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6900 - accuracy: 0.5233\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=32;, score=0.497 total time=   8.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6668 - accuracy: 0.6055\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.6775\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=32;, score=0.678 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6679 - accuracy: 0.6017\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6527 - accuracy: 0.6774\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=32;, score=0.677 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6923 - accuracy: 0.5077\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=64;, score=0.503 total time=   7.3s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6893 - accuracy: 0.5274\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=64;, score=0.501 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6884 - accuracy: 0.5231\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=64;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6941 - accuracy: 0.4968\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=128;, score=0.497 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6937 - accuracy: 0.5075\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=128;, score=0.501 total time=   7.4s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6912 - accuracy: 0.5127\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.4987\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=128;, score=0.499 total time=   6.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6940 - accuracy: 0.5189\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=256;, score=0.503 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6766 - accuracy: 0.5895\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6315 - accuracy: 0.6606\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=256;, score=0.661 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6960 - accuracy: 0.5109\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=256;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7200 - accuracy: 0.4989\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=512;, score=0.503 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7088 - accuracy: 0.5018\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=512;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7202 - accuracy: 0.5138\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=5, n_nodes=512;, score=0.499 total time=   6.8s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6919 - accuracy: 0.5062\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=32;, score=0.497 total time=   7.9s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6657 - accuracy: 0.6073\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.7334 - accuracy: 0.5393\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=32;, score=0.539 total time=   7.8s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6938 - accuracy: 0.5045\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=32;, score=0.501 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6934 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=64;, score=0.503 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6940 - accuracy: 0.4969\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=64;, score=0.501 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6654 - accuracy: 0.6094\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6559 - accuracy: 0.6448\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=64;, score=0.645 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6941 - accuracy: 0.4989\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=128;, score=0.497 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6651 - accuracy: 0.6088\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6838 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=128;, score=0.499 total time=   8.7s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6931 - accuracy: 0.5174\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=128;, score=0.501 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7027 - accuracy: 0.4998\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=256;, score=0.497 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6952 - accuracy: 0.5013\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=256;, score=0.499 total time=   8.2s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6956 - accuracy: 0.5033\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=256;, score=0.499 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7089 - accuracy: 0.4972\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=512;, score=0.497 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7012 - accuracy: 0.5036\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=512;, score=0.501 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7383 - accuracy: 0.5022\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.01, n_layers=6, n_nodes=512;, score=0.499 total time=   8.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7060 - accuracy: 0.4948\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=32;, score=0.503 total time=   4.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7019 - accuracy: 0.4979\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=32;, score=0.499 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7114 - accuracy: 0.5007\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=32;, score=0.499 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7095 - accuracy: 0.5014\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=64;, score=0.503 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7187 - accuracy: 0.4963\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=64;, score=0.501 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7057 - accuracy: 0.5044\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6955 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=64;, score=0.499 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7412 - accuracy: 0.5014\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6954 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=128;, score=0.503 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7210 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6951 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=128;, score=0.499 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7188 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=128;, score=0.499 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7486 - accuracy: 0.5028\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=256;, score=0.497 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7532 - accuracy: 0.5013\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6979 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=256;, score=0.499 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7322 - accuracy: 0.5030\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6998 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=256;, score=0.499 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.8146 - accuracy: 0.5012\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6946 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=512;, score=0.503 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7807 - accuracy: 0.5075\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6953 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=512;, score=0.499 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.8333 - accuracy: 0.4960\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7085 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=1, n_nodes=512;, score=0.499 total time=   4.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7033 - accuracy: 0.5001\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=32;, score=0.503 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7057 - accuracy: 0.4977\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=32;, score=0.501 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7014 - accuracy: 0.5001\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=32;, score=0.499 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7122 - accuracy: 0.5023\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=64;, score=0.503 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7278 - accuracy: 0.5003\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6942 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=64;, score=0.499 total time=   5.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7146 - accuracy: 0.5018\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6975 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=64;, score=0.499 total time=   6.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7389 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=128;, score=0.497 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7422 - accuracy: 0.5006\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6962 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=128;, score=0.501 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7489 - accuracy: 0.5006\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=128;, score=0.499 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.9176 - accuracy: 0.4958\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=256;, score=0.503 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.0914 - accuracy: 0.4978\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6967 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=256;, score=0.501 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.9886 - accuracy: 0.5024\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=256;, score=0.499 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 2.1852 - accuracy: 0.5005\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=512;, score=0.497 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.9184 - accuracy: 0.4987\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=512;, score=0.501 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.1915 - accuracy: 0.5010\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=2, n_nodes=512;, score=0.499 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7036 - accuracy: 0.4990\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6972 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=32;, score=0.503 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7000 - accuracy: 0.4961\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6963 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=32;, score=0.499 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7044 - accuracy: 0.4969\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=32;, score=0.501 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7558 - accuracy: 0.5003\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6959 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=64;, score=0.503 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7395 - accuracy: 0.4993\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=64;, score=0.501 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7487 - accuracy: 0.4982\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7066 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=64;, score=0.501 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.8520 - accuracy: 0.5016\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6952 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=128;, score=0.503 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.8381 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7073 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=128;, score=0.499 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.9340 - accuracy: 0.4997\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=128;, score=0.501 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 2.7143 - accuracy: 0.5044\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6951 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=256;, score=0.503 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 1.3276 - accuracy: 0.5051\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6948 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=256;, score=0.499 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 1.1805 - accuracy: 0.5033\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=256;, score=0.499 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 11.1618 - accuracy: 0.4998\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6962 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=512;, score=0.497 total time=   6.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 7.7858 - accuracy: 0.4983\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6968 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=512;, score=0.501 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 5.2003 - accuracy: 0.5010\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7006 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=3, n_nodes=512;, score=0.501 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7046 - accuracy: 0.5001\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=32;, score=0.503 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6971 - accuracy: 0.4956\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=32;, score=0.501 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7074 - accuracy: 0.5002\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6954 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=32;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.8528 - accuracy: 0.5047\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=64;, score=0.503 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.8361 - accuracy: 0.4980\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=64;, score=0.501 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7299 - accuracy: 0.5049\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6975 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=64;, score=0.499 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 1.8463 - accuracy: 0.4994\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7036 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=128;, score=0.497 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 1.4441 - accuracy: 0.4947\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6951 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=128;, score=0.501 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 1.0773 - accuracy: 0.5040\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7046 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=128;, score=0.501 total time=   6.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 32.5210 - accuracy: 0.5033\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=256;, score=0.503 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 11.0425 - accuracy: 0.4995\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=256;, score=0.499 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 6.2474 - accuracy: 0.5010\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=256;, score=0.499 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 55.1004 - accuracy: 0.5029\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=512;, score=0.497 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 21.0826 - accuracy: 0.5028\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=512;, score=0.499 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 92.4886 - accuracy: 0.4976\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6998 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=4, n_nodes=512;, score=0.501 total time=   6.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6970 - accuracy: 0.5013\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=32;, score=0.503 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6984 - accuracy: 0.4979\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=32;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6982 - accuracy: 0.5034\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6951 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=32;, score=0.499 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7385 - accuracy: 0.5004\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6946 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=64;, score=0.497 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7892 - accuracy: 0.5044\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=64;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7305 - accuracy: 0.4982\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=64;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 1.7304 - accuracy: 0.4965\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6937 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=128;, score=0.497 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 1.2873 - accuracy: 0.4998\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=128;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 1.9621 - accuracy: 0.5024\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7030 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=128;, score=0.499 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 43.1650 - accuracy: 0.5029\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=256;, score=0.503 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 41.6037 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6954 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=256;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 28.3347 - accuracy: 0.4951\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=256;, score=0.499 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 222.1788 - accuracy: 0.4935\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6990 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=512;, score=0.497 total time=   7.2s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 1580.0117 - accuracy: 0.5030\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=512;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 420.5585 - accuracy: 0.5053\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=5, n_nodes=512;, score=0.499 total time=   7.1s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.7172 - accuracy: 0.4987\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6942 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=32;, score=0.503 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7218 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=32;, score=0.499 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7026 - accuracy: 0.4997\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=32;, score=0.501 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7470 - accuracy: 0.4996\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=64;, score=0.503 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7255 - accuracy: 0.4998\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6938 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=64;, score=0.499 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7577 - accuracy: 0.4990\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=64;, score=0.501 total time=   8.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 7.0991 - accuracy: 0.4943\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=128;, score=0.497 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 4.7702 - accuracy: 0.4983\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6949 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=128;, score=0.499 total time=   7.7s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 6.2892 - accuracy: 0.5014\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=128;, score=0.501 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 60.9051 - accuracy: 0.5035\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=256;, score=0.503 total time=   8.0s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 239.4604 - accuracy: 0.4985\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6959 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=256;, score=0.499 total time=   7.8s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 297.2555 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7074 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=256;, score=0.501 total time=   8.0s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 3264.4543 - accuracy: 0.4993\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=512;, score=0.497 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 10582.7627 - accuracy: 0.5010\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=512;, score=0.501 total time=   7.7s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 4690.5054 - accuracy: 0.5024\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6945 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.1, lr=0.1, n_layers=6, n_nodes=512;, score=0.501 total time=   7.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6966 - accuracy: 0.5361\n",
      "354/354 [==============================] - 2s 3ms/step - loss: 0.6765 - accuracy: 0.5854\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=32;, score=0.585 total time=   5.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6906 - accuracy: 0.5617\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6605 - accuracy: 0.6509\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=32;, score=0.651 total time=   4.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6937 - accuracy: 0.5499\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6737 - accuracy: 0.6228\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=32;, score=0.623 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6909 - accuracy: 0.5485\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6741 - accuracy: 0.5907\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=64;, score=0.591 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6956 - accuracy: 0.5467\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6689 - accuracy: 0.6267\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=64;, score=0.627 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6877 - accuracy: 0.5604\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6674 - accuracy: 0.6064\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=64;, score=0.606 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6828 - accuracy: 0.5739\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6615 - accuracy: 0.6667\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=128;, score=0.667 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6852 - accuracy: 0.5597\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6626 - accuracy: 0.6736\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=128;, score=0.674 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6805 - accuracy: 0.5749\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6571 - accuracy: 0.6484\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=128;, score=0.648 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6711 - accuracy: 0.6045\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6496 - accuracy: 0.6677\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=256;, score=0.668 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6762 - accuracy: 0.5918\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6543 - accuracy: 0.6218\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=256;, score=0.622 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6759 - accuracy: 0.5928\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6507 - accuracy: 0.6709\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=256;, score=0.671 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6619 - accuracy: 0.6246\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6410 - accuracy: 0.6695\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=512;, score=0.669 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6657 - accuracy: 0.6194\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6387 - accuracy: 0.6765\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=512;, score=0.676 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6620 - accuracy: 0.6205\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6391 - accuracy: 0.6709\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=1, n_nodes=512;, score=0.671 total time=   4.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6930 - accuracy: 0.5284\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6775 - accuracy: 0.6277\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=32;, score=0.628 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6958 - accuracy: 0.5198\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6847 - accuracy: 0.6092\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=32;, score=0.609 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7141 - accuracy: 0.5166\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6882 - accuracy: 0.5733\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=32;, score=0.573 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6845 - accuracy: 0.5665\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6655 - accuracy: 0.6449\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=64;, score=0.645 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6813 - accuracy: 0.5742\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6507 - accuracy: 0.6601\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=64;, score=0.660 total time=   5.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6817 - accuracy: 0.5788\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6605 - accuracy: 0.6578\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=64;, score=0.658 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6748 - accuracy: 0.5858\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6466 - accuracy: 0.6611\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=128;, score=0.661 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6704 - accuracy: 0.6012\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6341 - accuracy: 0.6748\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=128;, score=0.675 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6727 - accuracy: 0.5939\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6406 - accuracy: 0.6686\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=128;, score=0.669 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6570 - accuracy: 0.6223\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.6686\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=256;, score=0.669 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6613 - accuracy: 0.6183\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6263 - accuracy: 0.6662\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=256;, score=0.666 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6580 - accuracy: 0.6225\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6280 - accuracy: 0.6686\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=256;, score=0.669 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6444 - accuracy: 0.6440\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6274 - accuracy: 0.6647\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=512;, score=0.665 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6477 - accuracy: 0.6349\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6249 - accuracy: 0.6645\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=512;, score=0.665 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6435 - accuracy: 0.6407\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6226 - accuracy: 0.6734\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=2, n_nodes=512;, score=0.673 total time=   5.3s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6976 - accuracy: 0.5150\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6850 - accuracy: 0.6224\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=32;, score=0.622 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7000 - accuracy: 0.5363\n",
      "354/354 [==============================] - 2s 3ms/step - loss: 0.6724 - accuracy: 0.6449\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=32;, score=0.645 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6887 - accuracy: 0.5476\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6700 - accuracy: 0.6446\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=32;, score=0.645 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6891 - accuracy: 0.5445\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6636 - accuracy: 0.6623\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=64;, score=0.662 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6903 - accuracy: 0.5475\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6576 - accuracy: 0.6559\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=64;, score=0.656 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6817 - accuracy: 0.5668\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6574 - accuracy: 0.6460\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=64;, score=0.646 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6762 - accuracy: 0.5785\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6368 - accuracy: 0.6671\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=128;, score=0.667 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6725 - accuracy: 0.5868\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6419 - accuracy: 0.6349\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=128;, score=0.635 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5843\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6359 - accuracy: 0.6545\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=128;, score=0.655 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6568 - accuracy: 0.6220\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.6681\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=256;, score=0.668 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6603 - accuracy: 0.6107\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6163 - accuracy: 0.6760\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=256;, score=0.676 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6578 - accuracy: 0.6175\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6749\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=256;, score=0.675 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6455 - accuracy: 0.6383\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.6725\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=512;, score=0.672 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6463 - accuracy: 0.6353\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6102 - accuracy: 0.6843\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=512;, score=0.684 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6452 - accuracy: 0.6352\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6202 - accuracy: 0.6745\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=3, n_nodes=512;, score=0.674 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6987 - accuracy: 0.5085\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6884 - accuracy: 0.5801\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=32;, score=0.580 total time=   6.7s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6925 - accuracy: 0.5226\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6852 - accuracy: 0.6279\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=32;, score=0.628 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6948 - accuracy: 0.5116\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6862 - accuracy: 0.6434\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=32;, score=0.643 total time=   6.7s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6869 - accuracy: 0.5452\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6642 - accuracy: 0.6397\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=64;, score=0.640 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6916 - accuracy: 0.5290\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6753 - accuracy: 0.6431\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=64;, score=0.643 total time=   6.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6875 - accuracy: 0.5492\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6626 - accuracy: 0.6663\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=64;, score=0.666 total time=   7.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6838 - accuracy: 0.5578\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6432 - accuracy: 0.6585\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=128;, score=0.658 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6803 - accuracy: 0.5685\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6414 - accuracy: 0.6433\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=128;, score=0.643 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6793 - accuracy: 0.5663\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6373 - accuracy: 0.6686\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=128;, score=0.669 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6558 - accuracy: 0.6165\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6490 - accuracy: 0.6459\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=256;, score=0.646 total time=   6.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6601 - accuracy: 0.6068\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6155 - accuracy: 0.6759\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=256;, score=0.676 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6590 - accuracy: 0.6095\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6214 - accuracy: 0.6776\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=256;, score=0.678 total time=   6.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6463 - accuracy: 0.6317\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.6689\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=512;, score=0.669 total time=   7.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6483 - accuracy: 0.6325\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6104 - accuracy: 0.6797\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=512;, score=0.680 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6473 - accuracy: 0.6268\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.6640\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=4, n_nodes=512;, score=0.664 total time=   6.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6933 - accuracy: 0.5088\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6904 - accuracy: 0.5321\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=32;, score=0.532 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6935 - accuracy: 0.5165\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6891 - accuracy: 0.5514\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=32;, score=0.551 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6972 - accuracy: 0.5096\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6896 - accuracy: 0.6314\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=32;, score=0.631 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6919 - accuracy: 0.5276\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6809 - accuracy: 0.6027\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=64;, score=0.603 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6926 - accuracy: 0.5232\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6786 - accuracy: 0.6574\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=64;, score=0.657 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6923 - accuracy: 0.5253\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6799 - accuracy: 0.6220\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=64;, score=0.622 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6885 - accuracy: 0.5383\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6483 - accuracy: 0.6577\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=128;, score=0.658 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6833 - accuracy: 0.5527\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6373 - accuracy: 0.6652\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=128;, score=0.665 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6747 - accuracy: 0.5739\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.6707\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=128;, score=0.671 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6601 - accuracy: 0.6044\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6255 - accuracy: 0.6685\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=256;, score=0.669 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6634 - accuracy: 0.6023\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6146 - accuracy: 0.6790\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=256;, score=0.679 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6649 - accuracy: 0.5932\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6218 - accuracy: 0.6752\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=256;, score=0.675 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6495 - accuracy: 0.6255\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6293 - accuracy: 0.6692\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=512;, score=0.669 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6535 - accuracy: 0.6182\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6157 - accuracy: 0.6771\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=512;, score=0.677 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6484 - accuracy: 0.6263\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6184 - accuracy: 0.6717\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=5, n_nodes=512;, score=0.672 total time=   7.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6944 - accuracy: 0.4996\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.5129\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=32;, score=0.513 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6937 - accuracy: 0.5119\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6889 - accuracy: 0.6131\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=32;, score=0.613 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6929 - accuracy: 0.5163\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6886 - accuracy: 0.6344\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=32;, score=0.634 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6907 - accuracy: 0.5280\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6685 - accuracy: 0.6595\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=64;, score=0.660 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6925 - accuracy: 0.5223\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6804 - accuracy: 0.6165\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=64;, score=0.616 total time=   8.8s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6935 - accuracy: 0.5101\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.6067\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=64;, score=0.607 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6825 - accuracy: 0.5579\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6387 - accuracy: 0.6577\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=128;, score=0.658 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6826 - accuracy: 0.5561\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6266 - accuracy: 0.6747\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=128;, score=0.675 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6798 - accuracy: 0.5670\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6334 - accuracy: 0.6585\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=128;, score=0.659 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6643 - accuracy: 0.5966\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6248 - accuracy: 0.6691\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=256;, score=0.669 total time=   8.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6654 - accuracy: 0.5929\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6138 - accuracy: 0.6824\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=256;, score=0.682 total time=   7.7s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6648 - accuracy: 0.5923\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6258 - accuracy: 0.6613\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=256;, score=0.661 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6477 - accuracy: 0.6302\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6216 - accuracy: 0.6695\n",
      "[CV 1/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=512;, score=0.669 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6563 - accuracy: 0.6150\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6239 - accuracy: 0.6796\n",
      "[CV 2/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=512;, score=0.680 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6545 - accuracy: 0.6098\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6234 - accuracy: 0.6688\n",
      "[CV 3/3] END dropout=0.2, lr=0.0001, n_layers=6, n_nodes=512;, score=0.669 total time=   7.9s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6524 - accuracy: 0.6331\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6344 - accuracy: 0.6664\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=32;, score=0.666 total time=   4.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6633 - accuracy: 0.6144\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6376 - accuracy: 0.6615\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=32;, score=0.662 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6529 - accuracy: 0.6306\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6244 - accuracy: 0.6756\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=32;, score=0.676 total time=   4.9s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6507 - accuracy: 0.6360\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6637\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=64;, score=0.664 total time=   4.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6576 - accuracy: 0.6201\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6183 - accuracy: 0.6787\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=64;, score=0.679 total time=   4.3s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6485 - accuracy: 0.6384\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6253 - accuracy: 0.6756\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=64;, score=0.676 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6397 - accuracy: 0.6501\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6310 - accuracy: 0.6579\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=128;, score=0.658 total time=   4.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6483 - accuracy: 0.6375\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6163 - accuracy: 0.6810\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=128;, score=0.681 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6426 - accuracy: 0.6416\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6706 - accuracy: 0.5877\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=128;, score=0.588 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6380 - accuracy: 0.6514\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6331 - accuracy: 0.6562\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=256;, score=0.656 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6440 - accuracy: 0.6414\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6157 - accuracy: 0.6819\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=256;, score=0.682 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6418 - accuracy: 0.6434\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6320 - accuracy: 0.6584\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=256;, score=0.658 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6378 - accuracy: 0.6491\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6255 - accuracy: 0.6710\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=512;, score=0.671 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6434 - accuracy: 0.6392\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6119 - accuracy: 0.6825\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=512;, score=0.682 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6407 - accuracy: 0.6472\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6234 - accuracy: 0.6741\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=1, n_nodes=512;, score=0.674 total time=   5.1s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6646 - accuracy: 0.6046\n",
      "354/354 [==============================] - 2s 3ms/step - loss: 0.6341 - accuracy: 0.6543\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=32;, score=0.654 total time=   6.1s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6559 - accuracy: 0.6209\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6220 - accuracy: 0.6716\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=32;, score=0.672 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6601 - accuracy: 0.6092\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.6497\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=32;, score=0.650 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6430 - accuracy: 0.6409\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6240 - accuracy: 0.6744\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=64;, score=0.674 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6470 - accuracy: 0.6358\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6188 - accuracy: 0.6804\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=64;, score=0.680 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6449 - accuracy: 0.6364\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6549 - accuracy: 0.6090\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=64;, score=0.609 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6410 - accuracy: 0.6453\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6221 - accuracy: 0.6719\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=128;, score=0.672 total time=   5.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6431 - accuracy: 0.6403\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6238 - accuracy: 0.6702\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=128;, score=0.670 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6395 - accuracy: 0.6456\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6235 - accuracy: 0.6696\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=128;, score=0.670 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6371 - accuracy: 0.6536\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6225 - accuracy: 0.6700\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=256;, score=0.670 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6444 - accuracy: 0.6380\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6146 - accuracy: 0.6798\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=256;, score=0.680 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6396 - accuracy: 0.6485\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.6727\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=256;, score=0.673 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6346 - accuracy: 0.6507\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6713\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=512;, score=0.671 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6443 - accuracy: 0.6366\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6392 - accuracy: 0.6362\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=512;, score=0.636 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6379 - accuracy: 0.6485\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.6751\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=2, n_nodes=512;, score=0.675 total time=   5.3s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6605 - accuracy: 0.6059\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6282 - accuracy: 0.6637\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=32;, score=0.664 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6615 - accuracy: 0.6107\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6246 - accuracy: 0.6743\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=32;, score=0.674 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6575 - accuracy: 0.6179\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6246 - accuracy: 0.6712\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=32;, score=0.671 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6455 - accuracy: 0.6374\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6590\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=64;, score=0.659 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6507 - accuracy: 0.6304\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6168 - accuracy: 0.6822\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=64;, score=0.682 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6508 - accuracy: 0.6270\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6194 - accuracy: 0.6727\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=64;, score=0.673 total time=   5.9s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6403 - accuracy: 0.6462\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6207 - accuracy: 0.6728\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=128;, score=0.673 total time=   6.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6478 - accuracy: 0.6338\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6201 - accuracy: 0.6765\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=128;, score=0.676 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6429 - accuracy: 0.6396\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6739\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=128;, score=0.674 total time=   5.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6391 - accuracy: 0.6487\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6204 - accuracy: 0.6717\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=256;, score=0.672 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6442 - accuracy: 0.6395\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6125 - accuracy: 0.6851\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=256;, score=0.685 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6417 - accuracy: 0.6448\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.6701\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=256;, score=0.670 total time=   5.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6372 - accuracy: 0.6489\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6228 - accuracy: 0.6736\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=512;, score=0.674 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6442 - accuracy: 0.6394\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6107 - accuracy: 0.6804\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=512;, score=0.680 total time=   5.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6378 - accuracy: 0.6494\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6297 - accuracy: 0.6642\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=3, n_nodes=512;, score=0.664 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6629 - accuracy: 0.6078\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6329 - accuracy: 0.6647\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=32;, score=0.665 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6575 - accuracy: 0.6180\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6167 - accuracy: 0.6827\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=32;, score=0.683 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6571 - accuracy: 0.6184\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6249 - accuracy: 0.6736\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=32;, score=0.674 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6462 - accuracy: 0.6345\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6279 - accuracy: 0.6647\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=64;, score=0.665 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6523 - accuracy: 0.6281\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6282 - accuracy: 0.6623\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=64;, score=0.662 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6514 - accuracy: 0.6264\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6251 - accuracy: 0.6749\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=64;, score=0.675 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6448 - accuracy: 0.6358\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6628\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=128;, score=0.663 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6480 - accuracy: 0.6326\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6318 - accuracy: 0.6598\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=128;, score=0.660 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6425 - accuracy: 0.6461\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6212 - accuracy: 0.6734\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=128;, score=0.673 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6392 - accuracy: 0.6474\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.6554\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=256;, score=0.655 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6437 - accuracy: 0.6444\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6233 - accuracy: 0.6677\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=256;, score=0.668 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6452 - accuracy: 0.6357\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6211 - accuracy: 0.6766\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=256;, score=0.677 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6408 - accuracy: 0.6449\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6233 - accuracy: 0.6718\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=512;, score=0.672 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6447 - accuracy: 0.6400\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6274 - accuracy: 0.6737\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=512;, score=0.674 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6441 - accuracy: 0.6391\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6214 - accuracy: 0.6762\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=4, n_nodes=512;, score=0.676 total time=   6.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6735 - accuracy: 0.5752\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6327 - accuracy: 0.6590\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=32;, score=0.659 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6692 - accuracy: 0.5916\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6238 - accuracy: 0.6730\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=32;, score=0.673 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6662 - accuracy: 0.5992\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6762\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=32;, score=0.676 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6471 - accuracy: 0.6379\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6241 - accuracy: 0.6682\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=64;, score=0.668 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6581 - accuracy: 0.6190\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6212 - accuracy: 0.6749\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=64;, score=0.675 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6626 - accuracy: 0.5972\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6252 - accuracy: 0.6680\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=64;, score=0.668 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6445 - accuracy: 0.6402\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6336 - accuracy: 0.6611\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=128;, score=0.661 total time=   7.2s\n",
      "708/708 [==============================] - 7s 8ms/step - loss: 0.6515 - accuracy: 0.6243\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6485 - accuracy: 0.6116\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=128;, score=0.612 total time=   8.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6439 - accuracy: 0.6388\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6240 - accuracy: 0.6722\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=128;, score=0.672 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6427 - accuracy: 0.6421\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6252 - accuracy: 0.6773\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=256;, score=0.677 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6502 - accuracy: 0.6315\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6145 - accuracy: 0.6812\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=256;, score=0.681 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6479 - accuracy: 0.6344\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6212 - accuracy: 0.6773\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=256;, score=0.677 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6423 - accuracy: 0.6428\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6435 - accuracy: 0.6388\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=512;, score=0.639 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6483 - accuracy: 0.6343\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6130 - accuracy: 0.6796\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=512;, score=0.680 total time=   7.4s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6423 - accuracy: 0.6438\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6253 - accuracy: 0.6731\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=5, n_nodes=512;, score=0.673 total time=   6.8s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6681 - accuracy: 0.5899\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6359 - accuracy: 0.6474\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=32;, score=0.647 total time=   7.9s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6691 - accuracy: 0.5883\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6309 - accuracy: 0.6721\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=32;, score=0.672 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6751 - accuracy: 0.5697\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6251 - accuracy: 0.6676\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=32;, score=0.668 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6574 - accuracy: 0.6103\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6271 - accuracy: 0.6694\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=64;, score=0.669 total time=   8.1s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6569 - accuracy: 0.6208\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6202 - accuracy: 0.6834\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=64;, score=0.683 total time=   7.8s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6567 - accuracy: 0.6172\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6230 - accuracy: 0.6688\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=64;, score=0.669 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6479 - accuracy: 0.6377\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6232 - accuracy: 0.6738\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=128;, score=0.674 total time=   7.8s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6543 - accuracy: 0.6229\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6141 - accuracy: 0.6804\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=128;, score=0.680 total time=   8.3s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6499 - accuracy: 0.6295\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6324 - accuracy: 0.6733\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=128;, score=0.673 total time=   7.8s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6454 - accuracy: 0.6376\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6710\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=256;, score=0.671 total time=   7.8s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6523 - accuracy: 0.6310\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6397 - accuracy: 0.6853\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=256;, score=0.685 total time=   7.8s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6474 - accuracy: 0.6384\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6368 - accuracy: 0.6764\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=256;, score=0.676 total time=   8.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6442 - accuracy: 0.6425\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6350 - accuracy: 0.6623\n",
      "[CV 1/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=512;, score=0.662 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6568 - accuracy: 0.6199\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6610\n",
      "[CV 2/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=512;, score=0.661 total time=   8.7s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6474 - accuracy: 0.6389\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6187 - accuracy: 0.6785\n",
      "[CV 3/3] END dropout=0.2, lr=0.001, n_layers=6, n_nodes=512;, score=0.678 total time=   7.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6463 - accuracy: 0.6389\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.6566\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=32;, score=0.657 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6581 - accuracy: 0.6103\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6281 - accuracy: 0.6778\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=32;, score=0.678 total time=   4.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6553 - accuracy: 0.6257\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6382 - accuracy: 0.6608\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=32;, score=0.661 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6424 - accuracy: 0.6451\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.6668\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=64;, score=0.667 total time=   4.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6478 - accuracy: 0.6304\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6151 - accuracy: 0.6842\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=64;, score=0.684 total time=   4.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6432 - accuracy: 0.6439\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6228 - accuracy: 0.6710\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=64;, score=0.671 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6481 - accuracy: 0.6357\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.6726\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=128;, score=0.673 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6506 - accuracy: 0.6302\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6143 - accuracy: 0.6810\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=128;, score=0.681 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6512 - accuracy: 0.6338\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6230 - accuracy: 0.6715\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=128;, score=0.671 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6507 - accuracy: 0.6297\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6230 - accuracy: 0.6719\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=256;, score=0.672 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6513 - accuracy: 0.6312\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6120 - accuracy: 0.6827\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=256;, score=0.683 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6487 - accuracy: 0.6332\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6314 - accuracy: 0.6748\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=256;, score=0.675 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6476 - accuracy: 0.6371\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.6719\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=512;, score=0.672 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6499 - accuracy: 0.6341\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6247 - accuracy: 0.6737\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=512;, score=0.674 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6566 - accuracy: 0.6223\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6209 - accuracy: 0.6773\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=1, n_nodes=512;, score=0.677 total time=   4.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6934 - accuracy: 0.4998\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4976\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=32;, score=0.498 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6606 - accuracy: 0.6130\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6508 - accuracy: 0.6454\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=32;, score=0.645 total time=   5.4s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6595 - accuracy: 0.6104\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6423 - accuracy: 0.6631\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=32;, score=0.663 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6511 - accuracy: 0.6214\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6391 - accuracy: 0.6588\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=64;, score=0.659 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6605 - accuracy: 0.6049\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6513 - accuracy: 0.6469\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=64;, score=0.647 total time=   5.4s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6628 - accuracy: 0.6093\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6400 - accuracy: 0.6796\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=64;, score=0.680 total time=   4.7s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6638 - accuracy: 0.6039\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6406 - accuracy: 0.6728\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=128;, score=0.673 total time=   3.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6570 - accuracy: 0.6097\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6173 - accuracy: 0.6783\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=128;, score=0.678 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6534 - accuracy: 0.6290\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.6610\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=128;, score=0.661 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6589 - accuracy: 0.6205\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.6590\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=256;, score=0.659 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6651 - accuracy: 0.6111\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6817\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=256;, score=0.682 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6604 - accuracy: 0.6148\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.6750\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=256;, score=0.675 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6572 - accuracy: 0.6129\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6435 - accuracy: 0.6469\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=512;, score=0.647 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6741 - accuracy: 0.5941\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6441 - accuracy: 0.6245\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=512;, score=0.625 total time=   5.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6628 - accuracy: 0.6215\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6381 - accuracy: 0.6775\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=2, n_nodes=512;, score=0.678 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6570 - accuracy: 0.6129\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6242 - accuracy: 0.6731\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=32;, score=0.673 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6788 - accuracy: 0.5672\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6414 - accuracy: 0.6814\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=32;, score=0.681 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6775 - accuracy: 0.5688\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6366 - accuracy: 0.6696\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=32;, score=0.670 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6756 - accuracy: 0.5751\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.4981\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=64;, score=0.498 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6700 - accuracy: 0.5930\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6458 - accuracy: 0.6550\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=64;, score=0.655 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6654 - accuracy: 0.6096\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6486 - accuracy: 0.6450\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=64;, score=0.645 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6619 - accuracy: 0.6138\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6292 - accuracy: 0.6603\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=128;, score=0.660 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6729 - accuracy: 0.5901\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6200 - accuracy: 0.6843\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=128;, score=0.684 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6682 - accuracy: 0.6037\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6765\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=128;, score=0.677 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6901 - accuracy: 0.5342\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=256;, score=0.503 total time=   5.9s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6861 - accuracy: 0.5532\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5017\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=256;, score=0.502 total time=   5.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6971 - accuracy: 0.5031\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=256;, score=0.499 total time=   4.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6782 - accuracy: 0.6060\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6362 - accuracy: 0.6726\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=512;, score=0.673 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6983 - accuracy: 0.5156\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=512;, score=0.499 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7008 - accuracy: 0.4996\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=3, n_nodes=512;, score=0.499 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6931 - accuracy: 0.5054\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=32;, score=0.503 total time=   5.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6757 - accuracy: 0.5746\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6466 - accuracy: 0.6797\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=32;, score=0.680 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6730 - accuracy: 0.5946\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6526 - accuracy: 0.6676\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=32;, score=0.668 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6661 - accuracy: 0.6017\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6537 - accuracy: 0.6556\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=64;, score=0.656 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5914\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6192 - accuracy: 0.6841\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=64;, score=0.684 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6940 - accuracy: 0.5012\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=64;, score=0.499 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6759 - accuracy: 0.5881\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6621 - accuracy: 0.6354\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=128;, score=0.635 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6938 - accuracy: 0.5060\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=128;, score=0.501 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6805 - accuracy: 0.5737\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=128;, score=0.499 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6954 - accuracy: 0.5071\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=256;, score=0.503 total time=   6.3s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6954 - accuracy: 0.5071\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=256;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6944 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=256;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7205 - accuracy: 0.4972\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=512;, score=0.503 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7137 - accuracy: 0.5110\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6946 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=512;, score=0.501 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7066 - accuracy: 0.5065\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=4, n_nodes=512;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6935 - accuracy: 0.5005\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=32;, score=0.503 total time=   6.7s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6938 - accuracy: 0.5010\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=32;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6939 - accuracy: 0.5072\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=32;, score=0.501 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6939 - accuracy: 0.5027\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=64;, score=0.497 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6939 - accuracy: 0.4970\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=64;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6927 - accuracy: 0.5057\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=64;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6948 - accuracy: 0.4995\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=128;, score=0.503 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6942 - accuracy: 0.4979\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=128;, score=0.501 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6933 - accuracy: 0.5065\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6946 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=128;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6950 - accuracy: 0.5007\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=256;, score=0.497 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6965 - accuracy: 0.5006\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=256;, score=0.499 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6980 - accuracy: 0.4978\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=256;, score=0.501 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7038 - accuracy: 0.4981\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=512;, score=0.497 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7092 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=512;, score=0.499 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7028 - accuracy: 0.4973\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=5, n_nodes=512;, score=0.501 total time=   6.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6937 - accuracy: 0.5008\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=32;, score=0.497 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6937 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=32;, score=0.499 total time=   7.4s\n",
      "708/708 [==============================] - 7s 8ms/step - loss: 0.6938 - accuracy: 0.4970\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=32;, score=0.501 total time=   8.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6940 - accuracy: 0.5028\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=64;, score=0.503 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6942 - accuracy: 0.5011\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=64;, score=0.499 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6942 - accuracy: 0.4996\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=64;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6942 - accuracy: 0.5019\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=128;, score=0.503 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6934 - accuracy: 0.5042\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=128;, score=0.501 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6941 - accuracy: 0.4988\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=128;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6976 - accuracy: 0.4988\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=256;, score=0.497 total time=   6.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6967 - accuracy: 0.4987\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=256;, score=0.499 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6958 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=256;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7603 - accuracy: 0.4965\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=512;, score=0.503 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7098 - accuracy: 0.5002\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6942 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=512;, score=0.501 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7275 - accuracy: 0.4996\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6949 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.01, n_layers=6, n_nodes=512;, score=0.499 total time=   7.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7019 - accuracy: 0.5080\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7011 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=32;, score=0.497 total time=   4.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6997 - accuracy: 0.5061\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=32;, score=0.499 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7082 - accuracy: 0.4976\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6972 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=32;, score=0.501 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7094 - accuracy: 0.5009\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=64;, score=0.503 total time=   4.4s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7096 - accuracy: 0.5006\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=64;, score=0.499 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7100 - accuracy: 0.5041\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6973 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=64;, score=0.501 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7182 - accuracy: 0.5035\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7120 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=128;, score=0.497 total time=   4.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7081 - accuracy: 0.5997\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6251 - accuracy: 0.6902\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=128;, score=0.690 total time=   4.4s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7237 - accuracy: 0.4978\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=128;, score=0.499 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7753 - accuracy: 0.5025\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6976 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=256;, score=0.497 total time=   4.4s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7391 - accuracy: 0.5009\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4987\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=256;, score=0.499 total time=   4.4s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7520 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=256;, score=0.501 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.8190 - accuracy: 0.5015\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=512;, score=0.503 total time=   4.3s\n",
      "708/708 [==============================] - 4s 4ms/step - loss: 0.8091 - accuracy: 0.5142\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6945 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=512;, score=0.499 total time=   4.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.8013 - accuracy: 0.5099\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=1, n_nodes=512;, score=0.501 total time=   3.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7008 - accuracy: 0.5013\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=32;, score=0.497 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7031 - accuracy: 0.4993\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=32;, score=0.501 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6996 - accuracy: 0.4966\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7001 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=32;, score=0.501 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7096 - accuracy: 0.4991\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6953 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=64;, score=0.503 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7319 - accuracy: 0.5010\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=64;, score=0.501 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7062 - accuracy: 0.4974\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=64;, score=0.499 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7302 - accuracy: 0.5059\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=128;, score=0.503 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.8360 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=128;, score=0.499 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7436 - accuracy: 0.4966\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=128;, score=0.499 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.9913 - accuracy: 0.5012\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=256;, score=0.497 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.9060 - accuracy: 0.5039\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=256;, score=0.501 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.8805 - accuracy: 0.5001\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=256;, score=0.499 total time=   5.1s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.3806 - accuracy: 0.4977\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=512;, score=0.503 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 2.1388 - accuracy: 0.5001\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=512;, score=0.501 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 1.4707 - accuracy: 0.4977\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6951 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=2, n_nodes=512;, score=0.499 total time=   5.1s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7064 - accuracy: 0.5012\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6954 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=32;, score=0.497 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7008 - accuracy: 0.5007\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6953 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=32;, score=0.501 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7230 - accuracy: 0.4953\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=32;, score=0.499 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7164 - accuracy: 0.5024\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6949 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=64;, score=0.497 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7245 - accuracy: 0.4957\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=64;, score=0.501 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7195 - accuracy: 0.5012\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=64;, score=0.501 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.8036 - accuracy: 0.4985\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6949 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=128;, score=0.497 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.8187 - accuracy: 0.5011\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=128;, score=0.501 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7887 - accuracy: 0.4984\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=128;, score=0.499 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.6801 - accuracy: 0.5047\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6963 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=256;, score=0.503 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.6659 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=256;, score=0.501 total time=   5.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 1.6651 - accuracy: 0.5101\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=256;, score=0.499 total time=   6.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 15.5287 - accuracy: 0.4946\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6982 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=512;, score=0.497 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 13.0630 - accuracy: 0.4959\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=512;, score=0.501 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 6.0824 - accuracy: 0.4973\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6951 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=3, n_nodes=512;, score=0.499 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7003 - accuracy: 0.5075\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=32;, score=0.503 total time=   5.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6999 - accuracy: 0.5002\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=32;, score=0.501 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6989 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=32;, score=0.499 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7304 - accuracy: 0.4942\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=64;, score=0.497 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7490 - accuracy: 0.5047\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6957 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=64;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7284 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=64;, score=0.501 total time=   6.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 2.2313 - accuracy: 0.5038\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=128;, score=0.497 total time=   5.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.8126 - accuracy: 0.5053\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=128;, score=0.501 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.0772 - accuracy: 0.4983\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=128;, score=0.499 total time=   5.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 3.0371 - accuracy: 0.5032\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6975 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=256;, score=0.497 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 2.6317 - accuracy: 0.5060\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6966 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=256;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 3.6851 - accuracy: 0.4979\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=256;, score=0.499 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 125.8275 - accuracy: 0.4950\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6988 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=512;, score=0.503 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 150.0431 - accuracy: 0.5085\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6987 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=512;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 80.9363 - accuracy: 0.5004\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6944 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=4, n_nodes=512;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7079 - accuracy: 0.4979\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=32;, score=0.503 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7001 - accuracy: 0.4936\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6959 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=32;, score=0.501 total time=   6.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7013 - accuracy: 0.5010\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6951 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=32;, score=0.501 total time=   5.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7770 - accuracy: 0.5003\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=64;, score=0.497 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.8270 - accuracy: 0.5017\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6961 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=64;, score=0.501 total time=   6.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.8781 - accuracy: 0.5038\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6991 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=64;, score=0.499 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 1.4919 - accuracy: 0.4970\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=128;, score=0.497 total time=   6.7s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 2.2247 - accuracy: 0.4941\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=128;, score=0.501 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 1.4025 - accuracy: 0.4985\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=128;, score=0.501 total time=   6.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 23.8175 - accuracy: 0.4988\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=256;, score=0.497 total time=   7.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 30.8390 - accuracy: 0.4982\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=256;, score=0.501 total time=   6.7s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 17.2634 - accuracy: 0.4962\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=256;, score=0.501 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 139.8468 - accuracy: 0.4958\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6965 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=512;, score=0.503 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 816.9182 - accuracy: 0.4993\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6967 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=512;, score=0.501 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 390.4722 - accuracy: 0.4947\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=5, n_nodes=512;, score=0.499 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7025 - accuracy: 0.5017\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6942 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=32;, score=0.497 total time=   6.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7066 - accuracy: 0.4977\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7023 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=32;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6987 - accuracy: 0.5023\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=32;, score=0.499 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7387 - accuracy: 0.4947\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6975 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=64;, score=0.497 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7463 - accuracy: 0.4918\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=64;, score=0.501 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7683 - accuracy: 0.5058\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=64;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 2.1806 - accuracy: 0.5002\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=128;, score=0.497 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 2.9848 - accuracy: 0.4990\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=128;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 2.9601 - accuracy: 0.5037\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6960 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=128;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 114.7744 - accuracy: 0.5034\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=256;, score=0.503 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 206.6900 - accuracy: 0.4990\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6959 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=256;, score=0.499 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 12.3556 - accuracy: 0.5034\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6993 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=256;, score=0.499 total time=   7.3s\n",
      "708/708 [==============================] - 7s 8ms/step - loss: 6613.3267 - accuracy: 0.4921\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=512;, score=0.503 total time=   8.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 2087.9734 - accuracy: 0.4994\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6966 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=512;, score=0.499 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 2300.7053 - accuracy: 0.5021\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.2, lr=0.1, n_layers=6, n_nodes=512;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6965 - accuracy: 0.5272\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6831 - accuracy: 0.6296\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=32;, score=0.630 total time=   4.4s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6894 - accuracy: 0.5460\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6716 - accuracy: 0.6320\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=32;, score=0.632 total time=   4.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6937 - accuracy: 0.5344\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6807 - accuracy: 0.6360\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=32;, score=0.636 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7062 - accuracy: 0.5379\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6756 - accuracy: 0.6453\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=64;, score=0.645 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6873 - accuracy: 0.5519\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6677 - accuracy: 0.6713\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=64;, score=0.671 total time=   5.0s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6901 - accuracy: 0.5623\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6689 - accuracy: 0.6626\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=64;, score=0.663 total time=   4.4s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6841 - accuracy: 0.5793\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6607 - accuracy: 0.6558\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=128;, score=0.656 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6869 - accuracy: 0.5578\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6594 - accuracy: 0.6589\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=128;, score=0.659 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6820 - accuracy: 0.5750\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6549 - accuracy: 0.6567\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=128;, score=0.657 total time=   4.9s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6769 - accuracy: 0.5856\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6546 - accuracy: 0.6688\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=256;, score=0.669 total time=   4.1s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6739 - accuracy: 0.5912\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6517 - accuracy: 0.6310\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=256;, score=0.631 total time=   3.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6792 - accuracy: 0.5814\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6533 - accuracy: 0.6520\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=256;, score=0.652 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6692 - accuracy: 0.6045\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6463 - accuracy: 0.6435\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=512;, score=0.644 total time=   4.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6684 - accuracy: 0.6110\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6413 - accuracy: 0.6762\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=512;, score=0.676 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6676 - accuracy: 0.6152\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6427 - accuracy: 0.6752\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=1, n_nodes=512;, score=0.675 total time=   4.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7041 - accuracy: 0.5103\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6807 - accuracy: 0.6078\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=32;, score=0.608 total time=   5.0s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6992 - accuracy: 0.5277\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6807 - accuracy: 0.6451\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=32;, score=0.645 total time=   4.4s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7123 - accuracy: 0.5226\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6818 - accuracy: 0.6180\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=32;, score=0.618 total time=   4.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6895 - accuracy: 0.5495\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6691 - accuracy: 0.6517\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=64;, score=0.652 total time=   5.4s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6963 - accuracy: 0.5368\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6630 - accuracy: 0.6421\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=64;, score=0.642 total time=   5.0s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6946 - accuracy: 0.5512\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6625 - accuracy: 0.6581\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=64;, score=0.658 total time=   5.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6821 - accuracy: 0.5716\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6484 - accuracy: 0.6621\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=128;, score=0.662 total time=   5.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6840 - accuracy: 0.5705\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6494 - accuracy: 0.6532\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=128;, score=0.653 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6833 - accuracy: 0.5691\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6505 - accuracy: 0.6582\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=128;, score=0.658 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6656 - accuracy: 0.6069\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.6547\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=256;, score=0.655 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6665 - accuracy: 0.6039\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6385 - accuracy: 0.6370\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=256;, score=0.637 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6677 - accuracy: 0.5956\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6710\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=256;, score=0.671 total time=   5.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6473 - accuracy: 0.6363\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6426 - accuracy: 0.6414\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=512;, score=0.641 total time=   5.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6524 - accuracy: 0.6306\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6234 - accuracy: 0.6657\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=512;, score=0.666 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6520 - accuracy: 0.6304\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6303 - accuracy: 0.6616\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=2, n_nodes=512;, score=0.662 total time=   5.0s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7057 - accuracy: 0.5066\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6916 - accuracy: 0.5807\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=32;, score=0.581 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7069 - accuracy: 0.5122\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6881 - accuracy: 0.5796\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=32;, score=0.580 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7009 - accuracy: 0.5146\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6848 - accuracy: 0.6316\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=32;, score=0.632 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6975 - accuracy: 0.5356\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6795 - accuracy: 0.5945\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=64;, score=0.595 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6943 - accuracy: 0.5287\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6744 - accuracy: 0.6414\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=64;, score=0.641 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7036 - accuracy: 0.5265\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6785 - accuracy: 0.6317\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=64;, score=0.632 total time=   5.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6833 - accuracy: 0.5611\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6526 - accuracy: 0.6297\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=128;, score=0.630 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6842 - accuracy: 0.5606\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6412 - accuracy: 0.6670\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=128;, score=0.667 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6888 - accuracy: 0.5465\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6533 - accuracy: 0.6743\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=128;, score=0.674 total time=   4.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6648 - accuracy: 0.6026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6319 - accuracy: 0.6591\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=256;, score=0.659 total time=   5.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6687 - accuracy: 0.5973\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6262 - accuracy: 0.6638\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=256;, score=0.664 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6748 - accuracy: 0.5833\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6289 - accuracy: 0.6686\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=256;, score=0.669 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6529 - accuracy: 0.6250\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.6651\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=512;, score=0.665 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6549 - accuracy: 0.6219\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6143 - accuracy: 0.6834\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=512;, score=0.683 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6557 - accuracy: 0.6172\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.6704\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=3, n_nodes=512;, score=0.670 total time=   5.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6979 - accuracy: 0.5054\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6895 - accuracy: 0.5823\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=32;, score=0.582 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6952 - accuracy: 0.5086\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6920 - accuracy: 0.5645\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=32;, score=0.564 total time=   5.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6970 - accuracy: 0.5081\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6877 - accuracy: 0.6255\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=32;, score=0.625 total time=   6.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6996 - accuracy: 0.5117\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6817 - accuracy: 0.6547\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=64;, score=0.655 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7001 - accuracy: 0.5052\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6891 - accuracy: 0.6048\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=64;, score=0.605 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6963 - accuracy: 0.5150\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6824 - accuracy: 0.6631\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=64;, score=0.663 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6901 - accuracy: 0.5369\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6617 - accuracy: 0.6504\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=128;, score=0.650 total time=   6.3s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6876 - accuracy: 0.5436\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6503 - accuracy: 0.6710\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=128;, score=0.671 total time=   5.4s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6915 - accuracy: 0.5329\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6613 - accuracy: 0.6611\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=128;, score=0.661 total time=   7.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6667 - accuracy: 0.5974\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6713\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=256;, score=0.671 total time=   5.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6754 - accuracy: 0.5760\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6203 - accuracy: 0.6848\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=256;, score=0.685 total time=   6.3s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6708 - accuracy: 0.5881\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6286 - accuracy: 0.6648\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=256;, score=0.665 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6559 - accuracy: 0.6177\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6243 - accuracy: 0.6702\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=512;, score=0.670 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6595 - accuracy: 0.6082\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.6764\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=512;, score=0.676 total time=   5.9s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6608 - accuracy: 0.6033\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6222 - accuracy: 0.6712\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=4, n_nodes=512;, score=0.671 total time=   5.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7010 - accuracy: 0.5065\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.5616\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=32;, score=0.562 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6986 - accuracy: 0.5036\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5592\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=32;, score=0.559 total time=   6.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6968 - accuracy: 0.5087\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6913 - accuracy: 0.6090\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=32;, score=0.609 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6968 - accuracy: 0.5066\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6906 - accuracy: 0.5644\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=64;, score=0.564 total time=   6.6s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6974 - accuracy: 0.5053\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6900 - accuracy: 0.6217\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=64;, score=0.622 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6977 - accuracy: 0.5060\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6890 - accuracy: 0.5854\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=64;, score=0.585 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6929 - accuracy: 0.5284\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6778 - accuracy: 0.6608\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=128;, score=0.661 total time=   6.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6928 - accuracy: 0.5253\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6730 - accuracy: 0.6676\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=128;, score=0.668 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6946 - accuracy: 0.5113\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6887 - accuracy: 0.5567\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=128;, score=0.557 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6834 - accuracy: 0.5503\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.6554\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=256;, score=0.655 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6857 - accuracy: 0.5481\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6343 - accuracy: 0.6572\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=256;, score=0.657 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6765 - accuracy: 0.5686\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6263 - accuracy: 0.6739\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=256;, score=0.674 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6590 - accuracy: 0.6105\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6244 - accuracy: 0.6648\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=512;, score=0.665 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6620 - accuracy: 0.6015\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6225 - accuracy: 0.6698\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=512;, score=0.670 total time=   6.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6582 - accuracy: 0.6063\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6241 - accuracy: 0.6726\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=5, n_nodes=512;, score=0.673 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6948 - accuracy: 0.5107\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.5776\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=32;, score=0.578 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6964 - accuracy: 0.5079\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6905 - accuracy: 0.6527\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=32;, score=0.653 total time=   8.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6954 - accuracy: 0.4980\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.5019\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=32;, score=0.502 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6972 - accuracy: 0.5021\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=64;, score=0.503 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6951 - accuracy: 0.5075\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6906 - accuracy: 0.5265\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=64;, score=0.526 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6963 - accuracy: 0.5028\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6918 - accuracy: 0.6040\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=64;, score=0.604 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6957 - accuracy: 0.5029\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6910 - accuracy: 0.5850\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=128;, score=0.585 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6943 - accuracy: 0.5073\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6914 - accuracy: 0.6570\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=128;, score=0.657 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6935 - accuracy: 0.5155\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6861 - accuracy: 0.5653\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=128;, score=0.565 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6859 - accuracy: 0.5442\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6341 - accuracy: 0.6610\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=256;, score=0.661 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6873 - accuracy: 0.5390\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6373 - accuracy: 0.6518\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=256;, score=0.652 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6872 - accuracy: 0.5382\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6355 - accuracy: 0.6544\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=256;, score=0.654 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6585 - accuracy: 0.6067\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6277 - accuracy: 0.6593\n",
      "[CV 1/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=512;, score=0.659 total time=   7.3s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6678 - accuracy: 0.5845\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6154 - accuracy: 0.6776\n",
      "[CV 2/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=512;, score=0.678 total time=   6.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6636 - accuracy: 0.5977\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6205 - accuracy: 0.6773\n",
      "[CV 3/3] END dropout=0.3, lr=0.0001, n_layers=6, n_nodes=512;, score=0.677 total time=   6.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6526 - accuracy: 0.6274\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6301 - accuracy: 0.6598\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=32;, score=0.660 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6704 - accuracy: 0.6013\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6271 - accuracy: 0.6804\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=32;, score=0.680 total time=   4.4s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6569 - accuracy: 0.6301\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6230 - accuracy: 0.6779\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=32;, score=0.678 total time=   4.4s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6492 - accuracy: 0.6378\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6276 - accuracy: 0.6696\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=64;, score=0.670 total time=   4.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6532 - accuracy: 0.6277\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6382 - accuracy: 0.6452\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=64;, score=0.645 total time=   4.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6539 - accuracy: 0.6299\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6263 - accuracy: 0.6695\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=64;, score=0.669 total time=   4.4s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6494 - accuracy: 0.6391\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6277 - accuracy: 0.6694\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=128;, score=0.669 total time=   4.4s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6497 - accuracy: 0.6352\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6234 - accuracy: 0.6688\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=128;, score=0.669 total time=   4.4s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6482 - accuracy: 0.6386\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6236 - accuracy: 0.6718\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=128;, score=0.672 total time=   4.4s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6427 - accuracy: 0.6409\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6734\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=256;, score=0.673 total time=   4.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6455 - accuracy: 0.6398\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6160 - accuracy: 0.6780\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=256;, score=0.678 total time=   5.2s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6435 - accuracy: 0.6460\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6420 - accuracy: 0.6429\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=256;, score=0.643 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6411 - accuracy: 0.6441\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.6722\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=512;, score=0.672 total time=   3.8s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6420 - accuracy: 0.6444\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6177 - accuracy: 0.6816\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=512;, score=0.682 total time=   3.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6412 - accuracy: 0.6438\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6233 - accuracy: 0.6746\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=1, n_nodes=512;, score=0.675 total time=   4.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6607 - accuracy: 0.6146\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6365 - accuracy: 0.6542\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=32;, score=0.654 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6641 - accuracy: 0.6118\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.6768\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=32;, score=0.677 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6562 - accuracy: 0.6179\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6331 - accuracy: 0.6650\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=32;, score=0.665 total time=   5.3s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6483 - accuracy: 0.6330\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.6693\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=64;, score=0.669 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6589 - accuracy: 0.6140\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6225 - accuracy: 0.6846\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=64;, score=0.685 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6504 - accuracy: 0.6272\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6205 - accuracy: 0.6754\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=64;, score=0.675 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6455 - accuracy: 0.6402\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6354 - accuracy: 0.6504\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=128;, score=0.650 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6484 - accuracy: 0.6320\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6143 - accuracy: 0.6824\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=128;, score=0.682 total time=   5.1s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6461 - accuracy: 0.6348\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6555 - accuracy: 0.6386\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=128;, score=0.639 total time=   4.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6400 - accuracy: 0.6452\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6235 - accuracy: 0.6706\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=256;, score=0.671 total time=   4.7s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6466 - accuracy: 0.6367\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6173 - accuracy: 0.6767\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=256;, score=0.677 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6404 - accuracy: 0.6423\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6267 - accuracy: 0.6754\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=256;, score=0.675 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6406 - accuracy: 0.6458\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.6723\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=512;, score=0.672 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6449 - accuracy: 0.6406\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.6816\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=512;, score=0.682 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6417 - accuracy: 0.6424\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6207 - accuracy: 0.6722\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=2, n_nodes=512;, score=0.672 total time=   5.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6670 - accuracy: 0.5943\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6666\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=32;, score=0.667 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6632 - accuracy: 0.6049\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6221 - accuracy: 0.6779\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=32;, score=0.678 total time=   5.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6623 - accuracy: 0.6067\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6265 - accuracy: 0.6728\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=32;, score=0.673 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6610 - accuracy: 0.6089\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6271 - accuracy: 0.6684\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=64;, score=0.668 total time=   4.9s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6579 - accuracy: 0.6157\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6155 - accuracy: 0.6817\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=64;, score=0.682 total time=   5.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6567 - accuracy: 0.6212\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6263 - accuracy: 0.6773\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=64;, score=0.677 total time=   4.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6457 - accuracy: 0.6312\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6567\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=128;, score=0.657 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6490 - accuracy: 0.6345\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6200 - accuracy: 0.6691\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=128;, score=0.669 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6475 - accuracy: 0.6318\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6201 - accuracy: 0.6722\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=128;, score=0.672 total time=   5.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6427 - accuracy: 0.6433\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6219 - accuracy: 0.6711\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=256;, score=0.671 total time=   6.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6504 - accuracy: 0.6287\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6157 - accuracy: 0.6775\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=256;, score=0.678 total time=   5.6s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6453 - accuracy: 0.6405\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6399 - accuracy: 0.6443\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=256;, score=0.644 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6431 - accuracy: 0.6408\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6428 - accuracy: 0.6429\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=512;, score=0.643 total time=   5.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6444 - accuracy: 0.6395\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.6831\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=512;, score=0.683 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6410 - accuracy: 0.6447\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6294 - accuracy: 0.6750\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=3, n_nodes=512;, score=0.675 total time=   5.9s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6676 - accuracy: 0.6040\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6454 - accuracy: 0.6470\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=32;, score=0.647 total time=   5.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6867 - accuracy: 0.5437\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6307 - accuracy: 0.6742\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=32;, score=0.674 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5873\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6399 - accuracy: 0.6544\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=32;, score=0.654 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6636 - accuracy: 0.6013\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.6715\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=64;, score=0.672 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6629 - accuracy: 0.6085\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6222 - accuracy: 0.6735\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=64;, score=0.673 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6652 - accuracy: 0.6040\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6203 - accuracy: 0.6783\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=64;, score=0.678 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6487 - accuracy: 0.6353\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.6711\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=128;, score=0.671 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6533 - accuracy: 0.6211\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6570 - accuracy: 0.6018\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=128;, score=0.602 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6526 - accuracy: 0.6252\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6208 - accuracy: 0.6770\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=128;, score=0.677 total time=   6.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6458 - accuracy: 0.6366\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6327 - accuracy: 0.6562\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=256;, score=0.656 total time=   6.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6524 - accuracy: 0.6270\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6168 - accuracy: 0.6811\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=256;, score=0.681 total time=   5.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6467 - accuracy: 0.6373\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6187 - accuracy: 0.6726\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=256;, score=0.673 total time=   6.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6441 - accuracy: 0.6420\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6276 - accuracy: 0.6696\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=512;, score=0.670 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6489 - accuracy: 0.6336\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.6552\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=512;, score=0.655 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6495 - accuracy: 0.6346\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6767\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=4, n_nodes=512;, score=0.677 total time=   6.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6744 - accuracy: 0.5788\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6362 - accuracy: 0.6589\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=32;, score=0.659 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6769 - accuracy: 0.5729\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.6761\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=32;, score=0.676 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6770 - accuracy: 0.5763\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6296 - accuracy: 0.6702\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=32;, score=0.670 total time=   7.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6567 - accuracy: 0.6227\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6728\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=64;, score=0.673 total time=   6.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6666 - accuracy: 0.5983\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6169 - accuracy: 0.6785\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=64;, score=0.679 total time=   6.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6676 - accuracy: 0.5889\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6207 - accuracy: 0.6727\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=64;, score=0.673 total time=   5.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6542 - accuracy: 0.6189\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6462 - accuracy: 0.6476\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=128;, score=0.648 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6603 - accuracy: 0.6120\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6170 - accuracy: 0.6784\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=128;, score=0.678 total time=   6.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6554 - accuracy: 0.6207\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6241 - accuracy: 0.6700\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=128;, score=0.670 total time=   5.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6467 - accuracy: 0.6352\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6241 - accuracy: 0.6721\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=256;, score=0.672 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6552 - accuracy: 0.6191\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6124 - accuracy: 0.6829\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=256;, score=0.683 total time=   6.4s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6487 - accuracy: 0.6324\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6239 - accuracy: 0.6751\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=256;, score=0.675 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6465 - accuracy: 0.6376\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6255 - accuracy: 0.6676\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=512;, score=0.668 total time=   7.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6524 - accuracy: 0.6298\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.6606\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=512;, score=0.661 total time=   5.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6501 - accuracy: 0.6321\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.6653\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=5, n_nodes=512;, score=0.665 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6808 - accuracy: 0.5596\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6346 - accuracy: 0.6693\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=32;, score=0.669 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6937 - accuracy: 0.5043\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=32;, score=0.499 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6759 - accuracy: 0.5831\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6501 - accuracy: 0.6484\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=32;, score=0.648 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6660 - accuracy: 0.6000\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6263 - accuracy: 0.6689\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=64;, score=0.669 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6744 - accuracy: 0.5780\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6250 - accuracy: 0.6779\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=64;, score=0.678 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6788 - accuracy: 0.5642\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6421 - accuracy: 0.6727\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=64;, score=0.673 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6610 - accuracy: 0.6055\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6339 - accuracy: 0.6657\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=128;, score=0.666 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6755 - accuracy: 0.5702\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6280 - accuracy: 0.6662\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=128;, score=0.666 total time=   7.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6635 - accuracy: 0.5996\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6215 - accuracy: 0.6690\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=128;, score=0.669 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6577 - accuracy: 0.6181\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6242 - accuracy: 0.6712\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=256;, score=0.671 total time=   6.6s\n",
      "708/708 [==============================] - 7s 8ms/step - loss: 0.6588 - accuracy: 0.6145\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6252 - accuracy: 0.6787\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=256;, score=0.679 total time=   8.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6565 - accuracy: 0.6211\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6189 - accuracy: 0.6778\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=256;, score=0.678 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6552 - accuracy: 0.6295\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.6713\n",
      "[CV 1/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=512;, score=0.671 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6569 - accuracy: 0.6231\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6288 - accuracy: 0.6573\n",
      "[CV 2/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=512;, score=0.657 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6486 - accuracy: 0.6331\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6666\n",
      "[CV 3/3] END dropout=0.3, lr=0.001, n_layers=6, n_nodes=512;, score=0.667 total time=   7.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6691 - accuracy: 0.5907\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6531 - accuracy: 0.6464\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=32;, score=0.646 total time=   3.9s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6572 - accuracy: 0.6078\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6197 - accuracy: 0.6819\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=32;, score=0.682 total time=   4.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6655 - accuracy: 0.5970\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6484 - accuracy: 0.6620\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=32;, score=0.662 total time=   4.6s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6592 - accuracy: 0.6167\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6495 - accuracy: 0.6460\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=64;, score=0.646 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6574 - accuracy: 0.6142\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6299 - accuracy: 0.6773\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=64;, score=0.677 total time=   4.4s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6501 - accuracy: 0.6311\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6361 - accuracy: 0.6781\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=64;, score=0.678 total time=   4.6s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6505 - accuracy: 0.6312\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6343 - accuracy: 0.6718\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=128;, score=0.672 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6564 - accuracy: 0.6204\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6365 - accuracy: 0.6834\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=128;, score=0.683 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6531 - accuracy: 0.6279\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.6772\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=128;, score=0.677 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6523 - accuracy: 0.6299\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6304 - accuracy: 0.6762\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=256;, score=0.676 total time=   4.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6590 - accuracy: 0.6203\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6310 - accuracy: 0.6691\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=256;, score=0.669 total time=   4.3s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6518 - accuracy: 0.6282\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6314 - accuracy: 0.6819\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=256;, score=0.682 total time=   4.7s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6499 - accuracy: 0.6368\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6357 - accuracy: 0.6490\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=512;, score=0.649 total time=   3.8s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6545 - accuracy: 0.6297\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6198 - accuracy: 0.6809\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=512;, score=0.681 total time=   4.0s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6517 - accuracy: 0.6344\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6344 - accuracy: 0.6730\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=1, n_nodes=512;, score=0.673 total time=   4.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6942 - accuracy: 0.5033\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=32;, score=0.503 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6797 - accuracy: 0.5723\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6453 - accuracy: 0.6797\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=32;, score=0.680 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=32;, score=0.501 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6690 - accuracy: 0.6000\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6334 - accuracy: 0.6768\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=64;, score=0.677 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6746 - accuracy: 0.5835\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6503 - accuracy: 0.6605\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=64;, score=0.660 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6744 - accuracy: 0.5868\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6581 - accuracy: 0.6575\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=64;, score=0.657 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6689 - accuracy: 0.5857\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6489 - accuracy: 0.6662\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=128;, score=0.666 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6912 - accuracy: 0.5181\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5017\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=128;, score=0.502 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6761 - accuracy: 0.5744\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6746 - accuracy: 0.5875\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=128;, score=0.587 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6808 - accuracy: 0.5718\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6425 - accuracy: 0.6620\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=256;, score=0.662 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6922 - accuracy: 0.5152\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.5013\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=256;, score=0.501 total time=   5.0s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6964 - accuracy: 0.5004\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=256;, score=0.501 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6961 - accuracy: 0.5185\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4981\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=512;, score=0.498 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6965 - accuracy: 0.5141\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=512;, score=0.501 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6767 - accuracy: 0.5876\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6405 - accuracy: 0.6732\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=2, n_nodes=512;, score=0.673 total time=   5.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6939 - accuracy: 0.5064\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=32;, score=0.497 total time=   5.6s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6938 - accuracy: 0.4950\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=32;, score=0.501 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6925 - accuracy: 0.5097\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=32;, score=0.501 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6819 - accuracy: 0.5656\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6981 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=64;, score=0.503 total time=   5.4s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6930 - accuracy: 0.5143\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=64;, score=0.499 total time=   4.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6916 - accuracy: 0.5083\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=64;, score=0.501 total time=   5.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6766 - accuracy: 0.5836\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6457 - accuracy: 0.6661\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=128;, score=0.666 total time=   4.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6949 - accuracy: 0.5028\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=128;, score=0.499 total time=   5.6s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6853 - accuracy: 0.5452\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6415 - accuracy: 0.6782\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=128;, score=0.678 total time=   5.9s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6733 - accuracy: 0.5914\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6535 - accuracy: 0.6432\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=256;, score=0.643 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6932 - accuracy: 0.5204\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=256;, score=0.501 total time=   6.0s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6794 - accuracy: 0.5745\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6565 - accuracy: 0.6577\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=256;, score=0.658 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6981 - accuracy: 0.5098\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=512;, score=0.503 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6922 - accuracy: 0.5703\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6442 - accuracy: 0.6867\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=512;, score=0.687 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7091 - accuracy: 0.5069\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=3, n_nodes=512;, score=0.499 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6766 - accuracy: 0.5792\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6838 - accuracy: 0.5630\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=32;, score=0.563 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6935 - accuracy: 0.5082\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=32;, score=0.501 total time=   5.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6938 - accuracy: 0.5051\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=32;, score=0.501 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6937 - accuracy: 0.5064\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=64;, score=0.503 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6942 - accuracy: 0.5022\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=64;, score=0.499 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6942 - accuracy: 0.4990\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=64;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6923 - accuracy: 0.5106\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=128;, score=0.497 total time=   6.4s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6942 - accuracy: 0.5011\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4984\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=128;, score=0.498 total time=   7.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6824 - accuracy: 0.5669\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6532 - accuracy: 0.6577\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=128;, score=0.658 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6962 - accuracy: 0.5021\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6944 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=256;, score=0.497 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6961 - accuracy: 0.4980\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=256;, score=0.499 total time=   5.9s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6952 - accuracy: 0.5031\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=256;, score=0.501 total time=   5.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7156 - accuracy: 0.4957\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=512;, score=0.497 total time=   6.1s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7068 - accuracy: 0.5021\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=512;, score=0.499 total time=   5.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6989 - accuracy: 0.5015\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=4, n_nodes=512;, score=0.501 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6942 - accuracy: 0.4946\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=32;, score=0.497 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6938 - accuracy: 0.5073\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=32;, score=0.501 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6926 - accuracy: 0.5050\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=32;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6942 - accuracy: 0.5063\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=64;, score=0.497 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6939 - accuracy: 0.5050\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=64;, score=0.501 total time=   6.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6940 - accuracy: 0.5049\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=64;, score=0.499 total time=   5.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6945 - accuracy: 0.4927\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=128;, score=0.503 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6847 - accuracy: 0.5649\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6739 - accuracy: 0.6632\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=128;, score=0.663 total time=   6.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6944 - accuracy: 0.5024\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=128;, score=0.501 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6974 - accuracy: 0.5025\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=256;, score=0.503 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6965 - accuracy: 0.5047\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=256;, score=0.501 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6955 - accuracy: 0.4978\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=256;, score=0.499 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7295 - accuracy: 0.4983\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=512;, score=0.503 total time=   6.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7100 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=512;, score=0.501 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6994 - accuracy: 0.4978\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=5, n_nodes=512;, score=0.501 total time=   6.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6939 - accuracy: 0.5040\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=32;, score=0.503 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6935 - accuracy: 0.5045\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=32;, score=0.499 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6944 - accuracy: 0.4924\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=32;, score=0.501 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6944 - accuracy: 0.4986\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=64;, score=0.497 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6942 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=64;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6944 - accuracy: 0.4996\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=64;, score=0.499 total time=   7.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6948 - accuracy: 0.5059\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=128;, score=0.497 total time=   6.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6944 - accuracy: 0.5016\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=128;, score=0.499 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6951 - accuracy: 0.4995\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=128;, score=0.501 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6963 - accuracy: 0.5005\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=256;, score=0.497 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7014 - accuracy: 0.4930\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=256;, score=0.501 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6960 - accuracy: 0.4992\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=256;, score=0.501 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7121 - accuracy: 0.5045\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=512;, score=0.497 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7096 - accuracy: 0.4971\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=512;, score=0.499 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7313 - accuracy: 0.5015\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.01, n_layers=6, n_nodes=512;, score=0.501 total time=   7.6s\n",
      "708/708 [==============================] - 3s 3ms/step - loss: 0.7009 - accuracy: 0.4988\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6939 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=32;, score=0.497 total time=   3.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7060 - accuracy: 0.4978\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=32;, score=0.499 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7046 - accuracy: 0.5023\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6937 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=32;, score=0.499 total time=   4.3s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7057 - accuracy: 0.4964\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=64;, score=0.503 total time=   4.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7098 - accuracy: 0.4972\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6992 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=64;, score=0.501 total time=   4.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7118 - accuracy: 0.5027\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6942 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=64;, score=0.501 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7233 - accuracy: 0.4942\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=128;, score=0.497 total time=   4.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7209 - accuracy: 0.4953\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=128;, score=0.499 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7221 - accuracy: 0.5016\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=128;, score=0.499 total time=   4.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7463 - accuracy: 0.4997\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=256;, score=0.503 total time=   4.6s\n",
      "708/708 [==============================] - 4s 4ms/step - loss: 0.7547 - accuracy: 0.5025\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=256;, score=0.501 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7696 - accuracy: 0.4978\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=256;, score=0.499 total time=   4.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.8129 - accuracy: 0.5044\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=512;, score=0.503 total time=   3.6s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.8050 - accuracy: 0.5036\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6982 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=512;, score=0.501 total time=   4.4s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.8089 - accuracy: 0.5006\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6999 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=1, n_nodes=512;, score=0.499 total time=   4.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7019 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=32;, score=0.503 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6977 - accuracy: 0.4957\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=32;, score=0.501 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7106 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=32;, score=0.499 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7177 - accuracy: 0.4990\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=64;, score=0.503 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7093 - accuracy: 0.5031\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=64;, score=0.501 total time=   5.3s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7076 - accuracy: 0.5004\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6942 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=64;, score=0.499 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7740 - accuracy: 0.5076\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6954 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=128;, score=0.497 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7469 - accuracy: 0.4936\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=128;, score=0.499 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7623 - accuracy: 0.5023\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=128;, score=0.501 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.8657 - accuracy: 0.5037\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6971 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=256;, score=0.503 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.8761 - accuracy: 0.4952\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=256;, score=0.501 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.9229 - accuracy: 0.5019\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6947 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=256;, score=0.501 total time=   5.1s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.5867 - accuracy: 0.4989\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6990 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=512;, score=0.497 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 2.5416 - accuracy: 0.4958\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=512;, score=0.499 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 1.2000 - accuracy: 0.4997\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=2, n_nodes=512;, score=0.501 total time=   5.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7009 - accuracy: 0.5008\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6979 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=32;, score=0.497 total time=   5.9s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7103 - accuracy: 0.4968\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6949 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=32;, score=0.501 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6980 - accuracy: 0.4983\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6950 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=32;, score=0.501 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7167 - accuracy: 0.4979\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6976 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=64;, score=0.497 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7173 - accuracy: 0.5000\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6951 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=64;, score=0.501 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7237 - accuracy: 0.4992\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6978 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=64;, score=0.499 total time=   5.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.8371 - accuracy: 0.4981\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6946 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=128;, score=0.503 total time=   4.9s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.8612 - accuracy: 0.5013\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=128;, score=0.501 total time=   4.4s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.8701 - accuracy: 0.4960\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=128;, score=0.499 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 1.9882 - accuracy: 0.5025\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6979 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=256;, score=0.497 total time=   6.5s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 1.8999 - accuracy: 0.4981\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=256;, score=0.501 total time=   4.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 2.0490 - accuracy: 0.5004\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=256;, score=0.501 total time=   5.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 8.7402 - accuracy: 0.4981\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6953 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=512;, score=0.503 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 5.1393 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6964 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=512;, score=0.501 total time=   5.6s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 8.6487 - accuracy: 0.4936\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6953 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=3, n_nodes=512;, score=0.501 total time=   4.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7053 - accuracy: 0.5044\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=32;, score=0.503 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7106 - accuracy: 0.5017\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6991 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=32;, score=0.499 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7000 - accuracy: 0.4986\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6974 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=32;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7211 - accuracy: 0.4937\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=64;, score=0.497 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7425 - accuracy: 0.4976\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7001 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=64;, score=0.501 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7452 - accuracy: 0.5014\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6990 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=64;, score=0.501 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 1.4772 - accuracy: 0.4944\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7016 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=128;, score=0.497 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7911 - accuracy: 0.4924\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6989 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=128;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 1.2941 - accuracy: 0.4986\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7004 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=128;, score=0.501 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 4.8499 - accuracy: 0.4930\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6944 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=256;, score=0.497 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 2.8019 - accuracy: 0.5046\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.7052 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=256;, score=0.499 total time=   6.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 3.6370 - accuracy: 0.5002\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=256;, score=0.499 total time=   5.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 74.4810 - accuracy: 0.5006\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=512;, score=0.503 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 14.7353 - accuracy: 0.5008\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=512;, score=0.499 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 65.4009 - accuracy: 0.4985\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=4, n_nodes=512;, score=0.499 total time=   6.5s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7821 - accuracy: 0.5007\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=32;, score=0.503 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7170 - accuracy: 0.4986\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6955 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=32;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6986 - accuracy: 0.5002\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6967 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=32;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7390 - accuracy: 0.5075\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=64;, score=0.497 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7486 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=64;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7413 - accuracy: 0.4981\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=64;, score=0.499 total time=   5.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.8748 - accuracy: 0.4990\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6985 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=128;, score=0.503 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 1.2087 - accuracy: 0.4991\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6954 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=128;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 1.6734 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=128;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 6.5168 - accuracy: 0.5001\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=256;, score=0.497 total time=   6.7s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 25.3813 - accuracy: 0.4956\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=256;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 14.0988 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=256;, score=0.501 total time=   6.6s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 1632.4996 - accuracy: 0.4973\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 129.0706 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=512;, score=0.503 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 336.2430 - accuracy: 0.4963\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=512;, score=0.501 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 833.1103 - accuracy: 0.4930\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6944 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=5, n_nodes=512;, score=0.499 total time=   6.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7178 - accuracy: 0.5080\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=32;, score=0.503 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7002 - accuracy: 0.4953\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6952 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=32;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7131 - accuracy: 0.4937\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=32;, score=0.499 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7320 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6971 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=64;, score=0.503 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7257 - accuracy: 0.5022\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6950 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=64;, score=0.499 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7705 - accuracy: 0.5048\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=64;, score=0.501 total time=   7.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 6.1715 - accuracy: 0.4933\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=128;, score=0.503 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 2.7893 - accuracy: 0.4928\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6962 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=128;, score=0.499 total time=   6.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 23.9178 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6950 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=128;, score=0.501 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 17.1264 - accuracy: 0.4974\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7136 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=256;, score=0.497 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 33.5297 - accuracy: 0.5034\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=256;, score=0.501 total time=   7.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 56.5537 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=256;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 8094.6304 - accuracy: 0.4993\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=512;, score=0.503 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 6891.3940 - accuracy: 0.4955\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=512;, score=0.499 total time=   7.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 3299.2927 - accuracy: 0.4984\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.3, lr=0.1, n_layers=6, n_nodes=512;, score=0.501 total time=   7.4s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7171 - accuracy: 0.5025\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6858 - accuracy: 0.5848\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=32;, score=0.585 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7008 - accuracy: 0.5416\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6789 - accuracy: 0.6468\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=32;, score=0.647 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7244 - accuracy: 0.5216\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6773 - accuracy: 0.6394\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=32;, score=0.639 total time=   4.4s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7001 - accuracy: 0.5408\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6735 - accuracy: 0.6358\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=64;, score=0.636 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6903 - accuracy: 0.5538\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6700 - accuracy: 0.6277\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=64;, score=0.628 total time=   4.3s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.7119 - accuracy: 0.5293\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6777 - accuracy: 0.6319\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=64;, score=0.632 total time=   4.5s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6814 - accuracy: 0.5769\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6593 - accuracy: 0.6548\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=128;, score=0.655 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6952 - accuracy: 0.5472\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6632 - accuracy: 0.6642\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=128;, score=0.664 total time=   4.2s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6802 - accuracy: 0.5816\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6609 - accuracy: 0.6644\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=128;, score=0.664 total time=   4.6s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6806 - accuracy: 0.5779\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6530 - accuracy: 0.6665\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=256;, score=0.666 total time=   4.4s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6837 - accuracy: 0.5674\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6528 - accuracy: 0.6769\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=256;, score=0.677 total time=   4.4s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6720 - accuracy: 0.5988\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6488 - accuracy: 0.6642\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=256;, score=0.664 total time=   4.4s\n",
      "708/708 [==============================] - 3s 5ms/step - loss: 0.6687 - accuracy: 0.6012\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6451 - accuracy: 0.6659\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=512;, score=0.666 total time=   4.5s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6708 - accuracy: 0.5997\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6438 - accuracy: 0.6754\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=512;, score=0.675 total time=   4.3s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6696 - accuracy: 0.6054\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6442 - accuracy: 0.6783\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=1, n_nodes=512;, score=0.678 total time=   4.3s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7169 - accuracy: 0.5154\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6841 - accuracy: 0.5899\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=32;, score=0.590 total time=   5.2s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.7278 - accuracy: 0.4960\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5725\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=32;, score=0.573 total time=   4.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7312 - accuracy: 0.5064\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6871 - accuracy: 0.5515\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=32;, score=0.552 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7067 - accuracy: 0.5168\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6811 - accuracy: 0.5888\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=64;, score=0.589 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7094 - accuracy: 0.5025\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6841 - accuracy: 0.6193\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=64;, score=0.619 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7058 - accuracy: 0.5333\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6754 - accuracy: 0.6478\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=64;, score=0.648 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6841 - accuracy: 0.5762\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6522 - accuracy: 0.6583\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=128;, score=0.658 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6872 - accuracy: 0.5601\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6565 - accuracy: 0.6774\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=128;, score=0.677 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6834 - accuracy: 0.5675\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6517 - accuracy: 0.6694\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=128;, score=0.669 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6759 - accuracy: 0.5868\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6400 - accuracy: 0.6623\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=256;, score=0.662 total time=   4.7s\n",
      "708/708 [==============================] - 3s 4ms/step - loss: 0.6740 - accuracy: 0.5888\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6796\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=256;, score=0.680 total time=   4.3s\n",
      "708/708 [==============================] - 5s 5ms/step - loss: 0.6761 - accuracy: 0.5850\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.6724\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=256;, score=0.672 total time=   5.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6536 - accuracy: 0.6292\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6309 - accuracy: 0.6576\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=512;, score=0.658 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6572 - accuracy: 0.6187\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6211 - accuracy: 0.6714\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=512;, score=0.671 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6559 - accuracy: 0.6227\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6243 - accuracy: 0.6759\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=2, n_nodes=512;, score=0.676 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7384 - accuracy: 0.5080\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5033\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=32;, score=0.503 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7058 - accuracy: 0.5135\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6882 - accuracy: 0.5898\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=32;, score=0.590 total time=   5.2s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7170 - accuracy: 0.5007\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6911 - accuracy: 0.5604\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=32;, score=0.560 total time=   5.6s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6997 - accuracy: 0.5209\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6778 - accuracy: 0.6472\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=64;, score=0.647 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7020 - accuracy: 0.5093\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6854 - accuracy: 0.6476\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=64;, score=0.648 total time=   5.9s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7026 - accuracy: 0.5136\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6872 - accuracy: 0.5111\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=64;, score=0.511 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6948 - accuracy: 0.5334\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6687 - accuracy: 0.6419\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=128;, score=0.642 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6950 - accuracy: 0.5331\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6731 - accuracy: 0.6364\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=128;, score=0.636 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6933 - accuracy: 0.5310\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6736 - accuracy: 0.6239\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=128;, score=0.624 total time=   5.6s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6846 - accuracy: 0.5599\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6417 - accuracy: 0.6643\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=256;, score=0.664 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6868 - accuracy: 0.5555\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6392 - accuracy: 0.6800\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=256;, score=0.680 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6808 - accuracy: 0.5692\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.6714\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=256;, score=0.671 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6598 - accuracy: 0.6111\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6693\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=512;, score=0.669 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6628 - accuracy: 0.6062\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.6764\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=512;, score=0.676 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6621 - accuracy: 0.6078\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6246 - accuracy: 0.6711\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=3, n_nodes=512;, score=0.671 total time=   6.3s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7025 - accuracy: 0.5005\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.5541\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=32;, score=0.554 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7021 - accuracy: 0.5024\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.5143\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=32;, score=0.514 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7056 - accuracy: 0.5056\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5939\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=32;, score=0.594 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7055 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.5459\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=64;, score=0.546 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7066 - accuracy: 0.5060\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.5430\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=64;, score=0.543 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7046 - accuracy: 0.5100\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.5379\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=64;, score=0.538 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7008 - accuracy: 0.5142\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6854 - accuracy: 0.5979\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=128;, score=0.598 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6991 - accuracy: 0.5177\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6828 - accuracy: 0.6244\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=128;, score=0.624 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7000 - accuracy: 0.5100\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6885 - accuracy: 0.5909\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=128;, score=0.591 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6828 - accuracy: 0.5636\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6391 - accuracy: 0.6695\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=256;, score=0.669 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6863 - accuracy: 0.5542\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6375 - accuracy: 0.6750\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=256;, score=0.675 total time=   7.1s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6924 - accuracy: 0.5353\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6605 - accuracy: 0.6694\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=256;, score=0.669 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6687 - accuracy: 0.5893\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6283 - accuracy: 0.6686\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=512;, score=0.669 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6711 - accuracy: 0.5844\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6194 - accuracy: 0.6737\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=512;, score=0.674 total time=   6.9s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6741 - accuracy: 0.5806\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6335 - accuracy: 0.6529\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=4, n_nodes=512;, score=0.653 total time=   6.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7040 - accuracy: 0.5089\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6928 - accuracy: 0.5307\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=32;, score=0.531 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7013 - accuracy: 0.4987\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=32;, score=0.501 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7021 - accuracy: 0.5032\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.5021\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=32;, score=0.502 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7028 - accuracy: 0.4994\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.5334\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=64;, score=0.533 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7042 - accuracy: 0.5040\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6922 - accuracy: 0.5013\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=64;, score=0.501 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7005 - accuracy: 0.5054\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6913 - accuracy: 0.6272\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=64;, score=0.627 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6987 - accuracy: 0.5037\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.5454\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=128;, score=0.545 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6977 - accuracy: 0.5093\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6898 - accuracy: 0.5783\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=128;, score=0.578 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6984 - accuracy: 0.5092\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6891 - accuracy: 0.6564\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=128;, score=0.656 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6955 - accuracy: 0.5176\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6831 - accuracy: 0.5518\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=256;, score=0.552 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6958 - accuracy: 0.5175\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6823 - accuracy: 0.5662\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=256;, score=0.566 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6921 - accuracy: 0.5333\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6638 - accuracy: 0.6043\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=256;, score=0.604 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6805 - accuracy: 0.5637\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6340 - accuracy: 0.6732\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=512;, score=0.673 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6822 - accuracy: 0.5551\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6225 - accuracy: 0.6773\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=512;, score=0.677 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6831 - accuracy: 0.5509\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6276 - accuracy: 0.6682\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=5, n_nodes=512;, score=0.668 total time=   7.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7006 - accuracy: 0.5027\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=32;, score=0.503 total time=   8.1s\n",
      "708/708 [==============================] - 8s 10ms/step - loss: 0.7035 - accuracy: 0.4988\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5072\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=32;, score=0.507 total time=   9.6s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7048 - accuracy: 0.4966\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.4857\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=32;, score=0.486 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6979 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=64;, score=0.497 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6971 - accuracy: 0.5032\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6928 - accuracy: 0.5181\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=64;, score=0.518 total time=   8.6s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6977 - accuracy: 0.5102\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6924 - accuracy: 0.5172\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=64;, score=0.517 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6985 - accuracy: 0.4976\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.5163\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=128;, score=0.516 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6992 - accuracy: 0.5050\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6924 - accuracy: 0.5311\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=128;, score=0.531 total time=   8.4s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6988 - accuracy: 0.5032\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6915 - accuracy: 0.6178\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=128;, score=0.618 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6959 - accuracy: 0.5091\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6889 - accuracy: 0.6381\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=256;, score=0.638 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6966 - accuracy: 0.5050\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6924 - accuracy: 0.6194\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=256;, score=0.619 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6960 - accuracy: 0.5093\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6904 - accuracy: 0.6138\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=256;, score=0.614 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6877 - accuracy: 0.5358\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6448 - accuracy: 0.6373\n",
      "[CV 1/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=512;, score=0.637 total time=   7.9s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6897 - accuracy: 0.5290\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.6548\n",
      "[CV 2/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=512;, score=0.655 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6900 - accuracy: 0.5344\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6373 - accuracy: 0.6715\n",
      "[CV 3/3] END dropout=0.4, lr=0.0001, n_layers=6, n_nodes=512;, score=0.671 total time=   7.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6700 - accuracy: 0.5969\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6397 - accuracy: 0.6627\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=32;, score=0.663 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6731 - accuracy: 0.5977\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6389 - accuracy: 0.6572\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=32;, score=0.657 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6622 - accuracy: 0.6197\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6333 - accuracy: 0.6680\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=32;, score=0.668 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6558 - accuracy: 0.6261\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6707\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=64;, score=0.671 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6569 - accuracy: 0.6240\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6235 - accuracy: 0.6705\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=64;, score=0.670 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6605 - accuracy: 0.6155\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.6717\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=64;, score=0.672 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6460 - accuracy: 0.6413\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6250 - accuracy: 0.6702\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=128;, score=0.670 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6542 - accuracy: 0.6250\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6201 - accuracy: 0.6812\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=128;, score=0.681 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6501 - accuracy: 0.6320\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6238 - accuracy: 0.6742\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=128;, score=0.674 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6441 - accuracy: 0.6447\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6287 - accuracy: 0.6628\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=256;, score=0.663 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6475 - accuracy: 0.6385\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6269 - accuracy: 0.6623\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=256;, score=0.662 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6468 - accuracy: 0.6388\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6250 - accuracy: 0.6767\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=256;, score=0.677 total time=   4.9s\n",
      "708/708 [==============================] - 5s 5ms/step - loss: 0.6435 - accuracy: 0.6422\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6279 - accuracy: 0.6705\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=512;, score=0.670 total time=   5.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6465 - accuracy: 0.6353\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6158 - accuracy: 0.6790\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=512;, score=0.679 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6448 - accuracy: 0.6388\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.6593\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=1, n_nodes=512;, score=0.659 total time=   4.9s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6676 - accuracy: 0.6000\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6353 - accuracy: 0.6692\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=32;, score=0.669 total time=   5.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6668 - accuracy: 0.6053\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6415 - accuracy: 0.6395\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=32;, score=0.639 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6624 - accuracy: 0.6152\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6463 - accuracy: 0.6261\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=32;, score=0.626 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6558 - accuracy: 0.6218\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6355 - accuracy: 0.6577\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=64;, score=0.658 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6615 - accuracy: 0.6186\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6307 - accuracy: 0.6675\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=64;, score=0.668 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6564 - accuracy: 0.6184\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6231 - accuracy: 0.6787\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=64;, score=0.679 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6489 - accuracy: 0.6353\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6230 - accuracy: 0.6728\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=128;, score=0.673 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6490 - accuracy: 0.6383\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6153 - accuracy: 0.6807\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=128;, score=0.681 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6516 - accuracy: 0.6301\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6326 - accuracy: 0.6582\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=128;, score=0.658 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6447 - accuracy: 0.6385\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6684\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=256;, score=0.668 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6497 - accuracy: 0.6322\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6127 - accuracy: 0.6822\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=256;, score=0.682 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6448 - accuracy: 0.6392\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6363 - accuracy: 0.6498\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=256;, score=0.650 total time=   5.5s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6434 - accuracy: 0.6421\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6525 - accuracy: 0.6127\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=512;, score=0.613 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6463 - accuracy: 0.6389\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6135 - accuracy: 0.6832\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=512;, score=0.683 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6454 - accuracy: 0.6377\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6187 - accuracy: 0.6744\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=2, n_nodes=512;, score=0.674 total time=   5.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6739 - accuracy: 0.5800\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6383 - accuracy: 0.6653\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=32;, score=0.665 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6787 - accuracy: 0.5776\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6377 - accuracy: 0.6691\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=32;, score=0.669 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6823 - accuracy: 0.5558\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6388 - accuracy: 0.6744\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=32;, score=0.674 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6621 - accuracy: 0.6127\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6317 - accuracy: 0.6620\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=64;, score=0.662 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6722 - accuracy: 0.5853\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6299 - accuracy: 0.6628\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=64;, score=0.663 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6625 - accuracy: 0.6160\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6743\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=64;, score=0.674 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6556 - accuracy: 0.6218\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6517\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=128;, score=0.652 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6583 - accuracy: 0.6163\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6198 - accuracy: 0.6744\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=128;, score=0.674 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6568 - accuracy: 0.6207\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.6772\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=128;, score=0.677 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6490 - accuracy: 0.6300\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6334 - accuracy: 0.6623\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=256;, score=0.662 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6549 - accuracy: 0.6234\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6133 - accuracy: 0.6827\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=256;, score=0.683 total time=   6.3s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6521 - accuracy: 0.6237\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6222 - accuracy: 0.6695\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=256;, score=0.669 total time=   7.1s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6478 - accuracy: 0.6365\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.6719\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=512;, score=0.672 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6510 - accuracy: 0.6321\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6174 - accuracy: 0.6778\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=512;, score=0.678 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6485 - accuracy: 0.6346\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6261 - accuracy: 0.6732\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=3, n_nodes=512;, score=0.673 total time=   6.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6811 - accuracy: 0.5729\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6349 - accuracy: 0.6634\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=32;, score=0.663 total time=   7.2s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6863 - accuracy: 0.5492\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6671 - accuracy: 0.6165\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=32;, score=0.616 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6875 - accuracy: 0.5396\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6666 - accuracy: 0.6591\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=32;, score=0.659 total time=   7.1s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6757 - accuracy: 0.5743\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6476 - accuracy: 0.6267\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=64;, score=0.627 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6812 - accuracy: 0.5611\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6239 - accuracy: 0.6819\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=64;, score=0.682 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6669 - accuracy: 0.5999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6299 - accuracy: 0.6650\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=64;, score=0.665 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6595 - accuracy: 0.6133\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6348 - accuracy: 0.6625\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=128;, score=0.663 total time=   7.1s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6657 - accuracy: 0.6055\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6144 - accuracy: 0.6826\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=128;, score=0.683 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6663 - accuracy: 0.6011\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6368 - accuracy: 0.6612\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=128;, score=0.661 total time=   7.1s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6551 - accuracy: 0.6206\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6269 - accuracy: 0.6710\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=256;, score=0.671 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6588 - accuracy: 0.6175\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6177 - accuracy: 0.6818\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=256;, score=0.682 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6542 - accuracy: 0.6231\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6294 - accuracy: 0.6667\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=256;, score=0.667 total time=   7.1s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6576 - accuracy: 0.6191\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.6723\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=512;, score=0.672 total time=   6.8s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6528 - accuracy: 0.6240\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.6819\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=512;, score=0.682 total time=   6.8s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6497 - accuracy: 0.6311\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6200 - accuracy: 0.6751\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=4, n_nodes=512;, score=0.675 total time=   6.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.5229\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6770 - accuracy: 0.6388\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=32;, score=0.639 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6856 - accuracy: 0.5545\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6555 - accuracy: 0.6591\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=32;, score=0.659 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6911 - accuracy: 0.5285\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.5013\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=32;, score=0.501 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6791 - accuracy: 0.5677\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6343 - accuracy: 0.6740\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=64;, score=0.674 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6851 - accuracy: 0.5459\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6270 - accuracy: 0.6818\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=64;, score=0.682 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6767 - accuracy: 0.5764\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6535 - accuracy: 0.6223\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=64;, score=0.622 total time=   7.7s\n",
      "708/708 [==============================] - 7s 8ms/step - loss: 0.6659 - accuracy: 0.5954\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6456 - accuracy: 0.6181\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=128;, score=0.618 total time=   8.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6744 - accuracy: 0.5757\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6210 - accuracy: 0.6751\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=128;, score=0.675 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6727 - accuracy: 0.5792\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6336 - accuracy: 0.6639\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=128;, score=0.664 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6602 - accuracy: 0.6114\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6289 - accuracy: 0.6602\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=256;, score=0.660 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6643 - accuracy: 0.6046\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6366 - accuracy: 0.6815\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=256;, score=0.682 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6580 - accuracy: 0.6134\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6635\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=256;, score=0.663 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6557 - accuracy: 0.6230\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6244 - accuracy: 0.6661\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=512;, score=0.666 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6608 - accuracy: 0.6157\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6243 - accuracy: 0.6825\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=512;, score=0.682 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6559 - accuracy: 0.6207\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6535 - accuracy: 0.6054\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=5, n_nodes=512;, score=0.605 total time=   7.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6917 - accuracy: 0.5203\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6797 - accuracy: 0.6054\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=32;, score=0.605 total time=   8.4s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6930 - accuracy: 0.5157\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6858 - accuracy: 0.6352\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=32;, score=0.635 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6895 - accuracy: 0.5411\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.5904\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=32;, score=0.590 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6895 - accuracy: 0.5387\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6638 - accuracy: 0.5840\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=64;, score=0.584 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6935 - accuracy: 0.5115\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6809 - accuracy: 0.6716\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=64;, score=0.672 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6944 - accuracy: 0.5031\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.5076\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=64;, score=0.508 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6845 - accuracy: 0.5474\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6393 - accuracy: 0.6587\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=128;, score=0.659 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6766 - accuracy: 0.5731\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6255 - accuracy: 0.6714\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=128;, score=0.671 total time=   8.4s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6874 - accuracy: 0.5404\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6321 - accuracy: 0.6791\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=128;, score=0.679 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6674 - accuracy: 0.5922\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6324 - accuracy: 0.6709\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=256;, score=0.671 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6739 - accuracy: 0.5794\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6153 - accuracy: 0.6829\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=256;, score=0.683 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6684 - accuracy: 0.5942\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6394 - accuracy: 0.6791\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=256;, score=0.679 total time=   8.4s\n",
      "708/708 [==============================] - 8s 9ms/step - loss: 0.6637 - accuracy: 0.6043\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6291 - accuracy: 0.6629\n",
      "[CV 1/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=512;, score=0.663 total time=   9.0s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6649 - accuracy: 0.6057\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6428 - accuracy: 0.6650\n",
      "[CV 2/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=512;, score=0.665 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6610 - accuracy: 0.6145\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6339 - accuracy: 0.6542\n",
      "[CV 3/3] END dropout=0.4, lr=0.001, n_layers=6, n_nodes=512;, score=0.654 total time=   8.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6723 - accuracy: 0.5761\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6450 - accuracy: 0.6704\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=32;, score=0.670 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6770 - accuracy: 0.5668\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6463 - accuracy: 0.6833\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=32;, score=0.683 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6916 - accuracy: 0.5116\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=32;, score=0.499 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6663 - accuracy: 0.5800\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6353 - accuracy: 0.6637\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=64;, score=0.664 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6699 - accuracy: 0.5820\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6313 - accuracy: 0.6787\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=64;, score=0.679 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6688 - accuracy: 0.5976\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6513 - accuracy: 0.6464\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=64;, score=0.646 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6635 - accuracy: 0.6060\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6363 - accuracy: 0.6712\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=128;, score=0.671 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6747 - accuracy: 0.5809\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6690 - accuracy: 0.6102\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=128;, score=0.610 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6675 - accuracy: 0.5867\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6360 - accuracy: 0.6727\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=128;, score=0.673 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6527 - accuracy: 0.6261\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6677\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=256;, score=0.668 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6934 - accuracy: 0.5134\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=256;, score=0.499 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6622 - accuracy: 0.6087\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6402 - accuracy: 0.6771\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=256;, score=0.677 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6628 - accuracy: 0.6156\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6580 - accuracy: 0.6427\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=512;, score=0.643 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6696 - accuracy: 0.5985\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6389 - accuracy: 0.6806\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=512;, score=0.681 total time=   4.8s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.6636 - accuracy: 0.6086\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6417 - accuracy: 0.6720\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=1, n_nodes=512;, score=0.672 total time=   4.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6937 - accuracy: 0.5016\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=32;, score=0.497 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6927 - accuracy: 0.5145\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=32;, score=0.501 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6941 - accuracy: 0.5095\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.5012\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=32;, score=0.501 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6944 - accuracy: 0.5043\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=64;, score=0.497 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6802 - accuracy: 0.5649\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6563 - accuracy: 0.6727\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=64;, score=0.673 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6941 - accuracy: 0.5110\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=64;, score=0.499 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6773 - accuracy: 0.5784\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6528 - accuracy: 0.6352\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=128;, score=0.635 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6948 - accuracy: 0.4980\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=128;, score=0.499 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6761 - accuracy: 0.5749\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6436 - accuracy: 0.6666\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=128;, score=0.667 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6775 - accuracy: 0.5753\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6517 - accuracy: 0.6563\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=256;, score=0.656 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6893 - accuracy: 0.5271\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=256;, score=0.499 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6952 - accuracy: 0.5134\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4987\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=256;, score=0.499 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6812 - accuracy: 0.5700\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6564 - accuracy: 0.6732\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=512;, score=0.673 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6995 - accuracy: 0.5056\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=512;, score=0.499 total time=   5.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6953 - accuracy: 0.5185\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7377 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=2, n_nodes=512;, score=0.501 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6867 - accuracy: 0.5448\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6584 - accuracy: 0.6668\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=32;, score=0.667 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6797 - accuracy: 0.5675\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6614 - accuracy: 0.6553\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=32;, score=0.655 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6944 - accuracy: 0.5031\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=32;, score=0.501 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6943 - accuracy: 0.5099\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=64;, score=0.497 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6943 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=64;, score=0.499 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6946 - accuracy: 0.4962\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=64;, score=0.499 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6923 - accuracy: 0.5193\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=128;, score=0.497 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6954 - accuracy: 0.5040\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=128;, score=0.501 total time=   6.4s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6955 - accuracy: 0.5011\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=128;, score=0.499 total time=   6.0s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6837 - accuracy: 0.5746\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6512 - accuracy: 0.6673\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=256;, score=0.667 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6952 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6948 - accuracy: 0.4989\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=256;, score=0.499 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6985 - accuracy: 0.4994\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=256;, score=0.499 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7053 - accuracy: 0.5007\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=512;, score=0.497 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7026 - accuracy: 0.4979\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=512;, score=0.499 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7002 - accuracy: 0.5116\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6958 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=3, n_nodes=512;, score=0.499 total time=   6.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6940 - accuracy: 0.5012\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=32;, score=0.503 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6939 - accuracy: 0.4950\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=32;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6939 - accuracy: 0.5008\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=32;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6921 - accuracy: 0.5255\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=64;, score=0.503 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6943 - accuracy: 0.5054\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=64;, score=0.501 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6949 - accuracy: 0.4947\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=64;, score=0.499 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6952 - accuracy: 0.4992\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=128;, score=0.497 total time=   7.2s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6956 - accuracy: 0.5024\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=128;, score=0.499 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6950 - accuracy: 0.5067\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=128;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6958 - accuracy: 0.5060\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=256;, score=0.503 total time=   6.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6956 - accuracy: 0.4984\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=256;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.6982 - accuracy: 0.5028\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=256;, score=0.501 total time=   7.5s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7035 - accuracy: 0.5070\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=512;, score=0.503 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7039 - accuracy: 0.5028\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4782\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=512;, score=0.478 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7178 - accuracy: 0.5026\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.4989\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=4, n_nodes=512;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6937 - accuracy: 0.5058\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=32;, score=0.503 total time=   7.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6940 - accuracy: 0.5001\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6938 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=32;, score=0.499 total time=   7.8s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6939 - accuracy: 0.5005\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=32;, score=0.499 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6944 - accuracy: 0.5007\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=64;, score=0.497 total time=   7.8s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6944 - accuracy: 0.5015\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=64;, score=0.499 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6949 - accuracy: 0.4981\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=64;, score=0.501 total time=   7.8s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6949 - accuracy: 0.4976\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=128;, score=0.503 total time=   7.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6954 - accuracy: 0.4937\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=128;, score=0.499 total time=   7.8s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.6951 - accuracy: 0.4985\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=128;, score=0.501 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6970 - accuracy: 0.5001\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6939 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=256;, score=0.503 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6969 - accuracy: 0.5018\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=256;, score=0.501 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6956 - accuracy: 0.4963\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=256;, score=0.499 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7017 - accuracy: 0.4958\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6948 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=512;, score=0.503 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7056 - accuracy: 0.4992\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=512;, score=0.501 total time=   7.6s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7120 - accuracy: 0.4996\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7014 - accuracy: 0.5011\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=5, n_nodes=512;, score=0.501 total time=   7.6s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6944 - accuracy: 0.5009\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=32;, score=0.497 total time=   8.4s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6940 - accuracy: 0.5065\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=32;, score=0.499 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6939 - accuracy: 0.4989\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=32;, score=0.499 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6945 - accuracy: 0.5017\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=64;, score=0.503 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6950 - accuracy: 0.5013\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=64;, score=0.501 total time=   9.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6945 - accuracy: 0.5000\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=64;, score=0.499 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6954 - accuracy: 0.4996\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6952 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=128;, score=0.503 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6951 - accuracy: 0.5000\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=128;, score=0.499 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6954 - accuracy: 0.5007\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.5011\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=128;, score=0.501 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6965 - accuracy: 0.4973\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=256;, score=0.503 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6968 - accuracy: 0.4998\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=256;, score=0.499 total time=   8.4s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.6969 - accuracy: 0.5000\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=256;, score=0.501 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7261 - accuracy: 0.4917\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6937 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=512;, score=0.497 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7171 - accuracy: 0.4973\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=512;, score=0.499 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7029 - accuracy: 0.4986\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.01, n_layers=6, n_nodes=512;, score=0.501 total time=   8.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7009 - accuracy: 0.4988\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6966 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=32;, score=0.497 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7067 - accuracy: 0.5037\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6975 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=32;, score=0.501 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7019 - accuracy: 0.4962\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=32;, score=0.501 total time=   5.3s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7144 - accuracy: 0.4994\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=64;, score=0.497 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7069 - accuracy: 0.4959\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6950 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=64;, score=0.501 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7078 - accuracy: 0.5009\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=64;, score=0.501 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7242 - accuracy: 0.5009\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=128;, score=0.497 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7234 - accuracy: 0.5064\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=128;, score=0.501 total time=   4.9s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7235 - accuracy: 0.5004\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=128;, score=0.499 total time=   5.1s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7892 - accuracy: 0.4949\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=256;, score=0.503 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7655 - accuracy: 0.4968\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6983 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=256;, score=0.499 total time=   5.2s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7561 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=256;, score=0.501 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7983 - accuracy: 0.4987\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=512;, score=0.497 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.7972 - accuracy: 0.4953\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=512;, score=0.501 total time=   5.0s\n",
      "708/708 [==============================] - 4s 5ms/step - loss: 0.8255 - accuracy: 0.4981\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6952 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=1, n_nodes=512;, score=0.499 total time=   5.2s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7019 - accuracy: 0.5025\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=32;, score=0.503 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.6994 - accuracy: 0.4980\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6980 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=32;, score=0.499 total time=   6.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.6973 - accuracy: 0.4993\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6956 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=32;, score=0.499 total time=   5.6s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7118 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=64;, score=0.497 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7098 - accuracy: 0.4948\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6951 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=64;, score=0.501 total time=   5.7s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7150 - accuracy: 0.4925\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=64;, score=0.501 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7845 - accuracy: 0.5056\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6985 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=128;, score=0.497 total time=   5.8s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.7591 - accuracy: 0.4980\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=128;, score=0.499 total time=   5.8s\n",
      "708/708 [==============================] - 5s 6ms/step - loss: 0.7999 - accuracy: 0.5066\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6994 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=128;, score=0.499 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.0337 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7016 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=256;, score=0.503 total time=   5.5s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.2242 - accuracy: 0.4991\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=256;, score=0.499 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 0.8038 - accuracy: 0.5038\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=256;, score=0.499 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.5286 - accuracy: 0.4966\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6959 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=512;, score=0.497 total time=   5.6s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.1312 - accuracy: 0.5006\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=512;, score=0.501 total time=   5.7s\n",
      "708/708 [==============================] - 4s 6ms/step - loss: 1.3990 - accuracy: 0.5014\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6972 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=2, n_nodes=512;, score=0.501 total time=   5.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7014 - accuracy: 0.4984\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6979 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=32;, score=0.503 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.6986 - accuracy: 0.4997\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=32;, score=0.499 total time=   6.7s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7159 - accuracy: 0.4997\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6958 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=32;, score=0.499 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7190 - accuracy: 0.5009\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=64;, score=0.497 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7096 - accuracy: 0.4991\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=64;, score=0.499 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7225 - accuracy: 0.5031\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6955 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=64;, score=0.501 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.8292 - accuracy: 0.4987\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=128;, score=0.503 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.7866 - accuracy: 0.4999\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=128;, score=0.501 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 0.8047 - accuracy: 0.4962\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6966 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=128;, score=0.499 total time=   6.5s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 1.4294 - accuracy: 0.4967\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=256;, score=0.497 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 2.1871 - accuracy: 0.5010\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6947 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=256;, score=0.499 total time=   6.2s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 1.0545 - accuracy: 0.4987\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=256;, score=0.501 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 7.7619 - accuracy: 0.5009\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6964 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=512;, score=0.497 total time=   6.3s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 6.7179 - accuracy: 0.5004\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6952 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=512;, score=0.499 total time=   6.4s\n",
      "708/708 [==============================] - 5s 7ms/step - loss: 5.4475 - accuracy: 0.4986\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=3, n_nodes=512;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6987 - accuracy: 0.4956\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=32;, score=0.497 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6980 - accuracy: 0.4961\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6946 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=32;, score=0.499 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7008 - accuracy: 0.4991\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6993 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=32;, score=0.501 total time=   7.3s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7384 - accuracy: 0.4954\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=64;, score=0.497 total time=   7.2s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7545 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=64;, score=0.499 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7430 - accuracy: 0.4963\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6950 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=64;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.9946 - accuracy: 0.5039\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6953 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=128;, score=0.497 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.9140 - accuracy: 0.4966\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=128;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 0.7881 - accuracy: 0.5014\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6957 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=128;, score=0.499 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 6.0020 - accuracy: 0.5028\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=256;, score=0.503 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 6.3273 - accuracy: 0.5029\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6947 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=256;, score=0.501 total time=   7.1s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 2.9813 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6977 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=256;, score=0.501 total time=   7.2s\n",
      "708/708 [==============================] - 6s 7ms/step - loss: 48.7778 - accuracy: 0.4987\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.7003 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=512;, score=0.497 total time=   6.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 201.3233 - accuracy: 0.5002\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6948 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=512;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 36.4486 - accuracy: 0.5008\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6968 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=4, n_nodes=512;, score=0.501 total time=   7.0s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7034 - accuracy: 0.5036\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=32;, score=0.497 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6982 - accuracy: 0.4975\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6937 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=32;, score=0.499 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6987 - accuracy: 0.4985\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=32;, score=0.501 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7389 - accuracy: 0.4995\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6971 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=64;, score=0.503 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.7337 - accuracy: 0.4993\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.7041 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=64;, score=0.499 total time=   7.7s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 0.7311 - accuracy: 0.5023\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6942 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=64;, score=0.499 total time=   7.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 1.4609 - accuracy: 0.5031\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6937 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=128;, score=0.503 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 1.0855 - accuracy: 0.5030\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6960 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=128;, score=0.499 total time=   7.8s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 1.3311 - accuracy: 0.5016\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6937 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=128;, score=0.501 total time=   7.8s\n",
      "708/708 [==============================] - 7s 8ms/step - loss: 7.0379 - accuracy: 0.5043\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=256;, score=0.497 total time=   8.4s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 3.8801 - accuracy: 0.5009\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6948 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=256;, score=0.499 total time=   7.6s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 13.4692 - accuracy: 0.5056\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=256;, score=0.501 total time=   7.9s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 90.6604 - accuracy: 0.4912\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5026\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=512;, score=0.503 total time=   7.7s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 242.0736 - accuracy: 0.5055\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=512;, score=0.501 total time=   7.8s\n",
      "708/708 [==============================] - 6s 9ms/step - loss: 325.6722 - accuracy: 0.5034\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6970 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=5, n_nodes=512;, score=0.501 total time=   7.8s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7125 - accuracy: 0.4972\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6962 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=32;, score=0.497 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7368 - accuracy: 0.5028\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=32;, score=0.501 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7010 - accuracy: 0.4960\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6985 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=32;, score=0.499 total time=   8.4s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7611 - accuracy: 0.4980\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=64;, score=0.497 total time=   8.5s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7589 - accuracy: 0.5021\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=64;, score=0.501 total time=   8.6s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.7492 - accuracy: 0.5074\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6961 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=64;, score=0.501 total time=   8.6s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 2.1856 - accuracy: 0.4935\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=128;, score=0.497 total time=   8.4s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 1.6228 - accuracy: 0.5047\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=128;, score=0.499 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 0.9599 - accuracy: 0.5020\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.4986\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=128;, score=0.499 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 99.6089 - accuracy: 0.4997\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.7051 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=256;, score=0.497 total time=   8.4s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 11.5151 - accuracy: 0.5025\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6945 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=256;, score=0.501 total time=   8.2s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 23.9828 - accuracy: 0.4985\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6975 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=256;, score=0.501 total time=   8.4s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 1053.2802 - accuracy: 0.4979\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "[CV 1/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=512;, score=0.497 total time=   8.1s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 764.2578 - accuracy: 0.4977\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5014\n",
      "[CV 2/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=512;, score=0.501 total time=   8.3s\n",
      "708/708 [==============================] - 7s 9ms/step - loss: 5040.9731 - accuracy: 0.4978\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6965 - accuracy: 0.5014\n",
      "[CV 3/3] END dropout=0.4, lr=0.1, n_layers=6, n_nodes=512;, score=0.501 total time=   8.1s\n",
      "1062/1062 [==============================] - 9s 8ms/step - loss: 0.6364 - accuracy: 0.6507\n",
      "Best Parameters: {'dropout': 0.2, 'lr': 0.001, 'n_layers': 5, 'n_nodes': 256}\n",
      "Best Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=3, n_jobs=1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_opt_dense(lr= 0.0001, n_nodes1=32, n_nodes2=32, n_nodes3=32, n_nodes4=32, n_nodes5=32,dropout=0.1, activation=\"sigmoid\"):\n",
    "    model = Sequential([\n",
    "        Dense(n_nodes1, activation='relu', input_shape=(len(x_train.columns),)),\n",
    "        Dropout(dropout),\n",
    "        Dense(n_nodes2, activation='relu'),\n",
    "        Dropout(dropout),\n",
    "        Dense(n_nodes3, activation='relu'),\n",
    "        Dropout(dropout),\n",
    "        Dense(n_nodes4, activation='relu'),\n",
    "        Dropout(dropout),\n",
    "        Dense(n_nodes5, activation='relu'),\n",
    "        Dropout(dropout),\n",
    "        Dense(len(le.classes_), activation=activation)\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominik Hahn\\AppData\\Local\\Temp\\ipykernel_26164\\2395483213.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model_opt_dense)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5832 candidates, totalling 17496 fits\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6844 - accuracy: 0.5540\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.6559 - accuracy: 0.6255\n",
      "[CV 1/3] END activation=sigmoid, dropout=0.1, lr=0.0001, n_nodes1=32, n_nodes2=64, n_nodes3=128, n_nodes4=64, n_nodes5=32;, score=0.626 total time=   7.7s\n",
      "708/708 [==============================] - 6s 8ms/step - loss: 0.6671 - accuracy: 0.6060\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m KerasClassifier(build_fn\u001b[39m=\u001b[39mcreate_model_opt_dense)\n\u001b[0;32m      2\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid_2, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m grid_result \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBest Parameters: \u001b[39m\u001b[39m{\u001b[39;00mgrid_result\u001b[39m.\u001b[39mbest_params_\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBest Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mgrid_result\u001b[39m.\u001b[39mbest_score_\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    705\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    707\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m--> 708\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[0;32m    709\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[0;32m    710\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    766\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[0;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    770\u001b[0m         \u001b[39m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    771\u001b[0m         \u001b[39m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:444\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_passthrough_scorer\u001b[39m(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    443\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39mscore(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:317\u001b[0m, in \u001b[0;36mKerasClassifier.score\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mif\u001b[39;00m loss_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(y\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    315\u001b[0m   y \u001b[39m=\u001b[39m to_categorical(y)\n\u001b[1;32m--> 317\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mevaluate(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    319\u001b[0m   outputs \u001b[39m=\u001b[39m [outputs]\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\keras\\engine\\training.py:1721\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m   data_handler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler\n\u001b[0;32m   1719\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1720\u001b[0m   \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1721\u001b[0m   data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   1722\u001b[0m       x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   1723\u001b[0m       y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   1724\u001b[0m       sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1725\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1726\u001b[0m       steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   1727\u001b[0m       initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   1728\u001b[0m       epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1729\u001b[0m       max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1730\u001b[0m       workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1731\u001b[0m       use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1732\u001b[0m       model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1733\u001b[0m       steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[0;32m   1735\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1401\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1400\u001b[0m   \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1401\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1168\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1165\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step_increment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem() \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_dataset_and_inferred_steps(strategy, x, steps_per_epoch,\n\u001b[0;32m   1172\u001b[0m                                            class_weight, distribute)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \n\u001b[0;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\envs\\check_gpu_neu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model_opt_dense)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid_2, cv=3, verbose=3, n_jobs=1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'Best Parameters: {grid_result.best_params_}')\n",
    "print(f'Best Accuracy: {grid_result.best_score_:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1062/1062 [==============================] - 11s 9ms/step - loss: 0.6583 - accuracy: 0.6218 - val_loss: 0.6279 - val_accuracy: 0.6806 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1062/1062 [==============================] - 9s 8ms/step - loss: 0.6353 - accuracy: 0.6591 - val_loss: 0.6131 - val_accuracy: 0.6861 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6286 - accuracy: 0.6688 - val_loss: 0.6187 - val_accuracy: 0.6898 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1062/1062 [==============================] - 9s 8ms/step - loss: 0.6294 - accuracy: 0.6671 - val_loss: 0.6219 - val_accuracy: 0.6797 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6256 - accuracy: 0.6698 - val_loss: 0.6223 - val_accuracy: 0.6852 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6253 - accuracy: 0.6704 - val_loss: 0.6116 - val_accuracy: 0.6894 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6239 - accuracy: 0.6711 - val_loss: 0.6144 - val_accuracy: 0.6872 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6227 - accuracy: 0.6728 - val_loss: 0.6095 - val_accuracy: 0.6922 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6225 - accuracy: 0.6720 - val_loss: 0.6146 - val_accuracy: 0.6915 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6225 - accuracy: 0.6727 - val_loss: 0.6071 - val_accuracy: 0.6930 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6210 - accuracy: 0.6737 - val_loss: 0.6130 - val_accuracy: 0.6850 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6211 - accuracy: 0.6747 - val_loss: 0.6108 - val_accuracy: 0.6908 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6213 - accuracy: 0.6728 - val_loss: 0.6146 - val_accuracy: 0.6930 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6206 - accuracy: 0.6763 - val_loss: 0.6066 - val_accuracy: 0.6941 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6197 - accuracy: 0.6749 - val_loss: 0.6068 - val_accuracy: 0.6886 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6188 - accuracy: 0.6744 - val_loss: 0.6203 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6205 - accuracy: 0.6750 - val_loss: 0.6098 - val_accuracy: 0.6916 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6180 - accuracy: 0.6764 - val_loss: 0.6137 - val_accuracy: 0.6922 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6173 - accuracy: 0.6775 - val_loss: 0.6117 - val_accuracy: 0.6897 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "1062/1062 [==============================] - 9s 9ms/step - loss: 0.6122 - accuracy: 0.6836 - val_loss: 0.6090 - val_accuracy: 0.6929 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.4\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(len(x_train.columns),)),\n",
    "    Dropout(dropout),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(dropout),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(dropout),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(dropout),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(dropout),\n",
    "    Dense(len(le.classes_), activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-03), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val), callbacks=[early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
